{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "BERT word emb.ipynb",
   "provenance": [],
   "machine_shape": "hm",
   "collapsed_sections": [],
   "authorship_tag": "ABX9TyPCA7CUDD8qJWS/R+rEKnU6"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "699f66fe0673497491bfc730bf03c84e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_1f8307e656704312a71f228c977cc81d",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_ba1ee8abcfff4054a7e1705fe489eab8",
       "IPY_MODEL_30c0ed0634e84a23934a6115a545504c",
       "IPY_MODEL_55b0368a4da74a4f9d9069a8364aee2d"
      ]
     }
    },
    "1f8307e656704312a71f228c977cc81d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "ba1ee8abcfff4054a7e1705fe489eab8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_47435b40677148c5847eaf5ed5e8f6b6",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": "Downloading: 100%",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_ab936cf89b1d4ec692fa3f0f34195d68"
     }
    },
    "30c0ed0634e84a23934a6115a545504c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_1c7bad3001004e99919d4873b80bf4fb",
      "_dom_classes": [],
      "description": "",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 371391,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 371391,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_987953fe52ce4180851f64c1e79a9cd9"
     }
    },
    "55b0368a4da74a4f9d9069a8364aee2d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_f7ea77a6e947453aaf7a7ead1de56706",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 371k/371k [00:00&lt;00:00, 3.61MB/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_eafbc89ef00e42e3bf1560d7e084a242"
     }
    },
    "47435b40677148c5847eaf5ed5e8f6b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "ab936cf89b1d4ec692fa3f0f34195d68": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "1c7bad3001004e99919d4873b80bf4fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "987953fe52ce4180851f64c1e79a9cd9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "f7ea77a6e947453aaf7a7ead1de56706": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "eafbc89ef00e42e3bf1560d7e084a242": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "e82f6ded6c614b25b4d0d4da00de6ba1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_2471fac3be93468da0c2e2ebd112dbb6",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_8add4558a0df4d208f91c98016ecfd4a",
       "IPY_MODEL_9728bdc318a34c70bfca6ce1d5a576fe",
       "IPY_MODEL_4203a5098b6a43ffb3aab6dad60c50aa"
      ]
     }
    },
    "2471fac3be93468da0c2e2ebd112dbb6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "8add4558a0df4d208f91c98016ecfd4a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_eb52d840599047258cefc67d5174f06c",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": "Downloading: 100%",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_32790801273240f7972b401f2fae9b29"
     }
    },
    "9728bdc318a34c70bfca6ce1d5a576fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_9bdf167244854e4ba03205760444f69b",
      "_dom_classes": [],
      "description": "",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 77779,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 77779,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_cac8f62caef84979aec3021de512df85"
     }
    },
    "4203a5098b6a43ffb3aab6dad60c50aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_2880ac26f6244bd19bc7d0bd164ff13d",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 77.8k/77.8k [00:00&lt;00:00, 1.86MB/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_1e0c0368d3404583b069e9d496024ff3"
     }
    },
    "eb52d840599047258cefc67d5174f06c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "32790801273240f7972b401f2fae9b29": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "9bdf167244854e4ba03205760444f69b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "cac8f62caef84979aec3021de512df85": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "2880ac26f6244bd19bc7d0bd164ff13d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "1e0c0368d3404583b069e9d496024ff3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "bf62e23a2dc94008a37086262ceeff47": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_c8d647196e794b23a747d87847a10db5",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_cdf73be922d24f07b144074810f6acd1",
       "IPY_MODEL_90e3e14b9b7a407faadff00fc15e157d",
       "IPY_MODEL_547c0c42b8fe4bdd903b4d57fd4d361b"
      ]
     }
    },
    "c8d647196e794b23a747d87847a10db5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "cdf73be922d24f07b144074810f6acd1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_fc1564b616f14909a56e5150a13f5b91",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": "100%",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_57b499ba8faf466b94f6b5c7236f82ff"
     }
    },
    "90e3e14b9b7a407faadff00fc15e157d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_ede23f9fa42b4a25b4f7b82e47f4a43f",
      "_dom_classes": [],
      "description": "",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 2,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 2,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_f5e877c552bf48e89301f8f4ebaa5b39"
     }
    },
    "547c0c42b8fe4bdd903b4d57fd4d361b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_3cbf2208e1a94351b039417d62758ebb",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 2/2 [00:00&lt;00:00, 58.79it/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_50b1630f19c84da1bfcd820d0677fa2e"
     }
    },
    "fc1564b616f14909a56e5150a13f5b91": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "57b499ba8faf466b94f6b5c7236f82ff": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "ede23f9fa42b4a25b4f7b82e47f4a43f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "f5e877c552bf48e89301f8f4ebaa5b39": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "3cbf2208e1a94351b039417d62758ebb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "50b1630f19c84da1bfcd820d0677fa2e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XIlU9x62s1ja",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1641963922485,
     "user_tz": -540,
     "elapsed": 17118,
     "user": {
      "displayName": "‍서수민(대학원생-비즈니스IT전공)",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17389323653104555693"
     }
    },
    "outputId": "58999c52-d280-4e3b-e389-1eb0ef951a17"
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wzKv8NKfukoH"
   },
   "source": [
    "!pip install transformers==3.0.1\n",
    "!pip install torch"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7SNqsBvdulot"
   },
   "source": [
    "!nvidia-smi"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zSlpKcD7urzD"
   },
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "import os\n",
    "import transformers\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "ok": true,
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "status": 200,
       "status_text": ""
      }
     },
     "base_uri": "https://localhost:8080/",
     "height": 95
    },
    "id": "ETRMmMAxu4F4",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1641964207792,
     "user_tz": -540,
     "elapsed": 7355,
     "user": {
      "displayName": "‍서수민(대학원생-비즈니스IT전공)",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17389323653104555693"
     }
    },
    "outputId": "e6310f34-75e6-442f-cf55-e7198c2d7f4f"
   },
   "source": [
    "from google.colab import files\n",
    "src = list(files.upload().values())[0]\n",
    "open('file1.py','wb')"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-414c9929-53be-4a0b-b3f6-4a8e5d443326\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-414c9929-53be-4a0b-b3f6-4a8e5d443326\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saving tokenization_kobert.py to tokenization_kobert.py\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<_io.BufferedWriter name='file1.py'>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tAVSwoLuu8sk",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "699f66fe0673497491bfc730bf03c84e",
      "1f8307e656704312a71f228c977cc81d",
      "ba1ee8abcfff4054a7e1705fe489eab8",
      "30c0ed0634e84a23934a6115a545504c",
      "55b0368a4da74a4f9d9069a8364aee2d",
      "47435b40677148c5847eaf5ed5e8f6b6",
      "ab936cf89b1d4ec692fa3f0f34195d68",
      "1c7bad3001004e99919d4873b80bf4fb",
      "987953fe52ce4180851f64c1e79a9cd9",
      "f7ea77a6e947453aaf7a7ead1de56706",
      "eafbc89ef00e42e3bf1560d7e084a242",
      "e82f6ded6c614b25b4d0d4da00de6ba1",
      "2471fac3be93468da0c2e2ebd112dbb6",
      "8add4558a0df4d208f91c98016ecfd4a",
      "9728bdc318a34c70bfca6ce1d5a576fe",
      "4203a5098b6a43ffb3aab6dad60c50aa",
      "eb52d840599047258cefc67d5174f06c",
      "32790801273240f7972b401f2fae9b29",
      "9bdf167244854e4ba03205760444f69b",
      "cac8f62caef84979aec3021de512df85",
      "2880ac26f6244bd19bc7d0bd164ff13d",
      "1e0c0368d3404583b069e9d496024ff3"
     ]
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1641964439568,
     "user_tz": -540,
     "elapsed": 984,
     "user": {
      "displayName": "‍서수민(대학원생-비즈니스IT전공)",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17389323653104555693"
     }
    },
    "outputId": "4dbe685f-1f3e-47b4-e3bf-31e88f7367f0"
   },
   "source": [
    "import tokenization_kobert\n",
    "model_version = 'monologg/kobert'\n",
    "tokenizer = tokenization_kobert.KoBertTokenizer.from_pretrained(model_version)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "699f66fe0673497491bfc730bf03c84e",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/371k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e82f6ded6c614b25b4d0d4da00de6ba1",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/77.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(tokenizer.tokenize('박주영 첫 골 도움 아르샤빈, 아스날과 결별'))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D182JMjUtRAf",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1641964522613,
     "user_tz": -540,
     "elapsed": 319,
     "user": {
      "displayName": "‍서수민(대학원생-비즈니스IT전공)",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17389323653104555693"
     }
    },
    "outputId": "61d0324d-4eed-44c1-a95b-5dae9defb465"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['▁박', '주', '영', '▁첫', '▁골', '▁도움', '▁아', '르', '샤', '빈', ',', '▁아', '스', '날', '과', '▁결별']\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "tokens=['아스날','박주영','아르샤빈']"
   ],
   "metadata": {
    "id": "hER6Lj2YecIt"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# 추가된 단어의 개수 확인\n",
    "num_added_toks = tokenizer.add_tokens(tokens)\n",
    "num_added_toks\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MdrTEzc7ecOs",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1641964535847,
     "user_tz": -540,
     "elapsed": 319,
     "user": {
      "displayName": "‍서수민(대학원생-비즈니스IT전공)",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17389323653104555693"
     }
    },
    "outputId": "2c44620d-dbd1-42c5-8b0c-ec914700a810"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# 추가된 단어의 토큰 번호 확인\n",
    "encoded_entity = tokenizer.convert_tokens_to_ids(tokens)"
   ],
   "metadata": {
    "id": "4tE68GdxecQ8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "encoded_entity"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BGMJErbwecS8",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1641964549600,
     "user_tz": -540,
     "elapsed": 318,
     "user": {
      "displayName": "‍서수민(대학원생-비즈니스IT전공)",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17389323653104555693"
     }
    },
    "outputId": "f3cd9e7d-344b-4b7a-9db5-829f7691128b"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[8002, 8003, 8004]"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(tokenizer.tokenize('박주영 첫 골 도움 아르샤빈, 아스날과 결별'))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fLqQbVAktvAH",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1641964569497,
     "user_tz": -540,
     "elapsed": 296,
     "user": {
      "displayName": "‍서수민(대학원생-비즈니스IT전공)",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17389323653104555693"
     }
    },
    "outputId": "645f4a2c-09a9-40b7-cbd7-b61a436a57f6"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['박주영', '▁첫', '▁골', '▁도움', '아르샤빈', '▁', ',', '아스날', '▁', '과', '▁결별']\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "##GPU 사용 시\n",
    "device = torch.device(0)"
   ],
   "metadata": {
    "id": "g1qrl07zegc0"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import BertForMaskedLM, AdamW, BertConfig\n",
    "\n",
    "model = BertForMaskedLM.from_pretrained(model_version, # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    output_attentions = True, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = True, # Whether the model returns all hidden-states.    \n",
    ")\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "model.cuda(device)"
   ],
   "metadata": {
    "id": "g_LbgFLAeiEG"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "U_ANZmftC3wM"
   },
   "source": [
    "import copy\n",
    "param_list=[]\n",
    "name_list=[]\n",
    "for name, param in model.named_parameters():\n",
    "  param_list.append(copy.deepcopy(param))\n",
    "  name_list.append(name)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ik00Ni2UDAsS",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1641965099671,
     "user_tz": -540,
     "elapsed": 311,
     "user": {
      "displayName": "‍서수민(대학원생-비즈니스IT전공)",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17389323653104555693"
     }
    },
    "outputId": "61fe11bd-10e6-4dba-ced4-7a0821ed726f"
   },
   "source": [
    "len(param_list)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "204"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "name_list[0]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "Rc_VMcUbvyzE",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1641965115466,
     "user_tz": -540,
     "elapsed": 316,
     "user": {
      "displayName": "‍서수민(대학원생-비즈니스IT전공)",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17389323653104555693"
     }
    },
    "outputId": "1e6b34c1-a6ed-434c-8ba6-cd739fa1e8d1"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'bert.embeddings.word_embeddings.weight'"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "param_list[0]"
   ],
   "metadata": {
    "id": "VhOrYLCkof0x",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1641965101944,
     "user_tz": -540,
     "elapsed": 446,
     "user": {
      "displayName": "‍서수민(대학원생-비즈니스IT전공)",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17389323653104555693"
     }
    },
    "outputId": "eb9b0326-ecd0-4335-caae-473696fc2263"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0086,  0.0153,  0.0338,  ..., -0.0012,  0.0861, -0.0199],\n",
       "        [ 0.0014,  0.0273,  0.1173,  ...,  0.0422, -0.0582, -0.0720],\n",
       "        [ 0.0035, -0.0004, -0.0004,  ...,  0.0031,  0.0103, -0.0033],\n",
       "        ...,\n",
       "        [-0.0287,  0.0017,  0.0496,  ..., -0.0023,  0.0141,  0.0168],\n",
       "        [ 0.0070, -0.0141,  0.0199,  ...,  0.0017,  0.0113, -0.0008],\n",
       "        [ 0.0005, -0.0276, -0.0281,  ..., -0.0107, -0.0009, -0.0112]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "sentences=['아르샤빈은 아스날에서 최고의 선수다','아르샤빈보다 박주영이 훨씬 잘한다']"
   ],
   "metadata": {
    "id": "fCtS47KGfAkW"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "sentences"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lqy-OYw4fAsN",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1641965341253,
     "user_tz": -540,
     "elapsed": 3,
     "user": {
      "displayName": "‍서수민(대학원생-비즈니스IT전공)",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17389323653104555693"
     }
    },
    "outputId": "21a63fa5-cd69-48d0-8127-9eb05608192a"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['아르샤빈은 아스날에서 최고의 선수다', '아르샤빈보다 박주영이 훨씬 잘한다']"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Print the original sentence.\n",
    "print(' Original: ', sentences[0])\n",
    "\n",
    "# Print the sentence split into tokens.\n",
    "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
    "\n",
    "# Print the sentence mapped to token ids.\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6M8sJw2jfAut",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1641965926759,
     "user_tz": -540,
     "elapsed": 311,
     "user": {
      "displayName": "‍서수민(대학원생-비즈니스IT전공)",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17389323653104555693"
     }
    },
    "outputId": "ce118e04-b395-4b7b-e2ac-25432f4f815d"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " Original:  아르샤빈은 아스날에서 최고의 선수다\n",
      "Tokenized:  ['아르샤빈', '▁', '은', '아스날', '▁', '에서', '▁최고의', '▁선수', '다']\n",
      "Token IDs:  [8004, 517, 7086, 8002, 517, 6903, 4524, 2753, 5782]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# 마스킹 하기전 모든 데이터를 숫자ID로 변경하는 작업 (가장 오래걸리는 작업)\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# For every sentence...\n",
    "for sent in tqdm_notebook(sentences):\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 128,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',\n",
    "                        truncation=True# Return pytorch tensors.\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print('Original: ', sentences[0])\n",
    "print('Token IDs:', input_ids[0])"
   ],
   "metadata": {
    "id": "P9GAz7svgCaR",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1641965928744,
     "user_tz": -540,
     "elapsed": 440,
     "user": {
      "displayName": "‍서수민(대학원생-비즈니스IT전공)",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17389323653104555693"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269,
     "referenced_widgets": [
      "bf62e23a2dc94008a37086262ceeff47",
      "c8d647196e794b23a747d87847a10db5",
      "cdf73be922d24f07b144074810f6acd1",
      "90e3e14b9b7a407faadff00fc15e157d",
      "547c0c42b8fe4bdd903b4d57fd4d361b",
      "fc1564b616f14909a56e5150a13f5b91",
      "57b499ba8faf466b94f6b5c7236f82ff",
      "ede23f9fa42b4a25b4f7b82e47f4a43f",
      "f5e877c552bf48e89301f8f4ebaa5b39",
      "3cbf2208e1a94351b039417d62758ebb",
      "50b1630f19c84da1bfcd820d0677fa2e"
     ]
    },
    "outputId": "8179b2b6-42e8-4e02-ec8d-478405bb74bf"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf62e23a2dc94008a37086262ceeff47",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Original:  아르샤빈은 아스날에서 최고의 선수다\n",
      "Token IDs: tensor([   2, 8004,  517, 7086, 8002,  517, 6903, 4524, 2753, 5782,    3,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print('Original: ', sentences[1])\n",
    "print('Token IDs:', input_ids[1])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r6j5XGpSzTPM",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1641966028183,
     "user_tz": -540,
     "elapsed": 296,
     "user": {
      "displayName": "‍서수민(대학원생-비즈니스IT전공)",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17389323653104555693"
     }
    },
    "outputId": "23352a84-ca05-476e-fc0c-ff18f4c061e3"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Original:  아르샤빈보다 박주영이 훨씬 잘한다\n",
      "Token IDs: tensor([   2, 8004, 2368, 8003, 3647, 5187, 3942, 7831,    3,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "input_ids"
   ],
   "metadata": {
    "id": "u7w9cDu0ngkP",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1641965967495,
     "user_tz": -540,
     "elapsed": 466,
     "user": {
      "displayName": "‍서수민(대학원생-비즈니스IT전공)",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17389323653104555693"
     }
    },
    "outputId": "d7867388-dcb4-411a-f6d1-c90c40c5b02a"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[   2, 8004,  517, 7086, 8002,  517, 6903, 4524, 2753, 5782,    3,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1],\n",
       "        [   2, 8004, 2368, 8003, 3647, 5187, 3942, 7831,    3,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1]])"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import copy\n",
    "input_id  = copy.deepcopy(input_ids[0].numpy().reshape(1,128))"
   ],
   "metadata": {
    "id": "lge1ENKLhSlU"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "input_id"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UnEsCuNFyTQ2",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1641965969727,
     "user_tz": -540,
     "elapsed": 487,
     "user": {
      "displayName": "‍서수민(대학원생-비즈니스IT전공)",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17389323653104555693"
     }
    },
    "outputId": "6f4d3459-6342-4a01-d4e9-9827ee1b17f7"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[   2, 8004,  517, 7086, 8002,  517, 6903, 4524, 2753, 5782,    3,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1]])"
      ]
     },
     "metadata": {},
     "execution_count": 55
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "input_id[0,1]=4"
   ],
   "metadata": {
    "id": "5HD830pyge0Z"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "random_ids = []\n",
    "random_ids.append(torch.from_numpy(input_id))"
   ],
   "metadata": {
    "id": "-WdUGVMqfA1e"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import copy\n",
    "input_id  = copy.deepcopy(input_ids[1].numpy().reshape(1,128))\n"
   ],
   "metadata": {
    "id": "y47U7WbVnrbn"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "input_id "
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MU8m-fIRzI9U",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1641965984956,
     "user_tz": -540,
     "elapsed": 303,
     "user": {
      "displayName": "‍서수민(대학원생-비즈니스IT전공)",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17389323653104555693"
     }
    },
    "outputId": "7f13ac1c-1c9e-4fee-8f64-60a6a389fb97"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[   2, 8004, 2368, 8003, 3647, 5187, 3942, 7831,    3,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1]])"
      ]
     },
     "metadata": {},
     "execution_count": 60
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "input_id[0,3]=4"
   ],
   "metadata": {
    "id": "mPbeY-ZRyyiU"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "random_ids.append(torch.from_numpy(input_id))"
   ],
   "metadata": {
    "id": "fq_CA4KTn-bo"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "random_ids=torch.cat(random_ids, dim=0)"
   ],
   "metadata": {
    "id": "6tSvjDVZimiQ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "random_ids"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "acH6lL6ZdJg6",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1641966003625,
     "user_tz": -540,
     "elapsed": 322,
     "user": {
      "displayName": "‍서수민(대학원생-비즈니스IT전공)",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17389323653104555693"
     }
    },
    "outputId": "67da4b96-2fc1-4517-abb5-6862c197a113"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[   2,    4,  517, 7086, 8002,  517, 6903, 4524, 2753, 5782,    3,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1],\n",
       "        [   2, 8004, 2368,    4, 3647, 5187, 3942, 7831,    3,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1]])"
      ]
     },
     "metadata": {},
     "execution_count": 65
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_ids, val_ids=train_test_split(random_ids,test_size=0.5,\n",
    "                                                  random_state=3333)\n",
    "train_att, val_att=train_test_split(attention_masks, test_size=0.5,\n",
    "                                                  random_state=3333)\n",
    "train_input, val_input=train_test_split(input_ids, test_size=0.5,\n",
    "                                                  random_state=3333)"
   ],
   "metadata": {
    "id": "MSeOjrl2qEGk"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "# Combine the training inputs into a TensorDataset.\n",
    "train_dataset = TensorDataset(train_ids, train_att, train_input)\n",
    "val_dataset = TensorDataset(val_ids, val_att, val_input)\n",
    "\n",
    "# Create a 90-10 train-validation split.\n",
    "\n",
    "# Calculate the number of samples to include in each set.\n",
    "#train_size = int(0.9 * len(dataset))\n",
    "#val_size = len(dataset) - train_size\n",
    "\n",
    "# Divide the dataset by randomly selecting samples.\n",
    "#train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print('{:>5,} training samples'.format(len(train_dataset)))\n",
    "print('{:>5,} validation samples'.format(len(val_dataset)))\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DfC30Q-uiI7M",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1641966199594,
     "user_tz": -540,
     "elapsed": 296,
     "user": {
      "displayName": "‍서수민(대학원생-비즈니스IT전공)",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17389323653104555693"
     }
    },
    "outputId": "a9242127-ecd4-4310-9ac2-8264624a7e46"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "    1 training samples\n",
      "    1 validation samples\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# The DataLoader needs to know our batch size for training, so we specify it \n",
    "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
    "# size of 16 or 32.\n",
    "batch_size = 26\n",
    "\n",
    "# Create the DataLoaders for our training and validation sets.\n",
    "# We'll take training samples in random order. \n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )"
   ],
   "metadata": {
    "id": "I4aIVcu-jeCw"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "# I believe the 'W' stands for 'Weight Decay fix\"\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )"
   ],
   "metadata": {
    "id": "Kg8dNnDYjjFg"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
    "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
    "# training data.\n",
    "epochs = 1000\n",
    "\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ],
   "metadata": {
    "id": "ZnzuvF9ijnsn"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ],
   "metadata": {
    "id": "p6i4mZ9Kjozf"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import random\n",
    "import os\n",
    "import pickle as pkl\n",
    "import shutil\n",
    "from transformers import AutoTokenizer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "import pandas as pd\n",
    "import copy\n",
    "from tqdm.notebook import tqdm_notebook"
   ],
   "metadata": {
    "id": "uoRMdQttd0cP"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# We'll store a number of quantities such as training and validation loss, \n",
    "# validation accuracy, and timings.\n",
    "training_stats = []\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "# attention weight saving\n",
    "## attention_train = []\n",
    "## attention_valid = []\n",
    "\n",
    "# input_id saving\n",
    "## input_id_train = []\n",
    "## input_id_valid = []\n",
    "\n",
    "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
    "\n",
    "out_dir = '/content/drive/MyDrive/word_emb/'\n",
    "output_dir = out_dir + 'random_all'\n",
    "\n",
    "# Create output directory if needed\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ],
   "metadata": {
    "id": "TovPNpfqjp9p"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def save_models(out_dir):\n",
    "    \n",
    "    # Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
    "\n",
    "    output_dir = out_dir\n",
    "\n",
    "    # Create output directory if needed\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    print(\"Saving model to %s\" % output_dir)\n",
    "\n",
    "    # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
    "    # They can then be reloaded using `from_pretrained()`\n",
    "    model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "    model_to_save.save_pretrained(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "    # Good practice: save your training arguments together with the trained model\n",
    "    # torch.save(args, os.path.join(output_dir, 'training_args.bin'))"
   ],
   "metadata": {
    "id": "EeTeKXWGj5BI"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to \n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because \n",
    "        # accumulating the gradients is \"convenient while training RNNs\". \n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # The documentation for this `model` function is here: \n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "        # It returns different numbers of parameters depending on what arguments\n",
    "        # arge given and what flags are set. For our useage here, it returns\n",
    "        # the loss (because we provided labels) and the \"logits\"--the model\n",
    "        # outputs prior to activation.\n",
    "        loss, logits, attention_t, t_h_state = model(b_input_ids, \n",
    "                                         token_type_ids=None, \n",
    "                                         attention_mask=b_input_mask,\n",
    "                                         masked_lm_labels=b_labels)\n",
    "        #print('train_loss:', loss)\n",
    "        \n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    epoch_dir = out_dir + 'random_all_epoch_' + str(epoch_i+1) + '/'\n",
    "    save_models(epoch_dir)\n",
    "        \n",
    "    epoch_output = epoch_dir + 'random_all_weight/'      \n",
    "    shutil.copytree(output_dir,epoch_output)\n",
    "\n",
    "    tmp_list=[]\n",
    "    p_list=[]\n",
    "    for name, param in model.named_parameters():\n",
    "      p_list.append(copy.deepcopy(param))\n",
    "      tmp_list.append(name)\n",
    "    \n",
    "    print(p_list[0])\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.5f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "        "
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i6z_o_QRiI9M",
    "executionInfo": {
     "status": "error",
     "timestamp": 1641969447141,
     "user_tz": -540,
     "elapsed": 3086716,
     "user": {
      "displayName": "‍서수민(대학원생-비즈니스IT전공)",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17389323653104555693"
     }
    },
    "outputId": "de1062ac-440a-4b6a-fa6d-c0bef73697bf"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001B[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001B[0m\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.05262\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 431 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_431/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0162,  0.0321,  ..., -0.0020,  0.0840, -0.0174],\n",
      "        [ 0.0018,  0.0279,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0044, -0.0010,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0305,  0.0006,  0.0516,  ..., -0.0017,  0.0155,  0.0165],\n",
      "        [ 0.0078, -0.0136,  0.0185,  ...,  0.0008,  0.0096,  0.0010],\n",
      "        [-0.0016, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04789\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 432 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_432/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0162,  0.0321,  ..., -0.0020,  0.0840, -0.0174],\n",
      "        [ 0.0018,  0.0279,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0044, -0.0010,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0305,  0.0006,  0.0516,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0136,  0.0185,  ...,  0.0008,  0.0096,  0.0010],\n",
      "        [-0.0016, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04570\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 433 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_433/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0162,  0.0321,  ..., -0.0020,  0.0840, -0.0174],\n",
      "        [ 0.0018,  0.0279,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0044, -0.0010,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0305,  0.0006,  0.0516,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0136,  0.0185,  ...,  0.0008,  0.0096,  0.0010],\n",
      "        [-0.0016, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04641\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 434 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_434/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0162,  0.0321,  ..., -0.0020,  0.0840, -0.0174],\n",
      "        [ 0.0017,  0.0279,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0044, -0.0010,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0305,  0.0006,  0.0516,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0136,  0.0185,  ...,  0.0008,  0.0096,  0.0010],\n",
      "        [-0.0016, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04855\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 435 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_435/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0162,  0.0321,  ..., -0.0020,  0.0840, -0.0174],\n",
      "        [ 0.0017,  0.0279,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0044, -0.0010,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0305,  0.0006,  0.0516,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0136,  0.0185,  ...,  0.0008,  0.0096,  0.0010],\n",
      "        [-0.0016, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04552\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 436 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_436/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0162,  0.0321,  ..., -0.0020,  0.0840, -0.0174],\n",
      "        [ 0.0017,  0.0279,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0044, -0.0010,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0305,  0.0006,  0.0516,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0136,  0.0185,  ...,  0.0008,  0.0096,  0.0010],\n",
      "        [-0.0016, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.03834\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 437 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_437/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0162,  0.0321,  ..., -0.0020,  0.0840, -0.0174],\n",
      "        [ 0.0017,  0.0279,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0044, -0.0010,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0305,  0.0006,  0.0516,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0136,  0.0185,  ...,  0.0008,  0.0096,  0.0010],\n",
      "        [-0.0016, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04214\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 438 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_438/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0162,  0.0321,  ..., -0.0020,  0.0840, -0.0174],\n",
      "        [ 0.0017,  0.0279,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0044, -0.0010,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0305,  0.0006,  0.0516,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0136,  0.0185,  ...,  0.0008,  0.0096,  0.0010],\n",
      "        [-0.0016, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04728\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 439 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_439/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0162,  0.0321,  ..., -0.0020,  0.0840, -0.0174],\n",
      "        [ 0.0017,  0.0279,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0044, -0.0010,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0305,  0.0006,  0.0516,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0136,  0.0185,  ...,  0.0008,  0.0096,  0.0010],\n",
      "        [-0.0016, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.05271\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 440 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_440/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0162,  0.0321,  ..., -0.0020,  0.0840, -0.0174],\n",
      "        [ 0.0017,  0.0279,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0044, -0.0010,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0305,  0.0006,  0.0516,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0136,  0.0185,  ...,  0.0008,  0.0096,  0.0010],\n",
      "        [-0.0016, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04672\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 441 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_441/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0162,  0.0321,  ..., -0.0020,  0.0840, -0.0174],\n",
      "        [ 0.0017,  0.0279,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0044, -0.0010,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0305,  0.0006,  0.0516,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0136,  0.0185,  ...,  0.0008,  0.0096,  0.0010],\n",
      "        [-0.0016, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04522\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 442 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_442/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0162,  0.0321,  ..., -0.0020,  0.0840, -0.0174],\n",
      "        [ 0.0017,  0.0279,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0044, -0.0010,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0305,  0.0006,  0.0516,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0136,  0.0185,  ...,  0.0008,  0.0096,  0.0010],\n",
      "        [-0.0016, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04274\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 443 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_443/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0162,  0.0321,  ..., -0.0020,  0.0840, -0.0174],\n",
      "        [ 0.0017,  0.0279,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0044, -0.0010,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0305,  0.0006,  0.0516,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0136,  0.0185,  ...,  0.0008,  0.0096,  0.0010],\n",
      "        [-0.0016, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.05078\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 444 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_444/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0162,  0.0321,  ..., -0.0020,  0.0840, -0.0174],\n",
      "        [ 0.0017,  0.0279,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0044, -0.0010,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0305,  0.0006,  0.0516,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0136,  0.0185,  ...,  0.0008,  0.0096,  0.0010],\n",
      "        [-0.0017, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.05078\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 445 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_445/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0162,  0.0321,  ..., -0.0020,  0.0840, -0.0174],\n",
      "        [ 0.0017,  0.0279,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0044, -0.0010,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0305,  0.0006,  0.0516,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0136,  0.0185,  ...,  0.0008,  0.0096,  0.0010],\n",
      "        [-0.0017, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.05018\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 446 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_446/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0162,  0.0321,  ..., -0.0020,  0.0840, -0.0174],\n",
      "        [ 0.0017,  0.0279,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0044, -0.0010,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0305,  0.0006,  0.0516,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0136,  0.0185,  ...,  0.0008,  0.0096,  0.0010],\n",
      "        [-0.0017, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04834\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 447 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_447/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0162,  0.0321,  ..., -0.0020,  0.0840, -0.0174],\n",
      "        [ 0.0017,  0.0279,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0044, -0.0010,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0305,  0.0006,  0.0516,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0136,  0.0185,  ...,  0.0008,  0.0096,  0.0010],\n",
      "        [-0.0017, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04027\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 448 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_448/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0162,  0.0321,  ..., -0.0020,  0.0840, -0.0174],\n",
      "        [ 0.0017,  0.0279,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0044, -0.0010,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0305,  0.0006,  0.0516,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0136,  0.0185,  ...,  0.0008,  0.0096,  0.0010],\n",
      "        [-0.0017, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04612\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 449 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_449/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0162,  0.0321,  ..., -0.0020,  0.0840, -0.0174],\n",
      "        [ 0.0017,  0.0279,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0044, -0.0010,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0305,  0.0006,  0.0516,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0136,  0.0185,  ...,  0.0008,  0.0096,  0.0010],\n",
      "        [-0.0017, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04306\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 450 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_450/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0162,  0.0321,  ..., -0.0020,  0.0840, -0.0174],\n",
      "        [ 0.0017,  0.0279,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0044, -0.0010,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0305,  0.0006,  0.0516,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0136,  0.0185,  ...,  0.0008,  0.0096,  0.0010],\n",
      "        [-0.0017, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.05001\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 451 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_451/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0162,  0.0321,  ..., -0.0020,  0.0840, -0.0174],\n",
      "        [ 0.0017,  0.0279,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0044, -0.0010,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0305,  0.0006,  0.0516,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0136,  0.0185,  ...,  0.0008,  0.0096,  0.0010],\n",
      "        [-0.0017, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04442\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 452 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_452/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0162,  0.0321,  ..., -0.0020,  0.0840, -0.0174],\n",
      "        [ 0.0017,  0.0279,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0044, -0.0010,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0305,  0.0006,  0.0516,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0136,  0.0185,  ...,  0.0008,  0.0096,  0.0010],\n",
      "        [-0.0017, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04399\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 453 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_453/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0162,  0.0321,  ..., -0.0020,  0.0840, -0.0174],\n",
      "        [ 0.0017,  0.0279,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0044, -0.0010,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0305,  0.0006,  0.0516,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0136,  0.0185,  ...,  0.0008,  0.0096,  0.0010],\n",
      "        [-0.0017, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.05330\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 454 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_454/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0162,  0.0321,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0017,  0.0279,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0044, -0.0010,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0305,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0136,  0.0185,  ...,  0.0008,  0.0096,  0.0010],\n",
      "        [-0.0017, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04647\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 455 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_455/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0162,  0.0321,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0017,  0.0279,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0044, -0.0010,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0305,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0136,  0.0185,  ...,  0.0008,  0.0096,  0.0010],\n",
      "        [-0.0017, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04723\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 456 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_456/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0162,  0.0321,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0017,  0.0279,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0044, -0.0010,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0305,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0136,  0.0185,  ...,  0.0008,  0.0096,  0.0010],\n",
      "        [-0.0017, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04833\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 457 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_457/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0162,  0.0321,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0017,  0.0279,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0044, -0.0010,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0305,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0136,  0.0185,  ...,  0.0008,  0.0096,  0.0010],\n",
      "        [-0.0017, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04322\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 458 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_458/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0162,  0.0321,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0017,  0.0279,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0044, -0.0010,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0305,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0136,  0.0185,  ...,  0.0008,  0.0096,  0.0010],\n",
      "        [-0.0017, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04685\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 459 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_459/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0162,  0.0321,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0017,  0.0279,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0044, -0.0010,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0305,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0136,  0.0185,  ...,  0.0008,  0.0096,  0.0010],\n",
      "        [-0.0017, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04160\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 460 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_460/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0162,  0.0321,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0017,  0.0279,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0044, -0.0010,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0305,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0136,  0.0185,  ...,  0.0008,  0.0096,  0.0010],\n",
      "        [-0.0017, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04111\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 461 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_461/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0162,  0.0321,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0017,  0.0279,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0044, -0.0010,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0305,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0136,  0.0185,  ...,  0.0008,  0.0096,  0.0010],\n",
      "        [-0.0017, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.05050\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 462 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_462/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0162,  0.0321,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0017,  0.0279,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0044, -0.0010,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0305,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0136,  0.0185,  ...,  0.0008,  0.0096,  0.0010],\n",
      "        [-0.0017, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.05088\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 463 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_463/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0162,  0.0321,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0017,  0.0279,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0044, -0.0010,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0305,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0136,  0.0185,  ...,  0.0008,  0.0096,  0.0010],\n",
      "        [-0.0017, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.05187\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 464 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_464/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0162,  0.0321,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0017,  0.0279,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0044, -0.0010,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0305,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0136,  0.0185,  ...,  0.0008,  0.0096,  0.0010],\n",
      "        [-0.0017, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04828\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 465 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_465/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0162,  0.0321,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0017,  0.0279,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0044, -0.0010,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0305,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0136,  0.0185,  ...,  0.0008,  0.0096,  0.0010],\n",
      "        [-0.0017, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04867\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 466 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_466/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0162,  0.0321,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0017,  0.0279,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0044, -0.0010,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0305,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0136,  0.0185,  ...,  0.0008,  0.0096,  0.0010],\n",
      "        [-0.0017, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.05108\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 467 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_467/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0162,  0.0321,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0017,  0.0279,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0044, -0.0010,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0305,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0136,  0.0185,  ...,  0.0008,  0.0096,  0.0010],\n",
      "        [-0.0017, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04705\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 468 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_468/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0162,  0.0321,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0017,  0.0279,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0044, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0305,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0136,  0.0185,  ...,  0.0008,  0.0096,  0.0010],\n",
      "        [-0.0017, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04847\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 469 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_469/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0162,  0.0321,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0017,  0.0279,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0044, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0305,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0136,  0.0185,  ...,  0.0008,  0.0096,  0.0010],\n",
      "        [-0.0017, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04665\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 470 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_470/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0162,  0.0321,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0017,  0.0279,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0044, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0305,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0136,  0.0185,  ...,  0.0008,  0.0096,  0.0010],\n",
      "        [-0.0017, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04264\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 471 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_471/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0162,  0.0321,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0017,  0.0279,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0044, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0305,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0136,  0.0185,  ...,  0.0008,  0.0096,  0.0010],\n",
      "        [-0.0017, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04462\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 472 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_472/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0162,  0.0321,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0017,  0.0279,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0044, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0305,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0136,  0.0185,  ...,  0.0008,  0.0096,  0.0010],\n",
      "        [-0.0017, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04695\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 473 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_473/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0162,  0.0321,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0017,  0.0279,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0044, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0305,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0136,  0.0185,  ...,  0.0008,  0.0096,  0.0010],\n",
      "        [-0.0017, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04399\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 474 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_474/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0162,  0.0321,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0017,  0.0279,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0044, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0305,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0136,  0.0185,  ...,  0.0008,  0.0096,  0.0010],\n",
      "        [-0.0017, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04475\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 475 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_475/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0162,  0.0321,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0017,  0.0279,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0044, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0305,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0136,  0.0185,  ...,  0.0008,  0.0096,  0.0010],\n",
      "        [-0.0017, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04697\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 476 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_476/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0162,  0.0321,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0017,  0.0279,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0044, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0305,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0136,  0.0185,  ...,  0.0008,  0.0095,  0.0010],\n",
      "        [-0.0017, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04289\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 477 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_477/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0162,  0.0321,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0017,  0.0279,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0044, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0305,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0136,  0.0185,  ...,  0.0008,  0.0095,  0.0010],\n",
      "        [-0.0017, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.05042\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 478 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_478/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0162,  0.0321,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0017,  0.0279,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0044, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0305,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0136,  0.0185,  ...,  0.0008,  0.0095,  0.0010],\n",
      "        [-0.0017, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.05618\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 479 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_479/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0162,  0.0321,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0017,  0.0279,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0044, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0305,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0136,  0.0185,  ...,  0.0008,  0.0095,  0.0010],\n",
      "        [-0.0017, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04609\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 480 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_480/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0162,  0.0321,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0017,  0.0279,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0044, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0305,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0136,  0.0184,  ...,  0.0008,  0.0095,  0.0010],\n",
      "        [-0.0017, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04213\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 481 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_481/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0162,  0.0321,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0017,  0.0279,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0044, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0305,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0136,  0.0184,  ...,  0.0008,  0.0095,  0.0010],\n",
      "        [-0.0017, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04818\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 482 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_482/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0162,  0.0320,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0017,  0.0279,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0044, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0305,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0136,  0.0184,  ...,  0.0008,  0.0095,  0.0010],\n",
      "        [-0.0017, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04690\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 483 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_483/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0162,  0.0320,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0017,  0.0279,  0.1172,  ...,  0.0418, -0.0582, -0.0723],\n",
      "        [ 0.0044, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0305,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0136,  0.0184,  ...,  0.0008,  0.0095,  0.0010],\n",
      "        [-0.0017, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04541\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 484 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_484/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0162,  0.0320,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0017,  0.0279,  0.1172,  ...,  0.0418, -0.0582, -0.0723],\n",
      "        [ 0.0044, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0305,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0136,  0.0184,  ...,  0.0008,  0.0095,  0.0010],\n",
      "        [-0.0017, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04488\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 485 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_485/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0162,  0.0320,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0017,  0.0279,  0.1172,  ...,  0.0418, -0.0582, -0.0723],\n",
      "        [ 0.0044, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0136,  0.0184,  ...,  0.0008,  0.0095,  0.0010],\n",
      "        [-0.0017, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.05201\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 486 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_486/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0162,  0.0320,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0017,  0.0279,  0.1172,  ...,  0.0418, -0.0582, -0.0723],\n",
      "        [ 0.0044, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0136,  0.0184,  ...,  0.0008,  0.0095,  0.0010],\n",
      "        [-0.0017, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04653\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 487 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_487/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0162,  0.0320,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0017,  0.0279,  0.1172,  ...,  0.0418, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0136,  0.0184,  ...,  0.0008,  0.0095,  0.0010],\n",
      "        [-0.0017, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04379\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 488 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_488/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0017,  0.0279,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0136,  0.0184,  ...,  0.0008,  0.0095,  0.0010],\n",
      "        [-0.0017, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04486\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 489 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_489/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0017,  0.0279,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0010],\n",
      "        [-0.0017, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04622\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 490 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_490/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0017,  0.0279,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0010],\n",
      "        [-0.0017, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04294\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 491 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_491/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0017,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0010],\n",
      "        [-0.0017, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04733\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 492 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_492/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0017,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0010],\n",
      "        [-0.0017, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04688\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 493 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_493/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0017,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0010],\n",
      "        [-0.0017, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04457\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 494 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_494/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0017,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0010],\n",
      "        [-0.0017, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.05085\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 495 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_495/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0017,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0010],\n",
      "        [-0.0017, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04357\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 496 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_496/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0017,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0010],\n",
      "        [-0.0017, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04222\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 497 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_497/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0018,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0010],\n",
      "        [-0.0017, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04828\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 498 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_498/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0018,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0010],\n",
      "        [-0.0017, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.05283\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 499 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_499/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0018,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0010],\n",
      "        [-0.0017, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04433\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 500 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_500/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0018,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0054],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0010],\n",
      "        [-0.0017, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04501\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 501 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_501/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0018,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0010],\n",
      "        [-0.0017, -0.0290, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04559\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 502 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_502/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0018,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0010],\n",
      "        [-0.0017, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04636\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 503 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_503/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0018,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0010],\n",
      "        [-0.0017, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.05088\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 504 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_504/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0018,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0010],\n",
      "        [-0.0017, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.05198\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 505 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_505/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0018,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0010],\n",
      "        [-0.0017, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04876\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 506 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_506/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0018,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0010],\n",
      "        [-0.0017, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04422\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 507 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_507/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0018,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0010],\n",
      "        [-0.0017, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04614\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 508 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_508/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0018,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0010],\n",
      "        [-0.0017, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04058\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 509 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_509/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0018,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0010],\n",
      "        [-0.0017, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04142\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 510 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_510/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0018,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0010],\n",
      "        [-0.0017, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04957\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 511 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_511/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0018,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0017, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04329\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 512 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_512/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0017, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04270\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 513 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_513/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0017, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04901\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 514 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_514/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0020,  0.0840, -0.0173],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0017, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04583\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 515 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_515/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0840, -0.0173],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0017, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04411\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 516 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_516/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0840, -0.0173],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0017, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04010\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 517 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_517/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0840, -0.0173],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0017, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04315\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 518 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_518/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0840, -0.0173],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0017, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.05004\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 519 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_519/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0840, -0.0173],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0017, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0132]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04968\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 520 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_520/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0840, -0.0173],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0155,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0017, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04588\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 521 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_521/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0840, -0.0173],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0017, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.05066\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 522 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_522/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0840, -0.0173],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0420, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0017, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04513\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 523 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_523/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0840, -0.0173],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0420, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0017, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04863\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 524 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_524/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0840, -0.0173],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0420, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0017, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04403\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 525 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_525/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0840, -0.0173],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0420, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0017, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04767\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 526 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_526/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0173],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0420, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0128, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0017, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04757\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 527 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_527/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0173],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0420, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0017, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04914\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 528 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_528/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0173],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0420, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0017, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04802\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 529 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_529/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0173],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0420, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0017, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04671\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 530 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_530/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0173],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0420, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0017, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04847\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 531 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_531/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0173],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0420, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0017, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04933\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 532 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_532/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0173],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0420, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0017, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04442\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 533 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_533/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0173],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0420, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0017, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04714\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 534 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_534/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0173],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0420, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0017, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04630\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 535 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_535/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0173],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0420, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0017, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04233\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 536 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_536/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0173],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0017, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.05195\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 537 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_537/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0173],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0017, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04960\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 538 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_538/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0173],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0017, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04368\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 539 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_539/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0173],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0017, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04384\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 540 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_540/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0173],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0017, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04598\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 541 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_541/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0173],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0017, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04206\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 542 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_542/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0173],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0017, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04309\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 543 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_543/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0173],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0017, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04538\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 544 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_544/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0017, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04369\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 545 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_545/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0017, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04455\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 546 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_546/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0017, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04613\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 547 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_547/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0017, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04897\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 548 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_548/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0017, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04769\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 549 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_549/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0017, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04002\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 550 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_550/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0017, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04239\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 551 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_551/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0017, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04526\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 552 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_552/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04610\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 553 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_553/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04690\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 554 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_554/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04563\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 555 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_555/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04622\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 556 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_556/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.03712\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 557 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_557/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04226\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 558 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_558/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.05079\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 559 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_559/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04540\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 560 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_560/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04350\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 561 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_561/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04936\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 562 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_562/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04603\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 563 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_563/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.05146\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 564 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_564/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04112\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 565 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_565/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04465\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 566 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_566/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.05167\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 567 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_567/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04357\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 568 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_568/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04746\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 569 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_569/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04573\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 570 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_570/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.05126\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 571 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_571/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.05029\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 572 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_572/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04654\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 573 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_573/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04483\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 574 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_574/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04147\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 575 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_575/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0517,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04452\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 576 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_576/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04560\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 577 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_577/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04690\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 578 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_578/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04528\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 579 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_579/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04477\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 580 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_580/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.05056\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 581 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_581/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04613\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 582 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_582/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.05116\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 583 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_583/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04392\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 584 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_584/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04679\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 585 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_585/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04704\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 586 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_586/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04960\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 587 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_587/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.05171\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 588 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_588/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04846\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 589 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_589/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04583\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 590 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_590/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04417\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 591 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_591/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.03925\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 592 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_592/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04598\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 593 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_593/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04329\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 594 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_594/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04290\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 595 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_595/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04673\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 596 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_596/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04323\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 597 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_597/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0281,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0291, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04106\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 598 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_598/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0281,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04760\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 599 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_599/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0281,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0306,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04588\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 600 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_600/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0281,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04686\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 601 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_601/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0281,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04736\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 602 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_602/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0281,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.05266\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 603 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_603/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0281,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04708\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 604 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_604/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.03845\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 605 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_605/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04963\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 606 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_606/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04464\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 607 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_607/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04627\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 608 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_608/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.05003\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 609 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_609/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.05036\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 610 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_610/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04786\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 611 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_611/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04609\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 612 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_612/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04058\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 613 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_613/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.05178\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 614 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_614/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04414\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 615 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_615/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04942\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 616 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_616/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04776\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 617 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_617/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04326\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 618 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_618/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04493\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 619 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_619/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04613\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 620 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_620/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04772\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 621 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_621/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04527\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 622 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_622/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04399\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 623 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_623/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04946\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 624 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_624/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0055],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04434\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 625 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_625/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04881\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 626 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_626/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04353\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 627 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_627/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.03999\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 628 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_628/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0018,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.05505\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 629 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_629/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0019,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04387\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 630 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_630/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0019,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04779\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 631 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_631/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0019,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0724],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.05022\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 632 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_632/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0019,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0724],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04892\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 633 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_633/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0019,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0724],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04378\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 634 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_634/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0019,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0724],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04492\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 635 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_635/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0019,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0724],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04483\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 636 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_636/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0019,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0724],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04239\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 637 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_637/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0019,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0724],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.05221\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 638 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_638/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0019,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0724],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04495\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 639 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_639/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0019,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0724],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04873\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 640 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_640/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0019,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0724],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.05312\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 641 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_641/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0019,  0.0280,  0.1171,  ...,  0.0419, -0.0582, -0.0724],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.05253\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 642 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_642/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0724],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04424\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 643 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_643/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0724],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04743\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 644 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_644/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0724],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04528\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 645 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_645/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0724],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04940\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 646 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_646/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0724],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04825\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 647 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_647/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0724],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04278\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 648 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_648/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0724],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04913\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 649 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_649/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0724],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04230\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 650 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_650/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0724],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04650\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 651 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_651/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0724],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04484\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 652 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_652/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0724],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04501\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 653 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_653/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0724],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04863\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 654 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_654/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0724],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04530\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 655 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_655/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0724],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04316\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 656 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_656/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0724],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04566\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 657 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_657/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0724],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04811\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 658 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_658/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0724],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04585\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 659 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_659/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0724],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04784\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 660 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_660/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0724],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04357\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 661 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_661/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0724],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04894\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 662 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_662/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0724],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04637\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 663 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_663/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0724],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04273\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 664 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_664/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0724],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04517\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 665 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_665/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0724],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.05066\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 666 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_666/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0724],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04682\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 667 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_667/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0724],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04390\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 668 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_668/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0724],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04498\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 669 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_669/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0724],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04812\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 670 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_670/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0724],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04259\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 671 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_671/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0724],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.05029\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 672 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_672/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0724],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04659\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 673 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_673/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0724],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04745\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 674 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_674/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0724],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04181\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 675 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_675/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0724],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04551\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 676 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_676/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0724],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04645\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 677 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_677/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0724],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04528\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 678 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_678/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04590\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 679 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_679/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04877\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 680 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_680/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.03959\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 681 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_681/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04610\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 682 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_682/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04891\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 683 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_683/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04344\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 684 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_684/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.05112\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 685 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_685/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04498\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 686 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_686/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04723\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 687 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_687/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04757\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 688 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_688/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04516\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 689 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_689/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04159\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 690 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_690/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0319,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04249\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 691 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_691/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0319,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04789\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 692 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_692/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0319,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04728\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 693 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_693/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0319,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04547\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 694 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_694/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0319,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04845\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 695 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_695/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0319,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04397\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 696 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_696/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0319,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04038\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 697 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_697/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0319,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04715\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 698 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_698/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0319,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04238\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 699 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_699/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0319,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04798\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 700 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_700/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0319,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04361\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 701 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_701/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0319,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04193\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 702 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_702/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0319,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04985\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 703 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_703/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0319,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04059\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 704 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_704/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0319,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04483\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 705 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_705/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0319,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04938\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 706 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_706/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0319,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04691\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 707 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_707/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0319,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04619\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 708 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_708/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0319,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04776\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 709 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_709/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0319,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0183,  ...,  0.0008,  0.0094,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04828\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 710 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_710/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0319,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0183,  ...,  0.0008,  0.0094,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04710\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 711 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_711/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0319,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0183,  ...,  0.0008,  0.0094,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04587\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 712 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_712/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0319,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0183,  ...,  0.0008,  0.0094,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04110\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 713 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_713/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0319,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0183,  ...,  0.0008,  0.0094,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04516\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 714 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_714/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0319,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0183,  ...,  0.0008,  0.0094,  0.0012],\n",
      "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04559\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 715 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_715/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0319,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0183,  ...,  0.0008,  0.0094,  0.0012],\n",
      "        [-0.0019, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04123\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 716 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_716/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0319,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0183,  ...,  0.0008,  0.0094,  0.0012],\n",
      "        [-0.0019, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04623\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 717 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_717/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0319,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0183,  ...,  0.0008,  0.0094,  0.0012],\n",
      "        [-0.0019, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04330\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 718 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_718/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0319,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0183,  ...,  0.0008,  0.0094,  0.0012],\n",
      "        [-0.0019, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04424\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 719 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_719/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0319,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0581, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0183,  ...,  0.0008,  0.0094,  0.0012],\n",
      "        [-0.0019, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04684\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 720 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_720/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0319,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0581, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0183,  ...,  0.0008,  0.0094,  0.0012],\n",
      "        [-0.0019, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04092\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 721 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_721/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0319,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0581, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0183,  ...,  0.0008,  0.0094,  0.0012],\n",
      "        [-0.0019, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04604\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 722 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_722/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0319,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0581, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0183,  ...,  0.0008,  0.0094,  0.0012],\n",
      "        [-0.0019, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04665\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 723 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_723/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0319,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0581, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0183,  ...,  0.0008,  0.0094,  0.0012],\n",
      "        [-0.0019, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04404\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 724 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_724/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0319,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0581, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0183,  ...,  0.0008,  0.0094,  0.0012],\n",
      "        [-0.0019, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04816\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 725 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_725/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0319,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0581, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0183,  ...,  0.0008,  0.0094,  0.0012],\n",
      "        [-0.0019, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04859\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 726 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_726/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0319,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0581, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0183,  ...,  0.0008,  0.0094,  0.0012],\n",
      "        [-0.0019, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04517\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 727 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_727/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0319,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0581, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0183,  ...,  0.0008,  0.0094,  0.0012],\n",
      "        [-0.0019, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04862\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 728 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_728/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0319,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0581, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0183,  ...,  0.0008,  0.0094,  0.0012],\n",
      "        [-0.0019, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04316\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 729 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_729/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0319,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0581, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0183,  ...,  0.0008,  0.0094,  0.0012],\n",
      "        [-0.0019, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04348\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 730 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_730/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0319,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0581, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0183,  ...,  0.0008,  0.0094,  0.0012],\n",
      "        [-0.0019, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04372\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 731 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_731/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0319,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0280,  0.1172,  ...,  0.0419, -0.0581, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0183,  ...,  0.0008,  0.0094,  0.0012],\n",
      "        [-0.0019, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04399\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 732 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_732/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0319,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0281,  0.1172,  ...,  0.0419, -0.0581, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0183,  ...,  0.0008,  0.0094,  0.0012],\n",
      "        [-0.0019, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.03919\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 733 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_733/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0319,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0281,  0.1172,  ...,  0.0419, -0.0581, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0183,  ...,  0.0008,  0.0094,  0.0012],\n",
      "        [-0.0019, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04614\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 734 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_734/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0319,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0281,  0.1172,  ...,  0.0419, -0.0581, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0183,  ...,  0.0008,  0.0094,  0.0012],\n",
      "        [-0.0019, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04814\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 735 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_735/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0319,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0281,  0.1172,  ...,  0.0419, -0.0581, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0183,  ...,  0.0008,  0.0094,  0.0012],\n",
      "        [-0.0019, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04997\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 736 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_736/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0319,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0281,  0.1172,  ...,  0.0419, -0.0581, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0183,  ...,  0.0008,  0.0094,  0.0012],\n",
      "        [-0.0019, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04993\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 737 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_737/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0319,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0281,  0.1172,  ...,  0.0419, -0.0581, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0183,  ...,  0.0008,  0.0094,  0.0012],\n",
      "        [-0.0019, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04736\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 738 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_738/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0319,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0281,  0.1172,  ...,  0.0419, -0.0581, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0183,  ...,  0.0008,  0.0094,  0.0012],\n",
      "        [-0.0019, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04572\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 739 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_739/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0319,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0281,  0.1172,  ...,  0.0419, -0.0581, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0183,  ...,  0.0008,  0.0094,  0.0012],\n",
      "        [-0.0019, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04862\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 740 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_740/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0319,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0281,  0.1172,  ...,  0.0419, -0.0581, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0129, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0183,  ...,  0.0008,  0.0094,  0.0012],\n",
      "        [-0.0019, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04440\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 741 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_741/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0319,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0281,  0.1172,  ...,  0.0419, -0.0581, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0130, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0183,  ...,  0.0008,  0.0094,  0.0012],\n",
      "        [-0.0019, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.05335\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 742 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_742/\n",
      "Parameter containing:\n",
      "tensor([[-0.0081,  0.0163,  0.0319,  ..., -0.0021,  0.0839, -0.0171],\n",
      "        [ 0.0019,  0.0281,  0.1172,  ...,  0.0419, -0.0581, -0.0723],\n",
      "        [ 0.0046, -0.0011,  0.0005,  ...,  0.0043,  0.0130, -0.0056],\n",
      "        ...,\n",
      "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
      "        [ 0.0078, -0.0135,  0.0183,  ...,  0.0008,  0.0094,  0.0012],\n",
      "        [-0.0019, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "  Average training loss: 0.04808\n",
      "  Training epcoh took: 0:00:00\n",
      "\n",
      "======== Epoch 743 / 1000 ========\n",
      "Training...\n",
      "Saving model to /content/drive/MyDrive/word_emb/random_all_epoch_743/\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "param_list[0]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wscu4kKRePvk",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1641969712894,
     "user_tz": -540,
     "elapsed": 321,
     "user": {
      "displayName": "‍서수민(대학원생-비즈니스IT전공)",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17389323653104555693"
     }
    },
    "outputId": "c2a989da-1e91-4adf-a7da-f8f5fd736fa4"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0086,  0.0153,  0.0338,  ..., -0.0012,  0.0861, -0.0199],\n",
       "        [ 0.0014,  0.0273,  0.1173,  ...,  0.0422, -0.0582, -0.0720],\n",
       "        [ 0.0035, -0.0004, -0.0004,  ...,  0.0031,  0.0103, -0.0033],\n",
       "        ...,\n",
       "        [-0.0287,  0.0017,  0.0496,  ..., -0.0023,  0.0141,  0.0168],\n",
       "        [ 0.0070, -0.0141,  0.0199,  ...,  0.0017,  0.0113, -0.0008],\n",
       "        [ 0.0005, -0.0276, -0.0281,  ..., -0.0107, -0.0009, -0.0112]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "metadata": {},
     "execution_count": 82
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "name_list[0]"
   ],
   "metadata": {
    "id": "dm6I02qJ0szt",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1641969713812,
     "user_tz": -540,
     "elapsed": 2,
     "user": {
      "displayName": "‍서수민(대학원생-비즈니스IT전공)",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17389323653104555693"
     }
    },
    "outputId": "0edc9fb4-653b-4bab-bd8a-bd88a1d12022"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'bert.embeddings.word_embeddings.weight'"
      ]
     },
     "metadata": {},
     "execution_count": 83
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import BertModel, DistilBertModel\n",
    "f_model = BertModel.from_pretrained(\"/content/drive/MyDrive/word_emb/random_all_epoch_600\")"
   ],
   "metadata": {
    "id": "-DI9tfaHlotU"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "with torch.no_grad():\n",
    "    f_emb= f_model(input_ids[0:1], attention_masks[0:1])\n",
    "    hidden_states = f_emb[2]"
   ],
   "metadata": {
    "id": "Z5wADNAhol5P"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "input_ids[0:1]"
   ],
   "metadata": {
    "id": "MQ7ePTcYpVHQ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print (\"Number of layers:\", len(hidden_states), \"  (initial embeddings + 12 BERT layers)\")\n",
    "layer_i = 0\n",
    "\n",
    "print (\"Number of batches:\", len(hidden_states[layer_i]))\n",
    "batch_i = 0\n",
    "\n",
    "print (\"Number of tokens:\", len(hidden_states[layer_i][batch_i]))\n",
    "token_i = 0\n",
    "\n",
    "print (\"Number of hidden units:\", len(hidden_states[layer_i][batch_i][token_i]))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KbEdK65Tol7W",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1639476843284,
     "user_tz": -540,
     "elapsed": 347,
     "user": {
      "displayName": "‍서수민(대학원생-비즈니스IT전공)",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17389323653104555693"
     }
    },
    "outputId": "e170ea07-e6ed-4b87-c8b0-57cb36c7c307"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of layers: 13   (initial embeddings + 12 BERT layers)\n",
      "Number of batches: 1\n",
      "Number of tokens: 128\n",
      "Number of hidden units: 768\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "f_emb[1]"
   ],
   "metadata": {
    "id": "fS8V6erMb5i9"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "torch.mean(hidden_states[-2][0], dim=0)"
   ],
   "metadata": {
    "id": "_SHc23nNp0Av"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "f_param_list=[]\n",
    "f_name_list=[]\n",
    "for name, param in f_model.named_parameters():\n",
    "  f_param_list.append(param)\n",
    "  f_name_list.append(name)"
   ],
   "metadata": {
    "id": "0pAHI_91kCA5"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "f_param_list[0]"
   ],
   "metadata": {
    "id": "B-tfTfBt1md5",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1639476784725,
     "user_tz": -540,
     "elapsed": 409,
     "user": {
      "displayName": "‍서수민(대학원생-비즈니스IT전공)",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17389323653104555693"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "22c9b244-087c-4852-f32c-9ef03c47b5c2"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0112,  0.0140,  0.0319,  ..., -0.0036,  0.0869, -0.0174],\n",
       "        [ 0.0014,  0.0275,  0.1172,  ...,  0.0425, -0.0585, -0.0722],\n",
       "        [ 0.0061,  0.0009,  0.0012,  ...,  0.0057,  0.0102, -0.0070],\n",
       "        ...,\n",
       "        [ 0.0003, -0.0146, -0.0772,  ...,  0.0907, -0.1730,  0.0090],\n",
       "        [ 0.0343,  0.0100,  0.0036,  ..., -0.0124,  0.0025, -0.0087],\n",
       "        [-0.0022,  0.0037, -0.0062,  ...,  0.0034,  0.0162, -0.0065]],\n",
       "       requires_grad=True)"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "v8zEZwNCvSWK"
   },
   "source": [
    "for name, param in model.named_parameters():\n",
    "\tif 'classifier' not in name: # classifier layer\n",
    "\t\tparam.requires_grad = False"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "BZ2kKGC3jrRK"
   },
   "source": [
    "model.init_weights()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "H2zpdOHWl-Z1"
   },
   "source": [
    "model.named_parameters"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "o2vBpn3hv0i9"
   },
   "source": [
    "for name, param in model.named_parameters():\n",
    "  print(name)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-d7fMHmymKqu"
   },
   "source": [
    "param_list=[]\n",
    "name_list=[]\n",
    "for name, param in model.named_parameters():\n",
    "  param_list.append(param)\n",
    "  name_list.append(name)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "iMBYfhZEmf1N"
   },
   "source": [
    "model.init_weights()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5axUbA6gYil0"
   },
   "source": [
    "name_list[0]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "BWCHdqvRwIha"
   },
   "source": [
    "len(param_list[0])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "OSfZMd9JmMct"
   },
   "source": [
    "name_list[5]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "AP7-WnbHw2Mj",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1641969999820,
     "user_tz": -540,
     "elapsed": 5319,
     "user": {
      "displayName": "‍서수민(대학원생-비즈니스IT전공)",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17389323653104555693"
     }
    },
    "outputId": "8e4db428-7a80-454f-aa47-c7c341f98a9b"
   },
   "source": [
    "from transformers import BertModel, DistilBertModel\n",
    "f_model = BertModel.from_pretrained(\"/content/drive/MyDrive/word_emb/random_all_epoch_600\")\n",
    "f_model.embeddings.word_embeddings"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Embedding(8005, 768, padding_idx=1)"
      ]
     },
     "metadata": {},
     "execution_count": 84
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2muIAA8AxBiY"
   },
   "source": [
    "f_param_list=[]\n",
    "f_name_list=[]\n",
    "for name, param in f_model.named_parameters():\n",
    "  f_param_list.append(param)\n",
    "  f_name_list.append(name)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "znCESmJ-zGK-",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1641970019484,
     "user_tz": -540,
     "elapsed": 336,
     "user": {
      "displayName": "‍서수민(대학원생-비즈니스IT전공)",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17389323653104555693"
     }
    },
    "outputId": "1cfeca2f-da20-41e9-f197-adaee371618e"
   },
   "source": [
    "f_param_list[0]"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0081,  0.0163,  0.0320,  ..., -0.0021,  0.0839, -0.0172],\n",
       "        [ 0.0018,  0.0281,  0.1172,  ...,  0.0419, -0.0582, -0.0723],\n",
       "        [ 0.0045, -0.0011,  0.0005,  ...,  0.0042,  0.0129, -0.0055],\n",
       "        ...,\n",
       "        [-0.0307,  0.0006,  0.0518,  ..., -0.0017,  0.0156,  0.0166],\n",
       "        [ 0.0078, -0.0135,  0.0184,  ...,  0.0008,  0.0095,  0.0011],\n",
       "        [-0.0018, -0.0292, -0.0267,  ..., -0.0094,  0.0006, -0.0133]],\n",
       "       requires_grad=True)"
      ]
     },
     "metadata": {},
     "execution_count": 87
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Dub-Mud_zI1g"
   },
   "source": [
    "import tensorflow as tf\n",
    "from numpy import dot \n",
    "from numpy.linalg import norm \n",
    "import numpy as np\n",
    "\n",
    "# 코사인 유사도를 구하는 함수 \n",
    "def cos_sim(a, b): \n",
    "  return dot(a, b)/(norm(a)*norm(b))\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CVBaFOeTAWqz",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1641970089593,
     "user_tz": -540,
     "elapsed": 8156,
     "user": {
      "displayName": "‍서수민(대학원생-비즈니스IT전공)",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17389323653104555693"
     }
    },
    "outputId": "a54cdcd2-b7c9-4b0f-88ba-d859dcf1a6ff"
   },
   "source": [
    "for num, i in enumerate(range(0, 8004)):\n",
    "  cos=cos_sim(param_list[0][i].detach().cpu().numpy(),f_param_list[0][i].detach().cpu().numpy())\n",
    "  print(num,cos)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001B[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001B[0m\n",
      "3004 0.99977154\n",
      "3005 0.99968356\n",
      "3006 0.99958706\n",
      "3007 0.9996259\n",
      "3008 0.9994348\n",
      "3009 0.99970615\n",
      "3010 0.9995294\n",
      "3011 0.9998649\n",
      "3012 0.99971455\n",
      "3013 0.9998147\n",
      "3014 0.9990761\n",
      "3015 0.9997417\n",
      "3016 0.99931794\n",
      "3017 0.9994746\n",
      "3018 0.9998665\n",
      "3019 0.99965686\n",
      "3020 0.99878573\n",
      "3021 0.99937594\n",
      "3022 0.99974257\n",
      "3023 0.9990803\n",
      "3024 0.9996056\n",
      "3025 0.999511\n",
      "3026 0.99974275\n",
      "3027 0.9995475\n",
      "3028 0.999832\n",
      "3029 0.9994875\n",
      "3030 0.99950886\n",
      "3031 0.9991914\n",
      "3032 0.9994637\n",
      "3033 0.9993948\n",
      "3034 0.99957067\n",
      "3035 0.9995641\n",
      "3036 0.9999347\n",
      "3037 0.99961144\n",
      "3038 0.99979866\n",
      "3039 0.99959666\n",
      "3040 0.9997387\n",
      "3041 0.9997512\n",
      "3042 0.99983335\n",
      "3043 0.9995544\n",
      "3044 0.999616\n",
      "3045 0.9996791\n",
      "3046 0.9996517\n",
      "3047 0.9996813\n",
      "3048 0.99964124\n",
      "3049 0.9991642\n",
      "3050 0.99948\n",
      "3051 0.99987876\n",
      "3052 0.9998118\n",
      "3053 0.9996978\n",
      "3054 0.9996654\n",
      "3055 0.99960005\n",
      "3056 0.9996893\n",
      "3057 0.99957937\n",
      "3058 0.9997975\n",
      "3059 0.9992883\n",
      "3060 0.9994528\n",
      "3061 0.99966884\n",
      "3062 0.9998311\n",
      "3063 0.9997609\n",
      "3064 0.999803\n",
      "3065 0.9994939\n",
      "3066 0.99978507\n",
      "3067 0.9999259\n",
      "3068 0.9997078\n",
      "3069 0.9997207\n",
      "3070 0.9995897\n",
      "3071 0.9994834\n",
      "3072 0.9996562\n",
      "3073 0.9993092\n",
      "3074 0.99971247\n",
      "3075 0.9995984\n",
      "3076 0.99980724\n",
      "3077 0.999753\n",
      "3078 0.9999018\n",
      "3079 0.9994432\n",
      "3080 0.99988157\n",
      "3081 0.9997977\n",
      "3082 0.99983263\n",
      "3083 0.99955523\n",
      "3084 0.99986994\n",
      "3085 0.99973565\n",
      "3086 0.9998466\n",
      "3087 0.99965394\n",
      "3088 0.9996999\n",
      "3089 0.99973357\n",
      "3090 0.9997619\n",
      "3091 0.9997908\n",
      "3092 0.99975884\n",
      "3093 0.9991799\n",
      "3094 0.9998509\n",
      "3095 0.99961185\n",
      "3096 0.99960524\n",
      "3097 0.9994977\n",
      "3098 0.99972486\n",
      "3099 0.999899\n",
      "3100 0.99918973\n",
      "3101 0.9996077\n",
      "3102 0.9997588\n",
      "3103 0.9995202\n",
      "3104 0.9995889\n",
      "3105 0.9997959\n",
      "3106 0.9992463\n",
      "3107 0.9996624\n",
      "3108 0.9993592\n",
      "3109 0.999558\n",
      "3110 0.9999144\n",
      "3111 0.99980384\n",
      "3112 0.9996786\n",
      "3113 0.99982965\n",
      "3114 0.9997596\n",
      "3115 0.99965405\n",
      "3116 0.9995278\n",
      "3117 0.9998016\n",
      "3118 0.99984795\n",
      "3119 0.9998133\n",
      "3120 0.9995411\n",
      "3121 0.999346\n",
      "3122 0.99975026\n",
      "3123 0.99964345\n",
      "3124 0.9997405\n",
      "3125 0.9997603\n",
      "3126 0.9995826\n",
      "3127 0.9998924\n",
      "3128 0.99954563\n",
      "3129 0.99984354\n",
      "3130 0.99977577\n",
      "3131 0.99962133\n",
      "3132 0.9997856\n",
      "3133 0.9997003\n",
      "3134 0.9995726\n",
      "3135 0.99922913\n",
      "3136 0.9992666\n",
      "3137 0.9995645\n",
      "3138 0.99944043\n",
      "3139 0.9995089\n",
      "3140 0.99954915\n",
      "3141 0.99959475\n",
      "3142 0.9997971\n",
      "3143 0.9994219\n",
      "3144 0.99983436\n",
      "3145 0.9998812\n",
      "3146 0.99927634\n",
      "3147 0.999708\n",
      "3148 0.99981433\n",
      "3149 0.99961835\n",
      "3150 0.9997022\n",
      "3151 0.9994792\n",
      "3152 0.9994112\n",
      "3153 0.99929\n",
      "3154 0.9997467\n",
      "3155 0.99954665\n",
      "3156 0.9993152\n",
      "3157 0.99957794\n",
      "3158 0.99982524\n",
      "3159 0.9996439\n",
      "3160 0.99979776\n",
      "3161 0.9997061\n",
      "3162 0.9996942\n",
      "3163 0.9993987\n",
      "3164 0.99985474\n",
      "3165 0.99946433\n",
      "3166 0.99963915\n",
      "3167 0.99993354\n",
      "3168 0.9996265\n",
      "3169 0.9988884\n",
      "3170 0.99913514\n",
      "3171 0.9989064\n",
      "3172 0.9995237\n",
      "3173 0.99952126\n",
      "3174 0.99964947\n",
      "3175 0.9998337\n",
      "3176 0.9992422\n",
      "3177 0.9998972\n",
      "3178 0.9997135\n",
      "3179 0.99985415\n",
      "3180 0.9999273\n",
      "3181 0.9997636\n",
      "3182 0.9997388\n",
      "3183 0.9997488\n",
      "3184 0.9997307\n",
      "3185 0.99988383\n",
      "3186 0.99979603\n",
      "3187 0.998964\n",
      "3188 0.99965197\n",
      "3189 0.9998389\n",
      "3190 0.99970996\n",
      "3191 0.9997668\n",
      "3192 0.9997083\n",
      "3193 0.99966097\n",
      "3194 0.99984187\n",
      "3195 0.999501\n",
      "3196 0.9990514\n",
      "3197 0.9997055\n",
      "3198 0.99968565\n",
      "3199 0.9997331\n",
      "3200 0.9998516\n",
      "3201 0.9994281\n",
      "3202 0.999487\n",
      "3203 0.9994072\n",
      "3204 0.9995264\n",
      "3205 0.9992435\n",
      "3206 0.99947107\n",
      "3207 0.99973553\n",
      "3208 0.99956435\n",
      "3209 0.999379\n",
      "3210 0.99975896\n",
      "3211 0.9996118\n",
      "3212 0.99921566\n",
      "3213 0.9996111\n",
      "3214 0.9997098\n",
      "3215 0.9999106\n",
      "3216 0.9995859\n",
      "3217 0.99958295\n",
      "3218 0.99985707\n",
      "3219 0.9995859\n",
      "3220 0.999727\n",
      "3221 0.9995952\n",
      "3222 0.99966305\n",
      "3223 0.9999122\n",
      "3224 0.99972373\n",
      "3225 0.99971724\n",
      "3226 0.9999007\n",
      "3227 0.999744\n",
      "3228 0.99994445\n",
      "3229 0.9998989\n",
      "3230 0.99964905\n",
      "3231 0.9998394\n",
      "3232 0.99949074\n",
      "3233 0.99980205\n",
      "3234 0.9997203\n",
      "3235 0.99986506\n",
      "3236 0.9997364\n",
      "3237 0.9996725\n",
      "3238 0.9991022\n",
      "3239 0.9995154\n",
      "3240 0.9990372\n",
      "3241 0.99977237\n",
      "3242 0.9994813\n",
      "3243 0.99914694\n",
      "3244 0.99932414\n",
      "3245 0.9997674\n",
      "3246 0.9996007\n",
      "3247 0.9997938\n",
      "3248 0.9998514\n",
      "3249 0.9999703\n",
      "3250 0.9999215\n",
      "3251 0.9996379\n",
      "3252 0.9997681\n",
      "3253 0.9996686\n",
      "3254 0.999773\n",
      "3255 0.9998032\n",
      "3256 0.99968076\n",
      "3257 0.9996398\n",
      "3258 0.9998584\n",
      "3259 0.99949026\n",
      "3260 0.9999265\n",
      "3261 0.99966997\n",
      "3262 0.9994276\n",
      "3263 0.9992841\n",
      "3264 0.9996913\n",
      "3265 0.9996691\n",
      "3266 0.99987113\n",
      "3267 0.99977195\n",
      "3268 0.9997448\n",
      "3269 0.9998681\n",
      "3270 0.9990004\n",
      "3271 0.99921227\n",
      "3272 0.99950004\n",
      "3273 0.9987914\n",
      "3274 0.99953496\n",
      "3275 0.99962175\n",
      "3276 0.9996797\n",
      "3277 0.99992675\n",
      "3278 0.9991873\n",
      "3279 0.99932104\n",
      "3280 0.99933064\n",
      "3281 0.9994983\n",
      "3282 0.9994426\n",
      "3283 0.99968576\n",
      "3284 0.99981105\n",
      "3285 0.99973905\n",
      "3286 0.99944735\n",
      "3287 0.9996949\n",
      "3288 0.99979657\n",
      "3289 0.9998997\n",
      "3290 0.9995669\n",
      "3291 0.9992793\n",
      "3292 0.99963766\n",
      "3293 0.99981344\n",
      "3294 0.99965525\n",
      "3295 0.99983895\n",
      "3296 0.99992687\n",
      "3297 0.9997183\n",
      "3298 0.9997436\n",
      "3299 0.9998153\n",
      "3300 0.9995829\n",
      "3301 0.9997369\n",
      "3302 0.99907017\n",
      "3303 0.9998152\n",
      "3304 0.99992055\n",
      "3305 0.9998643\n",
      "3306 0.9995539\n",
      "3307 0.999472\n",
      "3308 0.99960285\n",
      "3309 0.99938124\n",
      "3310 0.9990823\n",
      "3311 0.9995926\n",
      "3312 0.99943644\n",
      "3313 0.9996466\n",
      "3314 0.99982935\n",
      "3315 0.99993366\n",
      "3316 0.9999472\n",
      "3317 0.9997498\n",
      "3318 0.99952084\n",
      "3319 0.99976087\n",
      "3320 0.9997054\n",
      "3321 0.99932635\n",
      "3322 0.99976736\n",
      "3323 0.9997669\n",
      "3324 0.99954885\n",
      "3325 0.9996304\n",
      "3326 0.99974704\n",
      "3327 0.999721\n",
      "3328 0.9996287\n",
      "3329 0.999568\n",
      "3330 0.99958616\n",
      "3331 0.9996197\n",
      "3332 0.9995709\n",
      "3333 0.9997869\n",
      "3334 0.999732\n",
      "3335 0.999454\n",
      "3336 0.99935687\n",
      "3337 0.9998224\n",
      "3338 0.9997747\n",
      "3339 0.9995641\n",
      "3340 0.99993026\n",
      "3341 0.9997219\n",
      "3342 0.9996928\n",
      "3343 0.9997149\n",
      "3344 0.99935454\n",
      "3345 0.99944687\n",
      "3346 0.99967945\n",
      "3347 0.99983805\n",
      "3348 0.99974877\n",
      "3349 0.999805\n",
      "3350 0.99992645\n",
      "3351 0.99930704\n",
      "3352 0.999782\n",
      "3353 0.99980927\n",
      "3354 0.9994526\n",
      "3355 0.9997309\n",
      "3356 0.99972826\n",
      "3357 0.9992941\n",
      "3358 0.99976695\n",
      "3359 0.99980813\n",
      "3360 0.999435\n",
      "3361 0.9995917\n",
      "3362 0.9996016\n",
      "3363 0.9997779\n",
      "3364 0.9997168\n",
      "3365 0.99955565\n",
      "3366 0.9995433\n",
      "3367 0.9995628\n",
      "3368 0.9997782\n",
      "3369 0.99971247\n",
      "3370 0.9998069\n",
      "3371 0.999582\n",
      "3372 0.99952924\n",
      "3373 0.9996843\n",
      "3374 0.99977744\n",
      "3375 0.99985397\n",
      "3376 0.99963003\n",
      "3377 0.999786\n",
      "3378 0.999208\n",
      "3379 0.9995329\n",
      "3380 0.99965715\n",
      "3381 0.9996794\n",
      "3382 0.99971765\n",
      "3383 0.9997366\n",
      "3384 0.9996661\n",
      "3385 0.9995336\n",
      "3386 0.9997431\n",
      "3387 0.9994537\n",
      "3388 0.99976647\n",
      "3389 0.9998629\n",
      "3390 0.99953866\n",
      "3391 0.9995488\n",
      "3392 0.99967307\n",
      "3393 0.99966973\n",
      "3394 0.9993856\n",
      "3395 0.9998129\n",
      "3396 0.9998475\n",
      "3397 0.99930674\n",
      "3398 0.99955446\n",
      "3399 0.99974704\n",
      "3400 0.9994251\n",
      "3401 0.99990284\n",
      "3402 0.99945116\n",
      "3403 0.99975646\n",
      "3404 0.99940884\n",
      "3405 0.99855506\n",
      "3406 0.99966735\n",
      "3407 0.99844366\n",
      "3408 0.999446\n",
      "3409 0.9990226\n",
      "3410 0.9993789\n",
      "3411 0.9995326\n",
      "3412 0.9995823\n",
      "3413 0.998888\n",
      "3414 0.99895066\n",
      "3415 0.9988542\n",
      "3416 0.99968773\n",
      "3417 0.9989873\n",
      "3418 0.99956524\n",
      "3419 0.999517\n",
      "3420 0.9999519\n",
      "3421 0.99969316\n",
      "3422 0.99947417\n",
      "3423 0.9997539\n",
      "3424 0.999725\n",
      "3425 0.9997506\n",
      "3426 0.9997038\n",
      "3427 0.9996232\n",
      "3428 0.9997789\n",
      "3429 0.99966925\n",
      "3430 0.99955165\n",
      "3431 0.9995827\n",
      "3432 0.9993357\n",
      "3433 0.999653\n",
      "3434 0.9993398\n",
      "3435 0.9995368\n",
      "3436 0.99982494\n",
      "3437 0.9995871\n",
      "3438 0.99911094\n",
      "3439 0.99931824\n",
      "3440 0.9992983\n",
      "3441 0.99969894\n",
      "3442 0.9995598\n",
      "3443 0.99958485\n",
      "3444 0.9996049\n",
      "3445 0.9994929\n",
      "3446 0.9996742\n",
      "3447 0.9998335\n",
      "3448 0.99936223\n",
      "3449 0.9994466\n",
      "3450 0.99945307\n",
      "3451 0.99971753\n",
      "3452 0.9994732\n",
      "3453 0.9997568\n",
      "3454 0.9996852\n",
      "3455 0.9996302\n",
      "3456 0.99954313\n",
      "3457 0.999294\n",
      "3458 0.999686\n",
      "3459 0.99982196\n",
      "3460 0.9995889\n",
      "3461 0.9994883\n",
      "3462 0.9996745\n",
      "3463 0.9996933\n",
      "3464 0.9992805\n",
      "3465 0.99954724\n",
      "3466 0.99986476\n",
      "3467 0.9995817\n",
      "3468 0.99985653\n",
      "3469 0.99953604\n",
      "3470 0.9997167\n",
      "3471 0.999942\n",
      "3472 0.99970007\n",
      "3473 0.99973786\n",
      "3474 0.99979764\n",
      "3475 0.99961907\n",
      "3476 0.9992227\n",
      "3477 0.9998246\n",
      "3478 0.9996477\n",
      "3479 0.9998333\n",
      "3480 0.999556\n",
      "3481 0.9992075\n",
      "3482 0.9998278\n",
      "3483 0.99930793\n",
      "3484 0.9997498\n",
      "3485 0.99915767\n",
      "3486 0.9994771\n",
      "3487 0.9991146\n",
      "3488 0.9995164\n",
      "3489 0.99990827\n",
      "3490 0.9993419\n",
      "3491 0.9996557\n",
      "3492 0.9997568\n",
      "3493 0.9996748\n",
      "3494 0.9996661\n",
      "3495 0.99940157\n",
      "3496 0.9995389\n",
      "3497 0.99896455\n",
      "3498 0.9993339\n",
      "3499 0.9992973\n",
      "3500 0.9998201\n",
      "3501 0.99987364\n",
      "3502 0.9998024\n",
      "3503 0.9998736\n",
      "3504 0.999759\n",
      "3505 0.9996452\n",
      "3506 0.99974334\n",
      "3507 0.99949354\n",
      "3508 0.9998473\n",
      "3509 0.99984425\n",
      "3510 0.9998457\n",
      "3511 0.9995733\n",
      "3512 0.9999209\n",
      "3513 0.99944407\n",
      "3514 0.99988675\n",
      "3515 0.99988544\n",
      "3516 0.9994575\n",
      "3517 0.999086\n",
      "3518 0.9995546\n",
      "3519 0.9990696\n",
      "3520 0.9998767\n",
      "3521 0.99988776\n",
      "3522 0.9996388\n",
      "3523 0.99926203\n",
      "3524 0.9998781\n",
      "3525 0.9994599\n",
      "3526 0.9991717\n",
      "3527 0.999773\n",
      "3528 0.99984145\n",
      "3529 0.9998548\n",
      "3530 0.99989957\n",
      "3531 0.9995085\n",
      "3532 0.9993586\n",
      "3533 0.9997849\n",
      "3534 0.9999684\n",
      "3535 0.99968857\n",
      "3536 0.99960405\n",
      "3537 0.99978495\n",
      "3538 0.9996823\n",
      "3539 0.99982625\n",
      "3540 0.9998639\n",
      "3541 0.9996425\n",
      "3542 0.9994068\n",
      "3543 0.9998883\n",
      "3544 0.9992325\n",
      "3545 0.99976987\n",
      "3546 0.9995092\n",
      "3547 0.99971706\n",
      "3548 0.99970543\n",
      "3549 0.9996502\n",
      "3550 0.99953556\n",
      "3551 0.9993191\n",
      "3552 0.99992245\n",
      "3553 0.99984086\n",
      "3554 0.9995084\n",
      "3555 0.9996332\n",
      "3556 0.9997295\n",
      "3557 0.9990088\n",
      "3558 0.99974185\n",
      "3559 0.99964714\n",
      "3560 0.999781\n",
      "3561 0.9995364\n",
      "3562 0.9991397\n",
      "3563 0.99984455\n",
      "3564 0.9994333\n",
      "3565 0.999769\n",
      "3566 0.9998365\n",
      "3567 0.99941576\n",
      "3568 0.9999121\n",
      "3569 0.9998134\n",
      "3570 0.99957764\n",
      "3571 0.9993007\n",
      "3572 0.9996054\n",
      "3573 0.9996636\n",
      "3574 0.999445\n",
      "3575 0.99977726\n",
      "3576 0.9997477\n",
      "3577 0.99987644\n",
      "3578 0.9998285\n",
      "3579 0.9996401\n",
      "3580 0.99971837\n",
      "3581 0.99950314\n",
      "3582 0.9996433\n",
      "3583 0.9997854\n",
      "3584 0.9997991\n",
      "3585 0.99951124\n",
      "3586 0.9996608\n",
      "3587 0.9992323\n",
      "3588 0.9999528\n",
      "3589 0.9997106\n",
      "3590 0.9997844\n",
      "3591 0.9997111\n",
      "3592 0.9996662\n",
      "3593 0.99973756\n",
      "3594 0.99959946\n",
      "3595 0.9991337\n",
      "3596 0.9997899\n",
      "3597 0.99933267\n",
      "3598 0.9996591\n",
      "3599 0.9993413\n",
      "3600 0.99953926\n",
      "3601 0.9998827\n",
      "3602 0.99960536\n",
      "3603 0.9996799\n",
      "3604 0.99945813\n",
      "3605 0.99980265\n",
      "3606 0.9996965\n",
      "3607 0.9996108\n",
      "3608 0.999909\n",
      "3609 0.9996248\n",
      "3610 0.9996176\n",
      "3611 0.9997885\n",
      "3612 0.99948496\n",
      "3613 0.9999349\n",
      "3614 0.99975884\n",
      "3615 0.9997199\n",
      "3616 0.99993545\n",
      "3617 0.9996467\n",
      "3618 0.99953926\n",
      "3619 0.9993793\n",
      "3620 0.99954027\n",
      "3621 0.9993597\n",
      "3622 0.9998756\n",
      "3623 0.99990356\n",
      "3624 0.99927956\n",
      "3625 0.99955976\n",
      "3626 0.99967515\n",
      "3627 0.99976385\n",
      "3628 0.99949056\n",
      "3629 0.9997591\n",
      "3630 0.9997707\n",
      "3631 0.99919003\n",
      "3632 0.9995771\n",
      "3633 0.9999068\n",
      "3634 0.9997222\n",
      "3635 0.99952203\n",
      "3636 0.99957263\n",
      "3637 0.9998168\n",
      "3638 0.9997079\n",
      "3639 0.9995484\n",
      "3640 0.99981123\n",
      "3641 0.9997994\n",
      "3642 0.9995761\n",
      "3643 0.99947715\n",
      "3644 0.9994733\n",
      "3645 0.999456\n",
      "3646 0.9995825\n",
      "3647 0.99957424\n",
      "3648 0.9998536\n",
      "3649 0.9996398\n",
      "3650 0.9997403\n",
      "3651 0.9998648\n",
      "3652 0.9999157\n",
      "3653 0.99977916\n",
      "3654 0.99964446\n",
      "3655 0.99963397\n",
      "3656 0.9993597\n",
      "3657 0.9998111\n",
      "3658 0.9992465\n",
      "3659 0.9997021\n",
      "3660 0.9997213\n",
      "3661 0.99992687\n",
      "3662 0.9994873\n",
      "3663 0.9998449\n",
      "3664 0.9994391\n",
      "3665 0.99972737\n",
      "3666 0.9996897\n",
      "3667 0.9996373\n",
      "3668 0.9996135\n",
      "3669 0.9988365\n",
      "3670 0.9993426\n",
      "3671 0.99988157\n",
      "3672 0.9998302\n",
      "3673 0.9998598\n",
      "3674 0.9997438\n",
      "3675 0.9997635\n",
      "3676 0.99991286\n",
      "3677 0.9998907\n",
      "3678 0.99922353\n",
      "3679 0.9994343\n",
      "3680 0.9994657\n",
      "3681 0.99929506\n",
      "3682 0.9997589\n",
      "3683 0.999441\n",
      "3684 0.9993065\n",
      "3685 0.9999352\n",
      "3686 0.9998409\n",
      "3687 0.9993674\n",
      "3688 0.99970293\n",
      "3689 0.999584\n",
      "3690 0.9997463\n",
      "3691 0.9996502\n",
      "3692 0.99970573\n",
      "3693 0.99973434\n",
      "3694 0.9997944\n",
      "3695 0.9996421\n",
      "3696 0.9996889\n",
      "3697 0.9995011\n",
      "3698 0.99984926\n",
      "3699 0.99943316\n",
      "3700 0.999455\n",
      "3701 0.99981296\n",
      "3702 0.9996824\n",
      "3703 0.9995518\n",
      "3704 0.99943817\n",
      "3705 0.99977785\n",
      "3706 0.9995787\n",
      "3707 0.99969023\n",
      "3708 0.9994625\n",
      "3709 0.99982154\n",
      "3710 0.9995198\n",
      "3711 0.9995229\n",
      "3712 0.9998135\n",
      "3713 0.99976873\n",
      "3714 0.9990674\n",
      "3715 0.99979484\n",
      "3716 0.99978876\n",
      "3717 0.99974555\n",
      "3718 0.9997285\n",
      "3719 0.9996168\n",
      "3720 0.9995172\n",
      "3721 0.9997338\n",
      "3722 0.99958444\n",
      "3723 0.9997458\n",
      "3724 0.9995845\n",
      "3725 0.99955714\n",
      "3726 0.99975234\n",
      "3727 0.9996546\n",
      "3728 0.99980736\n",
      "3729 0.99975485\n",
      "3730 0.99987733\n",
      "3731 0.99946946\n",
      "3732 0.9989517\n",
      "3733 0.9992078\n",
      "3734 0.99951094\n",
      "3735 0.99947006\n",
      "3736 0.99964446\n",
      "3737 0.9997876\n",
      "3738 0.9998994\n",
      "3739 0.99967813\n",
      "3740 0.99980515\n",
      "3741 0.9997178\n",
      "3742 0.99973816\n",
      "3743 0.9998246\n",
      "3744 0.9995878\n",
      "3745 0.99968404\n",
      "3746 0.99988776\n",
      "3747 0.999908\n",
      "3748 0.99992317\n",
      "3749 0.9998347\n",
      "3750 0.9998465\n",
      "3751 0.9998209\n",
      "3752 0.9992365\n",
      "3753 0.99960625\n",
      "3754 0.9998006\n",
      "3755 0.9997922\n",
      "3756 0.99966085\n",
      "3757 0.99924695\n",
      "3758 0.99945474\n",
      "3759 0.9998641\n",
      "3760 0.99954486\n",
      "3761 0.99967515\n",
      "3762 0.99974453\n",
      "3763 0.99929696\n",
      "3764 0.9996444\n",
      "3765 0.99993265\n",
      "3766 0.99925804\n",
      "3767 0.9996174\n",
      "3768 0.9996061\n",
      "3769 0.9993266\n",
      "3770 0.9998475\n",
      "3771 0.99971855\n",
      "3772 0.9995713\n",
      "3773 0.9997415\n",
      "3774 0.99976355\n",
      "3775 0.99938834\n",
      "3776 0.9997357\n",
      "3777 0.9996474\n",
      "3778 0.99957484\n",
      "3779 0.9996855\n",
      "3780 0.9998307\n",
      "3781 0.9994904\n",
      "3782 0.99968064\n",
      "3783 0.999388\n",
      "3784 0.9998622\n",
      "3785 0.9995712\n",
      "3786 0.99929166\n",
      "3787 0.99934113\n",
      "3788 0.99974155\n",
      "3789 0.9995433\n",
      "3790 0.9992155\n",
      "3791 0.9996338\n",
      "3792 0.9995399\n",
      "3793 0.9995994\n",
      "3794 0.99974\n",
      "3795 0.99954665\n",
      "3796 0.9996107\n",
      "3797 0.99927056\n",
      "3798 0.99918693\n",
      "3799 0.9997344\n",
      "3800 0.9997264\n",
      "3801 0.99972284\n",
      "3802 0.9994453\n",
      "3803 0.9993139\n",
      "3804 0.9998765\n",
      "3805 0.999604\n",
      "3806 0.99990577\n",
      "3807 0.9996757\n",
      "3808 0.99990785\n",
      "3809 0.9993508\n",
      "3810 0.99968874\n",
      "3811 0.99980354\n",
      "3812 0.9995906\n",
      "3813 0.99966574\n",
      "3814 0.9998085\n",
      "3815 0.99988675\n",
      "3816 0.9998987\n",
      "3817 0.99942905\n",
      "3818 0.9995282\n",
      "3819 0.99981934\n",
      "3820 0.99936825\n",
      "3821 0.9997991\n",
      "3822 0.9998586\n",
      "3823 0.99981767\n",
      "3824 0.9997775\n",
      "3825 0.9999573\n",
      "3826 0.99952483\n",
      "3827 0.9996031\n",
      "3828 0.999936\n",
      "3829 0.99943095\n",
      "3830 0.9992862\n",
      "3831 0.9998513\n",
      "3832 0.9998764\n",
      "3833 0.99973273\n",
      "3834 0.99964166\n",
      "3835 0.99966866\n",
      "3836 0.9995775\n",
      "3837 0.99953955\n",
      "3838 0.9996573\n",
      "3839 0.9998063\n",
      "3840 0.9995756\n",
      "3841 0.9998759\n",
      "3842 0.99952334\n",
      "3843 0.99988616\n",
      "3844 0.99993604\n",
      "3845 0.99988693\n",
      "3846 0.999754\n",
      "3847 0.99971867\n",
      "3848 0.9994866\n",
      "3849 0.99969107\n",
      "3850 0.9996797\n",
      "3851 0.9998389\n",
      "3852 0.9997057\n",
      "3853 0.9996908\n",
      "3854 0.9995763\n",
      "3855 0.9996003\n",
      "3856 0.9989509\n",
      "3857 0.9989062\n",
      "3858 0.9996428\n",
      "3859 0.9992006\n",
      "3860 0.9992574\n",
      "3861 0.99937886\n",
      "3862 0.9988306\n",
      "3863 0.99941385\n",
      "3864 0.9995554\n",
      "3865 0.99968326\n",
      "3866 0.9991294\n",
      "3867 0.9993136\n",
      "3868 0.99938226\n",
      "3869 0.99963003\n",
      "3870 0.99957174\n",
      "3871 0.99926734\n",
      "3872 0.9997578\n",
      "3873 0.999284\n",
      "3874 0.99955267\n",
      "3875 0.99942005\n",
      "3876 0.99930066\n",
      "3877 0.99969554\n",
      "3878 0.9985607\n",
      "3879 0.99978435\n",
      "3880 0.9995566\n",
      "3881 0.99974537\n",
      "3882 0.99960876\n",
      "3883 0.9996019\n",
      "3884 0.99957156\n",
      "3885 0.99897313\n",
      "3886 0.99937594\n",
      "3887 0.9997656\n",
      "3888 0.99970496\n",
      "3889 0.9998246\n",
      "3890 0.9998736\n",
      "3891 0.99986625\n",
      "3892 0.9996958\n",
      "3893 0.9996191\n",
      "3894 0.9996644\n",
      "3895 0.99952435\n",
      "3896 0.9996241\n",
      "3897 0.9998108\n",
      "3898 0.9996651\n",
      "3899 0.999603\n",
      "3900 0.99983186\n",
      "3901 0.9997909\n",
      "3902 0.99995446\n",
      "3903 0.9998185\n",
      "3904 0.9998882\n",
      "3905 0.9995316\n",
      "3906 0.9997427\n",
      "3907 0.9997885\n",
      "3908 0.99964064\n",
      "3909 0.99975604\n",
      "3910 0.99961543\n",
      "3911 0.99983513\n",
      "3912 0.99973124\n",
      "3913 0.9998377\n",
      "3914 0.99970347\n",
      "3915 0.999796\n",
      "3916 0.9995938\n",
      "3917 0.9992487\n",
      "3918 0.99931705\n",
      "3919 0.99977005\n",
      "3920 0.99969673\n",
      "3921 0.9996376\n",
      "3922 0.9997885\n",
      "3923 0.9997573\n",
      "3924 0.9998197\n",
      "3925 0.9995655\n",
      "3926 0.9992089\n",
      "3927 0.9995692\n",
      "3928 0.9995702\n",
      "3929 0.9996227\n",
      "3930 0.99936676\n",
      "3931 0.99949443\n",
      "3932 0.999871\n",
      "3933 0.9995521\n",
      "3934 0.99923056\n",
      "3935 0.9997292\n",
      "3936 0.9996297\n",
      "3937 0.9996273\n",
      "3938 0.9996027\n",
      "3939 0.9997856\n",
      "3940 0.9996652\n",
      "3941 0.9996672\n",
      "3942 0.99971676\n",
      "3943 0.9997743\n",
      "3944 0.9998265\n",
      "3945 0.99984866\n",
      "3946 0.99989796\n",
      "3947 0.9995612\n",
      "3948 0.9995748\n",
      "3949 0.9997356\n",
      "3950 0.9996585\n",
      "3951 0.9995909\n",
      "3952 0.99966943\n",
      "3953 0.99958473\n",
      "3954 0.99963343\n",
      "3955 0.999696\n",
      "3956 0.9995136\n",
      "3957 0.99960166\n",
      "3958 0.99973893\n",
      "3959 0.9994471\n",
      "3960 0.9995696\n",
      "3961 0.99963015\n",
      "3962 0.99941313\n",
      "3963 0.99968916\n",
      "3964 0.9996844\n",
      "3965 0.9997644\n",
      "3966 0.9994505\n",
      "3967 0.99970526\n",
      "3968 0.99991053\n",
      "3969 0.99957776\n",
      "3970 0.999492\n",
      "3971 0.99960136\n",
      "3972 0.99979365\n",
      "3973 0.9997732\n",
      "3974 0.99938285\n",
      "3975 0.99943\n",
      "3976 0.99958646\n",
      "3977 0.9995566\n",
      "3978 0.999154\n",
      "3979 0.9998268\n",
      "3980 0.9998836\n",
      "3981 0.99926627\n",
      "3982 0.9995415\n",
      "3983 0.99958855\n",
      "3984 0.9994539\n",
      "3985 0.9994518\n",
      "3986 0.9998686\n",
      "3987 0.99989283\n",
      "3988 0.99977183\n",
      "3989 0.99914855\n",
      "3990 0.99951154\n",
      "3991 0.9994206\n",
      "3992 0.99954444\n",
      "3993 0.999454\n",
      "3994 0.99972737\n",
      "3995 0.9995369\n",
      "3996 0.99924606\n",
      "3997 0.9993259\n",
      "3998 0.999398\n",
      "3999 0.99958324\n",
      "4000 0.9997565\n",
      "4001 0.99982274\n",
      "4002 0.99913734\n",
      "4003 0.9998128\n",
      "4004 0.9995487\n",
      "4005 0.99961257\n",
      "4006 0.9995218\n",
      "4007 0.9993838\n",
      "4008 0.99987996\n",
      "4009 0.9988283\n",
      "4010 0.99931884\n",
      "4011 0.9993963\n",
      "4012 0.99917513\n",
      "4013 0.99931556\n",
      "4014 0.99979925\n",
      "4015 0.9998686\n",
      "4016 0.99962264\n",
      "4017 0.99937356\n",
      "4018 0.99985206\n",
      "4019 0.99969035\n",
      "4020 0.99915\n",
      "4021 0.999283\n",
      "4022 0.9993951\n",
      "4023 0.9996288\n",
      "4024 0.999864\n",
      "4025 0.99883807\n",
      "4026 0.9993325\n",
      "4027 0.9991095\n",
      "4028 0.99896973\n",
      "4029 0.999316\n",
      "4030 0.9993151\n",
      "4031 0.9990267\n",
      "4032 0.9994492\n",
      "4033 0.9997693\n",
      "4034 0.99975693\n",
      "4035 0.999757\n",
      "4036 0.99978495\n",
      "4037 0.99949074\n",
      "4038 0.9996688\n",
      "4039 0.99965626\n",
      "4040 0.99948126\n",
      "4041 0.9998487\n",
      "4042 0.9998548\n",
      "4043 0.9996469\n",
      "4044 0.9998352\n",
      "4045 0.99959975\n",
      "4046 0.9997442\n",
      "4047 0.9998868\n",
      "4048 0.9996373\n",
      "4049 0.99962336\n",
      "4050 0.999569\n",
      "4051 0.99929136\n",
      "4052 0.9997973\n",
      "4053 0.99976516\n",
      "4054 0.99982446\n",
      "4055 0.99964094\n",
      "4056 0.99991405\n",
      "4057 0.9996461\n",
      "4058 0.99974334\n",
      "4059 0.9990871\n",
      "4060 0.99954563\n",
      "4061 0.99895585\n",
      "4062 0.9997965\n",
      "4063 0.9996017\n",
      "4064 0.99968785\n",
      "4065 0.9995601\n",
      "4066 0.99977076\n",
      "4067 0.99981296\n",
      "4068 0.9997043\n",
      "4069 0.9998214\n",
      "4070 0.99988\n",
      "4071 0.9996542\n",
      "4072 0.9995759\n",
      "4073 0.9997138\n",
      "4074 0.9995257\n",
      "4075 0.99953175\n",
      "4076 0.9996805\n",
      "4077 0.99990785\n",
      "4078 0.999427\n",
      "4079 0.9994354\n",
      "4080 0.99983793\n",
      "4081 0.9997432\n",
      "4082 0.9992693\n",
      "4083 0.99955785\n",
      "4084 0.9995041\n",
      "4085 0.9997138\n",
      "4086 0.9996278\n",
      "4087 0.99960345\n",
      "4088 0.99960876\n",
      "4089 0.99968386\n",
      "4090 0.9995424\n",
      "4091 0.99955606\n",
      "4092 0.99970007\n",
      "4093 0.99981517\n",
      "4094 0.99965197\n",
      "4095 0.9997789\n",
      "4096 0.99973476\n",
      "4097 0.9997373\n",
      "4098 0.99978733\n",
      "4099 0.99977064\n",
      "4100 0.9997914\n",
      "4101 0.9994826\n",
      "4102 0.9997199\n",
      "4103 0.9990059\n",
      "4104 0.99916977\n",
      "4105 0.99963903\n",
      "4106 0.99930507\n",
      "4107 0.99985254\n",
      "4108 0.99965674\n",
      "4109 0.9999157\n",
      "4110 0.9997601\n",
      "4111 0.99972653\n",
      "4112 0.99941206\n",
      "4113 0.99982417\n",
      "4114 0.99952996\n",
      "4115 0.9997778\n",
      "4116 0.99913913\n",
      "4117 0.9995496\n",
      "4118 0.9993983\n",
      "4119 0.999305\n",
      "4120 0.9993873\n",
      "4121 0.999372\n",
      "4122 0.99948984\n",
      "4123 0.999638\n",
      "4124 0.9996867\n",
      "4125 0.9998112\n",
      "4126 0.9998193\n",
      "4127 0.9997092\n",
      "4128 0.99946916\n",
      "4129 0.99967253\n",
      "4130 0.9994457\n",
      "4131 0.99950093\n",
      "4132 0.99967265\n",
      "4133 0.9993088\n",
      "4134 0.99950314\n",
      "4135 0.99952316\n",
      "4136 0.9995421\n",
      "4137 0.9997607\n",
      "4138 0.99984264\n",
      "4139 0.9998216\n",
      "4140 0.99968517\n",
      "4141 0.9998043\n",
      "4142 0.99926734\n",
      "4143 0.9997905\n",
      "4144 0.9994564\n",
      "4145 0.99990004\n",
      "4146 0.9998104\n",
      "4147 0.99948776\n",
      "4148 0.99930835\n",
      "4149 0.9997535\n",
      "4150 0.999686\n",
      "4151 0.999684\n",
      "4152 0.9991282\n",
      "4153 0.9997341\n",
      "4154 0.9992353\n",
      "4155 0.99943006\n",
      "4156 0.9996313\n",
      "4157 0.99963886\n",
      "4158 0.99966925\n",
      "4159 0.99965537\n",
      "4160 0.9993926\n",
      "4161 0.9996382\n",
      "4162 0.99946177\n",
      "4163 0.99941456\n",
      "4164 0.99980253\n",
      "4165 0.99988216\n",
      "4166 0.9997862\n",
      "4167 0.99982226\n",
      "4168 0.9996388\n",
      "4169 0.9996109\n",
      "4170 0.99938387\n",
      "4171 0.9993938\n",
      "4172 0.9996694\n",
      "4173 0.9993805\n",
      "4174 0.9996055\n",
      "4175 0.9994743\n",
      "4176 0.9994371\n",
      "4177 0.9994612\n",
      "4178 0.99947286\n",
      "4179 0.9997444\n",
      "4180 0.9990643\n",
      "4181 0.9996404\n",
      "4182 0.99970067\n",
      "4183 0.9996857\n",
      "4184 0.9996318\n",
      "4185 0.9998512\n",
      "4186 0.99979156\n",
      "4187 0.999457\n",
      "4188 0.999571\n",
      "4189 0.9995799\n",
      "4190 0.9997884\n",
      "4191 0.9994588\n",
      "4192 0.9991133\n",
      "4193 0.99950117\n",
      "4194 0.9997286\n",
      "4195 0.999553\n",
      "4196 0.99984884\n",
      "4197 0.9996921\n",
      "4198 0.99966955\n",
      "4199 0.9996425\n",
      "4200 0.9994918\n",
      "4201 0.9992403\n",
      "4202 0.99979424\n",
      "4203 0.9997667\n",
      "4204 0.999292\n",
      "4205 0.99935627\n",
      "4206 0.9991923\n",
      "4207 0.9990308\n",
      "4208 0.99935824\n",
      "4209 0.99982804\n",
      "4210 0.9996452\n",
      "4211 0.99981314\n",
      "4212 0.999463\n",
      "4213 0.9995125\n",
      "4214 0.99964017\n",
      "4215 0.99952304\n",
      "4216 0.99929297\n",
      "4217 0.99985397\n",
      "4218 0.9996086\n",
      "4219 0.9994778\n",
      "4220 0.9993832\n",
      "4221 0.999531\n",
      "4222 0.9998484\n",
      "4223 0.9995117\n",
      "4224 0.99945474\n",
      "4225 0.99919873\n",
      "4226 0.9995638\n",
      "4227 0.99977106\n",
      "4228 0.99969876\n",
      "4229 0.999369\n",
      "4230 0.9996802\n",
      "4231 0.9996561\n",
      "4232 0.9994758\n",
      "4233 0.9995455\n",
      "4234 0.99984306\n",
      "4235 0.9995775\n",
      "4236 0.99941504\n",
      "4237 0.9991699\n",
      "4238 0.9998459\n",
      "4239 0.99973875\n",
      "4240 0.99981534\n",
      "4241 0.9994591\n",
      "4242 0.9994551\n",
      "4243 0.999597\n",
      "4244 0.99987525\n",
      "4245 0.9999414\n",
      "4246 0.9993702\n",
      "4247 0.9997735\n",
      "4248 0.99949944\n",
      "4249 0.99966556\n",
      "4250 0.999241\n",
      "4251 0.9998328\n",
      "4252 0.9996199\n",
      "4253 0.9992975\n",
      "4254 0.99829084\n",
      "4255 0.99928576\n",
      "4256 0.99975383\n",
      "4257 0.9994217\n",
      "4258 0.9998741\n",
      "4259 0.99960244\n",
      "4260 0.9995877\n",
      "4261 0.999562\n",
      "4262 0.9991938\n",
      "4263 0.99989974\n",
      "4264 0.9996175\n",
      "4265 0.99982375\n",
      "4266 0.99951243\n",
      "4267 0.9992619\n",
      "4268 0.99953073\n",
      "4269 0.9996445\n",
      "4270 0.9993181\n",
      "4271 0.9995981\n",
      "4272 0.9990539\n",
      "4273 0.9996919\n",
      "4274 0.998969\n",
      "4275 0.9996419\n",
      "4276 0.999533\n",
      "4277 0.99961114\n",
      "4278 0.9999282\n",
      "4279 0.9997479\n",
      "4280 0.99959683\n",
      "4281 0.9998313\n",
      "4282 0.9996519\n",
      "4283 0.9996701\n",
      "4284 0.99973285\n",
      "4285 0.99980295\n",
      "4286 0.99907666\n",
      "4287 0.9994418\n",
      "4288 0.9991945\n",
      "4289 0.9988232\n",
      "4290 0.9997768\n",
      "4291 0.99957496\n",
      "4292 0.9997926\n",
      "4293 0.99958026\n",
      "4294 0.999384\n",
      "4295 0.9997073\n",
      "4296 0.99974364\n",
      "4297 0.9995441\n",
      "4298 0.9999482\n",
      "4299 0.9998535\n",
      "4300 0.99956614\n",
      "4301 0.9997379\n",
      "4302 0.99954444\n",
      "4303 0.99933016\n",
      "4304 0.999243\n",
      "4305 0.9994934\n",
      "4306 0.9995788\n",
      "4307 0.999731\n",
      "4308 0.99995136\n",
      "4309 0.9998835\n",
      "4310 0.9997092\n",
      "4311 0.999602\n",
      "4312 0.9996165\n",
      "4313 0.99941796\n",
      "4314 0.99978316\n",
      "4315 0.9991922\n",
      "4316 0.99950945\n",
      "4317 0.99991053\n",
      "4318 0.9997509\n",
      "4319 0.99957913\n",
      "4320 0.99962825\n",
      "4321 0.999327\n",
      "4322 0.9995449\n",
      "4323 0.9997125\n",
      "4324 0.9996722\n",
      "4325 0.99968624\n",
      "4326 0.9994622\n",
      "4327 0.99934477\n",
      "4328 0.9998167\n",
      "4329 0.999497\n",
      "4330 0.9991984\n",
      "4331 0.9994613\n",
      "4332 0.99943775\n",
      "4333 0.99964845\n",
      "4334 0.9995884\n",
      "4335 0.99979293\n",
      "4336 0.9995744\n",
      "4337 0.9994184\n",
      "4338 0.99966437\n",
      "4339 0.9996819\n",
      "4340 0.9994226\n",
      "4341 0.99945396\n",
      "4342 0.99971735\n",
      "4343 0.9997115\n",
      "4344 0.9997786\n",
      "4345 0.9994144\n",
      "4346 0.99981767\n",
      "4347 0.99957496\n",
      "4348 0.99968594\n",
      "4349 0.999811\n",
      "4350 0.99967486\n",
      "4351 0.999691\n",
      "4352 0.9995982\n",
      "4353 0.99971807\n",
      "4354 0.9997608\n",
      "4355 0.99970263\n",
      "4356 0.9995998\n",
      "4357 0.99973506\n",
      "4358 0.99955314\n",
      "4359 0.9997271\n",
      "4360 0.9998141\n",
      "4361 0.99981165\n",
      "4362 0.9998611\n",
      "4363 0.9995613\n",
      "4364 0.9996907\n",
      "4365 0.9997166\n",
      "4366 0.99966574\n",
      "4367 0.9998366\n",
      "4368 0.9995762\n",
      "4369 0.9997538\n",
      "4370 0.99934053\n",
      "4371 0.99948204\n",
      "4372 0.9996036\n",
      "4373 0.9995472\n",
      "4374 0.99945325\n",
      "4375 0.9993819\n",
      "4376 0.99925226\n",
      "4377 0.9991041\n",
      "4378 0.99975914\n",
      "4379 0.99970406\n",
      "4380 0.9995177\n",
      "4381 0.9996775\n",
      "4382 0.9998289\n",
      "4383 0.99991685\n",
      "4384 0.99967897\n",
      "4385 0.99972516\n",
      "4386 0.99947774\n",
      "4387 0.99963355\n",
      "4388 0.99943423\n",
      "4389 0.9994357\n",
      "4390 0.99965304\n",
      "4391 0.99987453\n",
      "4392 0.99967825\n",
      "4393 0.9996979\n",
      "4394 0.99888223\n",
      "4395 0.9997921\n",
      "4396 0.99979836\n",
      "4397 0.9998013\n",
      "4398 0.99976563\n",
      "4399 0.9997456\n",
      "4400 0.9997988\n",
      "4401 0.99991673\n",
      "4402 0.99987555\n",
      "4403 0.99950415\n",
      "4404 0.99974716\n",
      "4405 0.9995352\n",
      "4406 0.99981403\n",
      "4407 0.99984175\n",
      "4408 0.99949193\n",
      "4409 0.9995833\n",
      "4410 0.9998889\n",
      "4411 0.9998914\n",
      "4412 0.99992865\n",
      "4413 0.99980944\n",
      "4414 0.9998441\n",
      "4415 0.9997584\n",
      "4416 0.9996634\n",
      "4417 0.99958944\n",
      "4418 0.99980015\n",
      "4419 0.9997817\n",
      "4420 0.9990191\n",
      "4421 0.9995636\n",
      "4422 0.9997271\n",
      "4423 0.99939346\n",
      "4424 0.999656\n",
      "4425 0.9996738\n",
      "4426 0.999448\n",
      "4427 0.9996978\n",
      "4428 0.9996965\n",
      "4429 0.9998449\n",
      "4430 0.9995777\n",
      "4431 0.99975216\n",
      "4432 0.9997647\n",
      "4433 0.99975514\n",
      "4434 0.9995229\n",
      "4435 0.99931926\n",
      "4436 0.99958855\n",
      "4437 0.9997987\n",
      "4438 0.99977356\n",
      "4439 0.99980783\n",
      "4440 0.9996755\n",
      "4441 0.999827\n",
      "4442 0.9993419\n",
      "4443 0.9996046\n",
      "4444 0.9996513\n",
      "4445 0.99988174\n",
      "4446 0.9994066\n",
      "4447 0.9996502\n",
      "4448 0.99991554\n",
      "4449 0.99980414\n",
      "4450 0.99980646\n",
      "4451 0.9993776\n",
      "4452 0.99963075\n",
      "4453 0.99901736\n",
      "4454 0.9993404\n",
      "4455 0.9997102\n",
      "4456 0.9996122\n",
      "4457 0.99981\n",
      "4458 0.9997609\n",
      "4459 0.99997526\n",
      "4460 0.9996444\n",
      "4461 0.9999021\n",
      "4462 0.99993\n",
      "4463 0.99987495\n",
      "4464 0.9997257\n",
      "4465 0.9994206\n",
      "4466 0.999695\n",
      "4467 0.99938387\n",
      "4468 0.99977964\n",
      "4469 0.9998937\n",
      "4470 0.99981874\n",
      "4471 0.9998208\n",
      "4472 0.99988544\n",
      "4473 0.9996419\n",
      "4474 0.99949753\n",
      "4475 0.99965626\n",
      "4476 0.99962634\n",
      "4477 0.999638\n",
      "4478 0.99982035\n",
      "4479 0.999603\n",
      "4480 0.9998447\n",
      "4481 0.99962634\n",
      "4482 0.9998313\n",
      "4483 0.9997754\n",
      "4484 0.9994927\n",
      "4485 0.9995008\n",
      "4486 0.99969536\n",
      "4487 0.9996629\n",
      "4488 0.99985975\n",
      "4489 0.9998679\n",
      "4490 0.9996411\n",
      "4491 0.9996289\n",
      "4492 0.99981964\n",
      "4493 0.9999339\n",
      "4494 0.9997187\n",
      "4495 0.9998738\n",
      "4496 0.99994504\n",
      "4497 0.99933696\n",
      "4498 0.9995152\n",
      "4499 0.9994767\n",
      "4500 0.9997601\n",
      "4501 0.99988854\n",
      "4502 0.99947083\n",
      "4503 0.9995582\n",
      "4504 0.9998442\n",
      "4505 0.9997431\n",
      "4506 0.9996604\n",
      "4507 0.99989563\n",
      "4508 0.9997798\n",
      "4509 0.99922156\n",
      "4510 0.9995806\n",
      "4511 0.9994763\n",
      "4512 0.9996662\n",
      "4513 0.9995878\n",
      "4514 0.9995048\n",
      "4515 0.99947965\n",
      "4516 0.9996084\n",
      "4517 0.999782\n",
      "4518 0.99958974\n",
      "4519 0.99984366\n",
      "4520 0.9997587\n",
      "4521 0.99966836\n",
      "4522 0.9998045\n",
      "4523 0.9996936\n",
      "4524 0.9999596\n",
      "4525 0.9997293\n",
      "4526 0.9998666\n",
      "4527 0.999878\n",
      "4528 0.999617\n",
      "4529 0.9999005\n",
      "4530 0.99987483\n",
      "4531 0.9994629\n",
      "4532 0.999666\n",
      "4533 0.99987054\n",
      "4534 0.9998807\n",
      "4535 0.99985135\n",
      "4536 0.9996899\n",
      "4537 0.99989516\n",
      "4538 0.99944377\n",
      "4539 0.99978757\n",
      "4540 0.99992484\n",
      "4541 0.9990483\n",
      "4542 0.9993918\n",
      "4543 0.99945396\n",
      "4544 0.9998033\n",
      "4545 0.9994927\n",
      "4546 0.9997542\n",
      "4547 0.9996765\n",
      "4548 0.99944687\n",
      "4549 0.99976635\n",
      "4550 0.9996856\n",
      "4551 0.9997968\n",
      "4552 0.9996862\n",
      "4553 0.99949044\n",
      "4554 0.99910307\n",
      "4555 0.99898124\n",
      "4556 0.9994909\n",
      "4557 0.9996096\n",
      "4558 0.99992007\n",
      "4559 0.99966174\n",
      "4560 0.999772\n",
      "4561 0.99969614\n",
      "4562 0.9996103\n",
      "4563 0.9995501\n",
      "4564 0.9996715\n",
      "4565 0.99917525\n",
      "4566 0.99955356\n",
      "4567 0.9993656\n",
      "4568 0.9997723\n",
      "4569 0.999636\n",
      "4570 0.99958205\n",
      "4571 0.9996781\n",
      "4572 0.9994149\n",
      "4573 0.999517\n",
      "4574 0.99955994\n",
      "4575 0.9998864\n",
      "4576 0.9998054\n",
      "4577 0.9992797\n",
      "4578 0.99966\n",
      "4579 0.99967736\n",
      "4580 0.99965626\n",
      "4581 0.99960655\n",
      "4582 0.9995228\n",
      "4583 0.9997223\n",
      "4584 0.99976474\n",
      "4585 0.9994775\n",
      "4586 0.99979657\n",
      "4587 0.99954396\n",
      "4588 0.9998183\n",
      "4589 0.99977434\n",
      "4590 0.9997306\n",
      "4591 0.9997794\n",
      "4592 0.9997801\n",
      "4593 0.99933946\n",
      "4594 0.9997912\n",
      "4595 0.9997165\n",
      "4596 0.9995877\n",
      "4597 0.9995852\n",
      "4598 0.9994074\n",
      "4599 0.99978\n",
      "4600 0.9997735\n",
      "4601 0.99984306\n",
      "4602 0.99951077\n",
      "4603 0.9991019\n",
      "4604 0.99963295\n",
      "4605 0.99960124\n",
      "4606 0.999545\n",
      "4607 0.9997617\n",
      "4608 0.99950224\n",
      "4609 0.99944997\n",
      "4610 0.9996165\n",
      "4611 0.99976856\n",
      "4612 0.9996605\n",
      "4613 0.99978894\n",
      "4614 0.99955094\n",
      "4615 0.99964154\n",
      "4616 0.99976856\n",
      "4617 0.99993604\n",
      "4618 0.99985677\n",
      "4619 0.99975544\n",
      "4620 0.99994016\n",
      "4621 0.9998963\n",
      "4622 0.9998528\n",
      "4623 0.999491\n",
      "4624 0.99978447\n",
      "4625 0.9999572\n",
      "4626 0.999585\n",
      "4627 0.99942756\n",
      "4628 0.9995131\n",
      "4629 0.99929357\n",
      "4630 0.9999001\n",
      "4631 0.99980384\n",
      "4632 0.9994823\n",
      "4633 0.9997527\n",
      "4634 0.99949145\n",
      "4635 0.9994696\n",
      "4636 0.9997394\n",
      "4637 0.99969184\n",
      "4638 0.9996411\n",
      "4639 0.9998925\n",
      "4640 0.9996326\n",
      "4641 0.9994063\n",
      "4642 0.9997772\n",
      "4643 0.99959093\n",
      "4644 0.9992786\n",
      "4645 0.99960476\n",
      "4646 0.9997171\n",
      "4647 0.99964213\n",
      "4648 0.9994551\n",
      "4649 0.99922997\n",
      "4650 0.9996793\n",
      "4651 0.9995791\n",
      "4652 0.9995411\n",
      "4653 0.99960953\n",
      "4654 0.9997395\n",
      "4655 0.9998202\n",
      "4656 0.99972564\n",
      "4657 0.9998426\n",
      "4658 0.99939144\n",
      "4659 0.9996995\n",
      "4660 0.9998257\n",
      "4661 0.99960405\n",
      "4662 0.9997213\n",
      "4663 0.9992347\n",
      "4664 0.99976677\n",
      "4665 0.9994526\n",
      "4666 0.9994182\n",
      "4667 0.9999805\n",
      "4668 0.9997104\n",
      "4669 0.99956036\n",
      "4670 0.9997457\n",
      "4671 0.9996794\n",
      "4672 0.99966466\n",
      "4673 0.99979216\n",
      "4674 0.9994417\n",
      "4675 0.9996488\n",
      "4676 0.99914235\n",
      "4677 0.99906117\n",
      "4678 0.99888396\n",
      "4679 0.999703\n",
      "4680 0.99981517\n",
      "4681 0.99961036\n",
      "4682 0.9992334\n",
      "4683 0.9997349\n",
      "4684 0.9993873\n",
      "4685 0.99966675\n",
      "4686 0.99982804\n",
      "4687 0.9997111\n",
      "4688 0.9996408\n",
      "4689 0.9998149\n",
      "4690 0.9997207\n",
      "4691 0.9998007\n",
      "4692 0.99963146\n",
      "4693 0.9993602\n",
      "4694 0.9997934\n",
      "4695 0.99971956\n",
      "4696 0.99984586\n",
      "4697 0.9998684\n",
      "4698 0.99987245\n",
      "4699 0.99979633\n",
      "4700 0.99991125\n",
      "4701 0.9997927\n",
      "4702 0.9996776\n",
      "4703 0.99987555\n",
      "4704 0.99980044\n",
      "4705 0.99969745\n",
      "4706 0.99978125\n",
      "4707 0.9997418\n",
      "4708 0.9995722\n",
      "4709 0.9995741\n",
      "4710 0.99990565\n",
      "4711 0.9995661\n",
      "4712 0.9997624\n",
      "4713 0.99990016\n",
      "4714 0.99973273\n",
      "4715 0.99970675\n",
      "4716 0.9997191\n",
      "4717 0.9995644\n",
      "4718 0.9994877\n",
      "4719 0.999701\n",
      "4720 0.99986833\n",
      "4721 0.99973816\n",
      "4722 0.99947834\n",
      "4723 0.9998791\n",
      "4724 0.9998248\n",
      "4725 0.99956673\n",
      "4726 0.9996793\n",
      "4727 0.9998599\n",
      "4728 0.9999282\n",
      "4729 0.99978197\n",
      "4730 0.9996844\n",
      "4731 0.9995828\n",
      "4732 0.9996221\n",
      "4733 0.9998222\n",
      "4734 0.9995592\n",
      "4735 0.9996905\n",
      "4736 0.9993844\n",
      "4737 0.9998341\n",
      "4738 0.9996921\n",
      "4739 0.9994658\n",
      "4740 0.9998671\n",
      "4741 0.9996922\n",
      "4742 0.9998674\n",
      "4743 0.99993\n",
      "4744 0.99970824\n",
      "4745 0.999548\n",
      "4746 0.9996009\n",
      "4747 0.9995996\n",
      "4748 0.9995519\n",
      "4749 0.9995444\n",
      "4750 0.9998243\n",
      "4751 0.9998887\n",
      "4752 0.9996173\n",
      "4753 0.9999689\n",
      "4754 0.999627\n",
      "4755 0.99966204\n",
      "4756 0.99962825\n",
      "4757 0.9998453\n",
      "4758 0.99957687\n",
      "4759 0.99970627\n",
      "4760 0.9996445\n",
      "4761 0.99945056\n",
      "4762 0.999812\n",
      "4763 0.9997542\n",
      "4764 0.99974436\n",
      "4765 0.9997743\n",
      "4766 0.999588\n",
      "4767 0.9995121\n",
      "4768 0.99967253\n",
      "4769 0.9997689\n",
      "4770 0.99962676\n",
      "4771 0.9996394\n",
      "4772 0.9998701\n",
      "4773 0.9992137\n",
      "4774 0.999529\n",
      "4775 0.9998272\n",
      "4776 0.9998878\n",
      "4777 0.99960876\n",
      "4778 0.9997018\n",
      "4779 0.99992424\n",
      "4780 0.99978817\n",
      "4781 0.99989843\n",
      "4782 0.99928963\n",
      "4783 0.9996757\n",
      "4784 0.99966496\n",
      "4785 0.9999083\n",
      "4786 0.99967796\n",
      "4787 0.9995173\n",
      "4788 0.9993971\n",
      "4789 0.99917734\n",
      "4790 0.99962753\n",
      "4791 0.9997395\n",
      "4792 0.9996714\n",
      "4793 0.9999512\n",
      "4794 0.99963164\n",
      "4795 0.99964726\n",
      "4796 0.9995113\n",
      "4797 0.9996763\n",
      "4798 0.9996652\n",
      "4799 0.99964315\n",
      "4800 0.99967164\n",
      "4801 0.9990543\n",
      "4802 0.99943167\n",
      "4803 0.9996995\n",
      "4804 0.9993328\n",
      "4805 0.99965096\n",
      "4806 0.99944615\n",
      "4807 0.99871695\n",
      "4808 0.9990167\n",
      "4809 0.9993509\n",
      "4810 0.9995806\n",
      "4811 0.99981296\n",
      "4812 0.9996226\n",
      "4813 0.9996812\n",
      "4814 0.9996404\n",
      "4815 0.99984574\n",
      "4816 0.9997443\n",
      "4817 0.9996911\n",
      "4818 0.999117\n",
      "4819 0.9995156\n",
      "4820 0.9995999\n",
      "4821 0.99933267\n",
      "4822 0.999404\n",
      "4823 0.99959064\n",
      "4824 0.99940383\n",
      "4825 0.9998906\n",
      "4826 0.9997475\n",
      "4827 0.9990261\n",
      "4828 0.99973726\n",
      "4829 0.9997968\n",
      "4830 0.9999587\n",
      "4831 0.9998364\n",
      "4832 0.9997881\n",
      "4833 0.9995428\n",
      "4834 0.99959046\n",
      "4835 0.99963874\n",
      "4836 0.9995235\n",
      "4837 0.9994803\n",
      "4838 0.99938035\n",
      "4839 0.9996158\n",
      "4840 0.9996442\n",
      "4841 0.99917966\n",
      "4842 0.9995661\n",
      "4843 0.9997252\n",
      "4844 0.9992702\n",
      "4845 0.99907047\n",
      "4846 0.9993822\n",
      "4847 0.9999743\n",
      "4848 0.9999127\n",
      "4849 0.99954355\n",
      "4850 0.9996533\n",
      "4851 0.999899\n",
      "4852 0.9994974\n",
      "4853 0.99905944\n",
      "4854 0.999402\n",
      "4855 0.99978524\n",
      "4856 0.99948317\n",
      "4857 0.9994284\n",
      "4858 0.9994328\n",
      "4859 0.99950665\n",
      "4860 0.99963266\n",
      "4861 0.99938726\n",
      "4862 0.9991954\n",
      "4863 0.99973744\n",
      "4864 0.9993045\n",
      "4865 0.9994259\n",
      "4866 0.99906236\n",
      "4867 0.9991326\n",
      "4868 0.9997682\n",
      "4869 0.9998592\n",
      "4870 0.9996881\n",
      "4871 0.9997558\n",
      "4872 0.99978966\n",
      "4873 0.9991652\n",
      "4874 0.9996459\n",
      "4875 0.99914086\n",
      "4876 0.99950296\n",
      "4877 0.9998362\n",
      "4878 0.99988353\n",
      "4879 0.9995432\n",
      "4880 0.99965745\n",
      "4881 0.9992117\n",
      "4882 0.9996878\n",
      "4883 0.99960613\n",
      "4884 0.9997069\n",
      "4885 0.99966145\n",
      "4886 0.9997703\n",
      "4887 0.99963325\n",
      "4888 0.9990832\n",
      "4889 0.99975526\n",
      "4890 0.99959576\n",
      "4891 0.9996426\n",
      "4892 0.9996897\n",
      "4893 0.999587\n",
      "4894 0.9997687\n",
      "4895 0.9999378\n",
      "4896 0.9994472\n",
      "4897 0.99915123\n",
      "4898 0.99949557\n",
      "4899 0.99973387\n",
      "4900 0.9987522\n",
      "4901 0.9996994\n",
      "4902 0.99930924\n",
      "4903 0.99973726\n",
      "4904 0.9996772\n",
      "4905 0.99976605\n",
      "4906 0.99965304\n",
      "4907 0.99962044\n",
      "4908 0.99964976\n",
      "4909 0.9997115\n",
      "4910 0.99973875\n",
      "4911 0.99957526\n",
      "4912 0.9998103\n",
      "4913 0.9997902\n",
      "4914 0.999878\n",
      "4915 0.99960387\n",
      "4916 0.99972844\n",
      "4917 0.9996373\n",
      "4918 0.99972385\n",
      "4919 0.9991493\n",
      "4920 0.9998815\n",
      "4921 0.9993762\n",
      "4922 0.9991965\n",
      "4923 0.9995658\n",
      "4924 0.9996286\n",
      "4925 0.99970174\n",
      "4926 0.99914885\n",
      "4927 0.99958915\n",
      "4928 0.99986863\n",
      "4929 0.99994844\n",
      "4930 0.99902296\n",
      "4931 0.99963385\n",
      "4932 0.99904764\n",
      "4933 0.9992724\n",
      "4934 0.9994627\n",
      "4935 0.9993112\n",
      "4936 0.99930924\n",
      "4937 0.9997945\n",
      "4938 0.9995716\n",
      "4939 0.9993265\n",
      "4940 0.99988765\n",
      "4941 0.9991328\n",
      "4942 0.99991846\n",
      "4943 0.99973464\n",
      "4944 0.9995435\n",
      "4945 0.9994724\n",
      "4946 0.99925524\n",
      "4947 0.9996584\n",
      "4948 0.99986345\n",
      "4949 0.9996778\n",
      "4950 0.9995502\n",
      "4951 0.99962896\n",
      "4952 0.99974114\n",
      "4953 0.99958783\n",
      "4954 0.9993318\n",
      "4955 0.99939513\n",
      "4956 0.99980783\n",
      "4957 0.99971867\n",
      "4958 0.99914885\n",
      "4959 0.99977976\n",
      "4960 0.99948996\n",
      "4961 0.99985623\n",
      "4962 0.9994195\n",
      "4963 0.9997575\n",
      "4964 0.99988645\n",
      "4965 0.9990224\n",
      "4966 0.9996052\n",
      "4967 0.9998827\n",
      "4968 0.99939287\n",
      "4969 0.99985796\n",
      "4970 0.9995499\n",
      "4971 0.9998942\n",
      "4972 0.9996971\n",
      "4973 0.99960464\n",
      "4974 0.9994107\n",
      "4975 0.9992506\n",
      "4976 0.99888635\n",
      "4977 0.99967754\n",
      "4978 0.9997767\n",
      "4979 0.9997547\n",
      "4980 0.9997348\n",
      "4981 0.99970806\n",
      "4982 0.9995591\n",
      "4983 0.9994694\n",
      "4984 0.999592\n",
      "4985 0.9997598\n",
      "4986 0.9996721\n",
      "4987 0.9996871\n",
      "4988 0.9994637\n",
      "4989 0.9993543\n",
      "4990 0.99958265\n",
      "4991 0.9994361\n",
      "4992 0.99978006\n",
      "4993 0.9994147\n",
      "4994 0.99954927\n",
      "4995 0.9994626\n",
      "4996 0.9995886\n",
      "4997 0.99995714\n",
      "4998 0.99956065\n",
      "4999 0.9995782\n",
      "5000 0.9994603\n",
      "5001 0.99980664\n",
      "5002 0.9994451\n",
      "5003 0.9988642\n",
      "5004 0.9995433\n",
      "5005 0.9998248\n",
      "5006 0.99973625\n",
      "5007 0.9996451\n",
      "5008 0.9994926\n",
      "5009 0.9993958\n",
      "5010 0.9991576\n",
      "5011 0.9995416\n",
      "5012 0.9995751\n",
      "5013 0.99930316\n",
      "5014 0.9998295\n",
      "5015 0.9997524\n",
      "5016 0.9991863\n",
      "5017 0.9991306\n",
      "5018 0.99962854\n",
      "5019 0.999132\n",
      "5020 0.99961495\n",
      "5021 0.999425\n",
      "5022 0.9999254\n",
      "5023 0.9997612\n",
      "5024 0.9994822\n",
      "5025 0.9990569\n",
      "5026 0.9992362\n",
      "5027 0.999437\n",
      "5028 0.99889505\n",
      "5029 0.9992813\n",
      "5030 0.9995978\n",
      "5031 0.9996933\n",
      "5032 0.9997526\n",
      "5033 0.99966604\n",
      "5034 0.9999155\n",
      "5035 0.9998249\n",
      "5036 0.9989414\n",
      "5037 0.9994674\n",
      "5038 0.9993658\n",
      "5039 0.9997571\n",
      "5040 0.9996494\n",
      "5041 0.99926233\n",
      "5042 0.99988633\n",
      "5043 0.9995858\n",
      "5044 0.9999752\n",
      "5045 0.99990386\n",
      "5046 0.99986804\n",
      "5047 0.9998239\n",
      "5048 0.99966604\n",
      "5049 0.99970263\n",
      "5050 0.9999043\n",
      "5051 0.9998488\n",
      "5052 0.9998463\n",
      "5053 0.99973613\n",
      "5054 0.9998822\n",
      "5055 0.99976236\n",
      "5056 0.9997819\n",
      "5057 0.9995277\n",
      "5058 0.9997736\n",
      "5059 0.9997656\n",
      "5060 0.9996605\n",
      "5061 0.9996438\n",
      "5062 0.9998069\n",
      "5063 0.99977994\n",
      "5064 0.999333\n",
      "5065 0.9998537\n",
      "5066 0.99947804\n",
      "5067 0.9998899\n",
      "5068 0.99950576\n",
      "5069 0.9999263\n",
      "5070 0.9996482\n",
      "5071 0.9995823\n",
      "5072 0.999894\n",
      "5073 0.99953324\n",
      "5074 0.99972254\n",
      "5075 0.9998926\n",
      "5076 0.99973667\n",
      "5077 0.99963737\n",
      "5078 0.9996228\n",
      "5079 0.99938226\n",
      "5080 0.9993322\n",
      "5081 0.99959606\n",
      "5082 0.9997833\n",
      "5083 0.99950063\n",
      "5084 0.99981976\n",
      "5085 0.9997432\n",
      "5086 0.99924743\n",
      "5087 0.99975026\n",
      "5088 0.9995982\n",
      "5089 0.9991192\n",
      "5090 0.9997127\n",
      "5091 0.9998971\n",
      "5092 0.9991703\n",
      "5093 0.99883026\n",
      "5094 0.9997254\n",
      "5095 0.9997406\n",
      "5096 0.9989536\n",
      "5097 0.999396\n",
      "5098 0.99980015\n",
      "5099 0.999702\n",
      "5100 0.9997355\n",
      "5101 0.99953765\n",
      "5102 0.99958706\n",
      "5103 0.9998631\n",
      "5104 0.9997917\n",
      "5105 0.999333\n",
      "5106 0.9996622\n",
      "5107 0.9995877\n",
      "5108 0.99972326\n",
      "5109 0.9996624\n",
      "5110 0.99921644\n",
      "5111 0.99944776\n",
      "5112 0.99958956\n",
      "5113 0.9998611\n",
      "5114 0.99987876\n",
      "5115 0.9996516\n",
      "5116 0.9997452\n",
      "5117 0.9990087\n",
      "5118 0.99954885\n",
      "5119 0.9993546\n",
      "5120 0.99978614\n",
      "5121 0.99959135\n",
      "5122 0.9995555\n",
      "5123 0.99916524\n",
      "5124 0.99903625\n",
      "5125 0.9991859\n",
      "5126 0.99926347\n",
      "5127 0.9990755\n",
      "5128 0.99977493\n",
      "5129 0.9997118\n",
      "5130 0.9996932\n",
      "5131 0.99955547\n",
      "5132 0.99981564\n",
      "5133 0.9996563\n",
      "5134 0.999383\n",
      "5135 0.99940383\n",
      "5136 0.99957234\n",
      "5137 0.9994718\n",
      "5138 0.99960375\n",
      "5139 0.9996707\n",
      "5140 0.9997189\n",
      "5141 0.99970424\n",
      "5142 0.99969774\n",
      "5143 0.99931324\n",
      "5144 0.99922824\n",
      "5145 0.99885404\n",
      "5146 0.99919206\n",
      "5147 0.99955904\n",
      "5148 0.999577\n",
      "5149 0.9997542\n",
      "5150 0.999936\n",
      "5151 0.9996294\n",
      "5152 0.9996135\n",
      "5153 0.9993882\n",
      "5154 0.999751\n",
      "5155 0.99963707\n",
      "5156 0.99976856\n",
      "5157 0.9998161\n",
      "5158 0.9997175\n",
      "5159 0.9994949\n",
      "5160 0.9997396\n",
      "5161 0.99957216\n",
      "5162 0.9998159\n",
      "5163 0.9994941\n",
      "5164 0.99972796\n",
      "5165 0.99980885\n",
      "5166 0.99973077\n",
      "5167 0.99955505\n",
      "5168 0.9995601\n",
      "5169 0.9998248\n",
      "5170 0.99977213\n",
      "5171 0.9999483\n",
      "5172 0.9999376\n",
      "5173 0.99983627\n",
      "5174 0.99923337\n",
      "5175 0.9996221\n",
      "5176 0.99961555\n",
      "5177 0.99946284\n",
      "5178 0.9993432\n",
      "5179 0.9995175\n",
      "5180 0.99976635\n",
      "5181 0.9998958\n",
      "5182 0.9997176\n",
      "5183 0.9995803\n",
      "5184 0.99969065\n",
      "5185 0.99971384\n",
      "5186 0.9999085\n",
      "5187 0.9996075\n",
      "5188 0.99952465\n",
      "5189 0.9996637\n",
      "5190 0.99962276\n",
      "5191 0.999677\n",
      "5192 0.9996434\n",
      "5193 0.99995005\n",
      "5194 0.99992275\n",
      "5195 0.9994825\n",
      "5196 0.99983954\n",
      "5197 0.9994947\n",
      "5198 0.9999234\n",
      "5199 0.99988824\n",
      "5200 0.9998641\n",
      "5201 0.99972874\n",
      "5202 0.99977386\n",
      "5203 0.9993095\n",
      "5204 0.9997309\n",
      "5205 0.99946123\n",
      "5206 0.9990872\n",
      "5207 0.9993051\n",
      "5208 0.99952614\n",
      "5209 0.99991405\n",
      "5210 0.9994766\n",
      "5211 0.999916\n",
      "5212 0.9997343\n",
      "5213 0.9991563\n",
      "5214 0.9999038\n",
      "5215 0.99925405\n",
      "5216 0.9992561\n",
      "5217 0.99993193\n",
      "5218 0.9998174\n",
      "5219 0.99916136\n",
      "5220 0.9996337\n",
      "5221 0.9995203\n",
      "5222 0.9994613\n",
      "5223 0.99949574\n",
      "5224 0.9999613\n",
      "5225 0.9998755\n",
      "5226 0.9999139\n",
      "5227 0.99985594\n",
      "5228 0.999815\n",
      "5229 0.9999631\n",
      "5230 0.99985\n",
      "5231 0.99979377\n",
      "5232 0.99979615\n",
      "5233 0.9993749\n",
      "5234 0.9995686\n",
      "5235 0.9994446\n",
      "5236 0.9998147\n",
      "5237 0.9997362\n",
      "5238 0.9998607\n",
      "5239 0.99968517\n",
      "5240 0.9994376\n",
      "5241 0.99976015\n",
      "5242 0.99947387\n",
      "5243 0.99995774\n",
      "5244 0.999757\n",
      "5245 0.99985826\n",
      "5246 0.9998718\n",
      "5247 0.99953675\n",
      "5248 0.9994397\n",
      "5249 0.9998802\n",
      "5250 0.99979866\n",
      "5251 0.9998459\n",
      "5252 0.9997322\n",
      "5253 0.9999768\n",
      "5254 0.9996041\n",
      "5255 0.9999239\n",
      "5256 0.9995602\n",
      "5257 0.999898\n",
      "5258 0.99986076\n",
      "5259 0.9998937\n",
      "5260 0.99973124\n",
      "5261 0.99990624\n",
      "5262 0.9999686\n",
      "5263 0.99980086\n",
      "5264 0.99981517\n",
      "5265 0.9997772\n",
      "5266 0.99986696\n",
      "5267 0.99969643\n",
      "5268 0.9994765\n",
      "5269 0.9999795\n",
      "5270 0.9997902\n",
      "5271 0.9996128\n",
      "5272 0.99987036\n",
      "5273 0.99992484\n",
      "5274 0.9998256\n",
      "5275 0.99980575\n",
      "5276 0.99980897\n",
      "5277 0.9996564\n",
      "5278 0.9995633\n",
      "5279 0.99989897\n",
      "5280 0.999823\n",
      "5281 0.9998307\n",
      "5282 0.9996954\n",
      "5283 0.99950564\n",
      "5284 0.9999559\n",
      "5285 0.99959344\n",
      "5286 0.9996379\n",
      "5287 0.9999513\n",
      "5288 0.99985534\n",
      "5289 0.99956673\n",
      "5290 0.9996292\n",
      "5291 0.99949044\n",
      "5292 0.9995998\n",
      "5293 0.999531\n",
      "5294 0.9998683\n",
      "5295 0.9998278\n",
      "5296 0.9998932\n",
      "5297 0.9996131\n",
      "5298 0.99992234\n",
      "5299 0.9995247\n",
      "5300 0.9997001\n",
      "5301 0.9998397\n",
      "5302 0.9994264\n",
      "5303 0.9997267\n",
      "5304 0.9997534\n",
      "5305 0.9995001\n",
      "5306 0.9998872\n",
      "5307 0.999318\n",
      "5308 0.9998896\n",
      "5309 0.99992853\n",
      "5310 0.99990875\n",
      "5311 0.99969864\n",
      "5312 0.9997682\n",
      "5313 0.9997529\n",
      "5314 0.99983716\n",
      "5315 0.99926525\n",
      "5316 0.99971646\n",
      "5317 0.999849\n",
      "5318 0.99995893\n",
      "5319 0.99993086\n",
      "5320 0.9997151\n",
      "5321 0.99894404\n",
      "5322 0.9998668\n",
      "5323 0.9994583\n",
      "5324 0.9996921\n",
      "5325 0.9999327\n",
      "5326 0.999834\n",
      "5327 0.9996813\n",
      "5328 0.9995051\n",
      "5329 0.9999189\n",
      "5330 0.9994158\n",
      "5331 0.9995483\n",
      "5332 0.9991517\n",
      "5333 0.9992173\n",
      "5334 0.99949086\n",
      "5335 0.9989562\n",
      "5336 0.9993648\n",
      "5337 0.9995912\n",
      "5338 0.9993823\n",
      "5339 0.99984145\n",
      "5340 0.9995433\n",
      "5341 0.99978995\n",
      "5342 0.9993399\n",
      "5343 0.99975425\n",
      "5344 0.9999823\n",
      "5345 0.99971503\n",
      "5346 0.9997678\n",
      "5347 0.9995415\n",
      "5348 0.99960816\n",
      "5349 0.9996114\n",
      "5350 0.9996098\n",
      "5351 0.99972224\n",
      "5352 0.9998266\n",
      "5353 0.9998972\n",
      "5354 0.9998365\n",
      "5355 0.9999069\n",
      "5356 0.99971956\n",
      "5357 0.99949324\n",
      "5358 0.9998064\n",
      "5359 0.99980855\n",
      "5360 0.99976134\n",
      "5361 0.99977255\n",
      "5362 0.9996959\n",
      "5363 0.99990946\n",
      "5364 0.9997312\n",
      "5365 0.9998012\n",
      "5366 0.9996573\n",
      "5367 0.999574\n",
      "5368 0.9997687\n",
      "5369 0.9995852\n",
      "5370 0.9998851\n",
      "5371 0.9998501\n",
      "5372 0.9997315\n",
      "5373 0.99991834\n",
      "5374 0.99988276\n",
      "5375 0.9999044\n",
      "5376 0.99971217\n",
      "5377 0.9998885\n",
      "5378 0.99960965\n",
      "5379 0.9998156\n",
      "5380 0.99985677\n",
      "5381 0.9996934\n",
      "5382 0.99968654\n",
      "5383 0.99975836\n",
      "5384 0.9997034\n",
      "5385 0.99983054\n",
      "5386 0.9993393\n",
      "5387 0.99975497\n",
      "5388 0.9990516\n",
      "5389 0.9997058\n",
      "5390 0.9998596\n",
      "5391 0.9997734\n",
      "5392 0.9996542\n",
      "5393 0.9993477\n",
      "5394 0.9997665\n",
      "5395 0.99959254\n",
      "5396 0.9993118\n",
      "5397 0.9998277\n",
      "5398 0.9996628\n",
      "5399 0.9998913\n",
      "5400 0.9994707\n",
      "5401 0.9994028\n",
      "5402 0.99977237\n",
      "5403 0.9999699\n",
      "5404 0.9996812\n",
      "5405 0.99960077\n",
      "5406 0.9994977\n",
      "5407 0.99984205\n",
      "5408 0.99986196\n",
      "5409 0.9999082\n",
      "5410 0.9994886\n",
      "5411 0.99975604\n",
      "5412 0.99948704\n",
      "5413 0.99839073\n",
      "5414 0.99971724\n",
      "5415 0.9996467\n",
      "5416 0.9996709\n",
      "5417 0.99952114\n",
      "5418 0.9998256\n",
      "5419 0.999742\n",
      "5420 0.99992126\n",
      "5421 0.9997754\n",
      "5422 0.99966514\n",
      "5423 0.99961865\n",
      "5424 0.99982846\n",
      "5425 0.9996361\n",
      "5426 0.99973464\n",
      "5427 0.9996192\n",
      "5428 0.9996136\n",
      "5429 0.99940103\n",
      "5430 0.99959254\n",
      "5431 0.99976075\n",
      "5432 0.9998127\n",
      "5433 0.99991614\n",
      "5434 0.999827\n",
      "5435 0.99992925\n",
      "5436 0.9998921\n",
      "5437 0.9996675\n",
      "5438 0.99950385\n",
      "5439 0.9992787\n",
      "5440 0.9996363\n",
      "5441 0.9995089\n",
      "5442 0.9997536\n",
      "5443 0.99988335\n",
      "5444 0.999675\n",
      "5445 0.9999115\n",
      "5446 0.9998279\n",
      "5447 0.9999376\n",
      "5448 0.9998675\n",
      "5449 0.999874\n",
      "5450 0.99976563\n",
      "5451 0.9998164\n",
      "5452 0.9996309\n",
      "5453 0.99964225\n",
      "5454 0.9994671\n",
      "5455 0.9997007\n",
      "5456 0.99991804\n",
      "5457 0.9998518\n",
      "5458 0.99970275\n",
      "5459 0.99972737\n",
      "5460 0.9995493\n",
      "5461 0.99984294\n",
      "5462 0.9992843\n",
      "5463 0.9994458\n",
      "5464 0.999653\n",
      "5465 0.99971676\n",
      "5466 0.99980134\n",
      "5467 0.9997449\n",
      "5468 0.9998196\n",
      "5469 0.9998379\n",
      "5470 0.999817\n",
      "5471 0.9996327\n",
      "5472 0.999904\n",
      "5473 0.9996355\n",
      "5474 0.9996182\n",
      "5475 0.999708\n",
      "5476 0.9991454\n",
      "5477 0.99956286\n",
      "5478 0.9996869\n",
      "5479 0.9998646\n",
      "5480 0.9998376\n",
      "5481 0.99982184\n",
      "5482 0.9993707\n",
      "5483 0.99965036\n",
      "5484 0.9998704\n",
      "5485 0.99967194\n",
      "5486 0.9997325\n",
      "5487 0.9997836\n",
      "5488 0.9995131\n",
      "5489 0.9997736\n",
      "5490 0.99986583\n",
      "5491 0.9995193\n",
      "5492 0.99965686\n",
      "5493 0.99958146\n",
      "5494 0.9996772\n",
      "5495 0.99961984\n",
      "5496 0.9998514\n",
      "5497 0.9999409\n",
      "5498 0.9998424\n",
      "5499 0.9997117\n",
      "5500 0.9998551\n",
      "5501 0.999879\n",
      "5502 0.9996321\n",
      "5503 0.99978405\n",
      "5504 0.99987537\n",
      "5505 0.9998711\n",
      "5506 0.99995756\n",
      "5507 0.9997477\n",
      "5508 0.9994949\n",
      "5509 0.9997699\n",
      "5510 0.9997704\n",
      "5511 0.99978614\n",
      "5512 0.99968696\n",
      "5513 0.99977773\n",
      "5514 0.99990046\n",
      "5515 0.9999229\n",
      "5516 0.9998928\n",
      "5517 0.99995357\n",
      "5518 0.9999776\n",
      "5519 0.9999294\n",
      "5520 0.9998965\n",
      "5521 0.9998891\n",
      "5522 0.9998926\n",
      "5523 0.99982595\n",
      "5524 0.99980277\n",
      "5525 0.99973655\n",
      "5526 0.99956936\n",
      "5527 0.99967796\n",
      "5528 0.9998304\n",
      "5529 0.9999637\n",
      "5530 0.9997764\n",
      "5531 0.9998172\n",
      "5532 0.999548\n",
      "5533 0.9996901\n",
      "5534 0.99938315\n",
      "5535 0.99967027\n",
      "5536 0.99978536\n",
      "5537 0.9998168\n",
      "5538 0.9997442\n",
      "5539 0.9998118\n",
      "5540 0.99960524\n",
      "5541 0.9998276\n",
      "5542 0.9996707\n",
      "5543 0.9997846\n",
      "5544 0.9996275\n",
      "5545 0.9995841\n",
      "5546 0.99981767\n",
      "5547 0.9997418\n",
      "5548 0.9998971\n",
      "5549 0.99986684\n",
      "5550 0.99970454\n",
      "5551 0.99932444\n",
      "5552 0.99988127\n",
      "5553 0.99966794\n",
      "5554 0.9994897\n",
      "5555 0.9996817\n",
      "5556 0.9992269\n",
      "5557 0.99990743\n",
      "5558 0.9998432\n",
      "5559 0.9999014\n",
      "5560 0.99955404\n",
      "5561 0.9997875\n",
      "5562 0.9998084\n",
      "5563 0.9995996\n",
      "5564 0.99960446\n",
      "5565 0.99984884\n",
      "5566 0.9998821\n",
      "5567 0.99980044\n",
      "5568 0.99972427\n",
      "5569 0.9995307\n",
      "5570 0.99970865\n",
      "5571 0.99990815\n",
      "5572 0.9997862\n",
      "5573 0.99985564\n",
      "5574 0.99964374\n",
      "5575 0.99968404\n",
      "5576 0.99976987\n",
      "5577 0.99902534\n",
      "5578 0.9997601\n",
      "5579 0.9994752\n",
      "5580 0.99947816\n",
      "5581 0.9997949\n",
      "5582 0.99977136\n",
      "5583 0.9993834\n",
      "5584 0.99977696\n",
      "5585 0.99985605\n",
      "5586 0.99981916\n",
      "5587 0.99977475\n",
      "5588 0.9998169\n",
      "5589 0.99955213\n",
      "5590 0.9997839\n",
      "5591 0.999757\n",
      "5592 0.9996882\n",
      "5593 0.99988294\n",
      "5594 0.9996244\n",
      "5595 0.99990976\n",
      "5596 0.99966455\n",
      "5597 0.99974424\n",
      "5598 0.9997543\n",
      "5599 0.999762\n",
      "5600 0.99978477\n",
      "5601 0.9998304\n",
      "5602 0.9998386\n",
      "5603 0.99992645\n",
      "5604 0.9997726\n",
      "5605 0.99976885\n",
      "5606 0.99985623\n",
      "5607 0.99987775\n",
      "5608 0.9996933\n",
      "5609 0.9996802\n",
      "5610 0.99977577\n",
      "5611 0.99983877\n",
      "5612 0.9999474\n",
      "5613 0.9997339\n",
      "5614 0.9994031\n",
      "5615 0.9998761\n",
      "5616 0.9999359\n",
      "5617 0.99980587\n",
      "5618 0.9998619\n",
      "5619 0.9995977\n",
      "5620 0.9999045\n",
      "5621 0.9997562\n",
      "5622 0.9996918\n",
      "5623 0.9998763\n",
      "5624 0.9998786\n",
      "5625 0.9999265\n",
      "5626 0.99967766\n",
      "5627 0.9998752\n",
      "5628 0.9997468\n",
      "5629 0.99978846\n",
      "5630 0.999778\n",
      "5631 0.99989396\n",
      "5632 0.99974835\n",
      "5633 0.9998554\n",
      "5634 0.9998074\n",
      "5635 0.999719\n",
      "5636 0.9998362\n",
      "5637 0.9997899\n",
      "5638 0.9999438\n",
      "5639 0.9998154\n",
      "5640 0.9997781\n",
      "5641 0.99987036\n",
      "5642 0.9997977\n",
      "5643 0.9999468\n",
      "5644 0.9992644\n",
      "5645 0.9998505\n",
      "5646 0.99983567\n",
      "5647 0.9996775\n",
      "5648 0.9998669\n",
      "5649 0.99973\n",
      "5650 0.9998299\n",
      "5651 0.9997543\n",
      "5652 0.9997731\n",
      "5653 0.9996595\n",
      "5654 0.99983346\n",
      "5655 0.9997531\n",
      "5656 0.99955094\n",
      "5657 0.9997708\n",
      "5658 0.999844\n",
      "5659 0.9998714\n",
      "5660 0.9994209\n",
      "5661 0.9999094\n",
      "5662 0.999939\n",
      "5663 0.99988025\n",
      "5664 0.9997638\n",
      "5665 0.9995084\n",
      "5666 0.9996734\n",
      "5667 0.9999473\n",
      "5668 0.99978846\n",
      "5669 0.9996445\n",
      "5670 0.99990577\n",
      "5671 0.9998042\n",
      "5672 0.9998054\n",
      "5673 0.99986535\n",
      "5674 0.99956864\n",
      "5675 0.9997462\n",
      "5676 0.9999012\n",
      "5677 0.99945533\n",
      "5678 0.99968094\n",
      "5679 0.9997284\n",
      "5680 0.9998357\n",
      "5681 0.999148\n",
      "5682 0.9997804\n",
      "5683 0.9997565\n",
      "5684 0.999932\n",
      "5685 0.9999775\n",
      "5686 0.99973845\n",
      "5687 0.9997679\n",
      "5688 0.99978477\n",
      "5689 0.9992957\n",
      "5690 0.9997341\n",
      "5691 0.9998781\n",
      "5692 0.99963516\n",
      "5693 0.9997447\n",
      "5694 0.99994177\n",
      "5695 0.99976826\n",
      "5696 0.9998651\n",
      "5697 0.99987954\n",
      "5698 0.99983984\n",
      "5699 0.9999447\n",
      "5700 0.999608\n",
      "5701 0.9998785\n",
      "5702 0.9997614\n",
      "5703 0.99988395\n",
      "5704 0.9997572\n",
      "5705 0.9999615\n",
      "5706 0.9996023\n",
      "5707 0.9998965\n",
      "5708 0.9995539\n",
      "5709 0.99993855\n",
      "5710 0.9998233\n",
      "5711 0.9997238\n",
      "5712 0.99973124\n",
      "5713 0.9995971\n",
      "5714 0.99976\n",
      "5715 0.99982363\n",
      "5716 0.99980366\n",
      "5717 0.999718\n",
      "5718 0.9998812\n",
      "5719 0.99979144\n",
      "5720 0.9998138\n",
      "5721 0.9997719\n",
      "5722 0.9996506\n",
      "5723 0.9992092\n",
      "5724 0.9998449\n",
      "5725 0.99982035\n",
      "5726 0.9997502\n",
      "5727 0.9998757\n",
      "5728 0.99993503\n",
      "5729 0.9997488\n",
      "5730 0.9998831\n",
      "5731 0.99987996\n",
      "5732 0.9995638\n",
      "5733 0.99983644\n",
      "5734 0.9989414\n",
      "5735 0.9996956\n",
      "5736 0.9998586\n",
      "5737 0.99928373\n",
      "5738 0.99959445\n",
      "5739 0.99971336\n",
      "5740 0.9997302\n",
      "5741 0.9999661\n",
      "5742 0.999883\n",
      "5743 0.9995015\n",
      "5744 0.999598\n",
      "5745 0.99972355\n",
      "5746 0.99984944\n",
      "5747 0.99990463\n",
      "5748 0.99990386\n",
      "5749 0.9999242\n",
      "5750 0.9997761\n",
      "5751 0.9998664\n",
      "5752 0.99941516\n",
      "5753 0.9997425\n",
      "5754 0.9995465\n",
      "5755 0.9998106\n",
      "5756 0.999968\n",
      "5757 0.9999302\n",
      "5758 0.99934816\n",
      "5759 0.99981475\n",
      "5760 0.999006\n",
      "5761 0.9993407\n",
      "5762 0.999961\n",
      "5763 0.9997754\n",
      "5764 0.9997557\n",
      "5765 0.9995628\n",
      "5766 0.9995831\n",
      "5767 0.99976236\n",
      "5768 0.9997847\n",
      "5769 0.9994306\n",
      "5770 0.9995467\n",
      "5771 0.9994691\n",
      "5772 0.99942535\n",
      "5773 0.9998211\n",
      "5774 0.99951667\n",
      "5775 0.9997162\n",
      "5776 0.9994379\n",
      "5777 0.99965733\n",
      "5778 0.99998134\n",
      "5779 0.9998572\n",
      "5780 0.9997821\n",
      "5781 0.999893\n",
      "5782 0.9999673\n",
      "5783 0.9997716\n",
      "5784 0.9998058\n",
      "5785 0.9998424\n",
      "5786 0.9998756\n",
      "5787 0.9999066\n",
      "5788 0.999664\n",
      "5789 0.9994043\n",
      "5790 0.99976635\n",
      "5791 0.99982655\n",
      "5792 0.9998557\n",
      "5793 0.99980646\n",
      "5794 0.99974597\n",
      "5795 0.999789\n",
      "5796 0.99943215\n",
      "5797 0.9998016\n",
      "5798 0.99949867\n",
      "5799 0.9989956\n",
      "5800 0.99962556\n",
      "5801 0.9997568\n",
      "5802 0.9999273\n",
      "5803 0.9994916\n",
      "5804 0.9993817\n",
      "5805 0.99986476\n",
      "5806 0.99964565\n",
      "5807 0.9996033\n",
      "5808 0.9993794\n",
      "5809 0.99968857\n",
      "5810 0.9999231\n",
      "5811 0.99984634\n",
      "5812 0.99948275\n",
      "5813 0.9996172\n",
      "5814 0.999758\n",
      "5815 0.9998604\n",
      "5816 0.99951804\n",
      "5817 0.999707\n",
      "5818 0.9996476\n",
      "5819 0.9996523\n",
      "5820 0.99964964\n",
      "5821 0.99977934\n",
      "5822 0.999766\n",
      "5823 0.99981445\n",
      "5824 0.99958163\n",
      "5825 0.99970645\n",
      "5826 0.9997922\n",
      "5827 0.9994253\n",
      "5828 0.99996173\n",
      "5829 0.9996556\n",
      "5830 0.99993247\n",
      "5831 0.99966055\n",
      "5832 0.9997515\n",
      "5833 0.99995446\n",
      "5834 0.99984205\n",
      "5835 0.99982697\n",
      "5836 0.9998567\n",
      "5837 0.99986184\n",
      "5838 0.99987566\n",
      "5839 0.99950206\n",
      "5840 0.99964267\n",
      "5841 0.99972045\n",
      "5842 0.9998606\n",
      "5843 0.99992794\n",
      "5844 0.99950266\n",
      "5845 0.9998069\n",
      "5846 0.9994248\n",
      "5847 0.99983364\n",
      "5848 0.9997336\n",
      "5849 0.9997054\n",
      "5850 0.9995411\n",
      "5851 0.9995997\n",
      "5852 0.9993565\n",
      "5853 0.99992573\n",
      "5854 0.99994886\n",
      "5855 0.99984854\n",
      "5856 0.99988747\n",
      "5857 0.9994004\n",
      "5858 0.9996268\n",
      "5859 0.9996489\n",
      "5860 0.9996259\n",
      "5861 0.9994727\n",
      "5862 0.9995827\n",
      "5863 0.99953055\n",
      "5864 0.99986243\n",
      "5865 0.99972075\n",
      "5866 0.9999255\n",
      "5867 0.9998743\n",
      "5868 0.99988747\n",
      "5869 0.99984694\n",
      "5870 0.9998214\n",
      "5871 0.9998003\n",
      "5872 0.99970293\n",
      "5873 0.99985075\n",
      "5874 0.99956113\n",
      "5875 0.9998497\n",
      "5876 0.9991661\n",
      "5877 0.99976385\n",
      "5878 0.99954283\n",
      "5879 0.9993349\n",
      "5880 0.99915314\n",
      "5881 0.9997069\n",
      "5882 0.99983436\n",
      "5883 0.999554\n",
      "5884 0.9993717\n",
      "5885 0.99942225\n",
      "5886 0.99942416\n",
      "5887 0.99927795\n",
      "5888 0.99971026\n",
      "5889 0.99921465\n",
      "5890 0.99990296\n",
      "5891 0.9993906\n",
      "5892 0.9996259\n",
      "5893 0.999504\n",
      "5894 0.99945235\n",
      "5895 0.99959934\n",
      "5896 0.9994495\n",
      "5897 0.99972534\n",
      "5898 0.99929833\n",
      "5899 0.99962\n",
      "5900 0.99936604\n",
      "5901 0.9996869\n",
      "5902 0.9994053\n",
      "5903 0.9998369\n",
      "5904 0.9997719\n",
      "5905 0.99979264\n",
      "5906 0.99974954\n",
      "5907 0.99981207\n",
      "5908 0.99976736\n",
      "5909 0.9997029\n",
      "5910 0.99983716\n",
      "5911 0.9999184\n",
      "5912 0.9999028\n",
      "5913 0.99956447\n",
      "5914 0.9998479\n",
      "5915 0.9999792\n",
      "5916 0.9996672\n",
      "5917 0.99977964\n",
      "5918 0.9997759\n",
      "5919 0.9998033\n",
      "5920 0.99962175\n",
      "5921 0.9992327\n",
      "5922 0.99961543\n",
      "5923 0.9999384\n",
      "5924 0.9998205\n",
      "5925 0.999949\n",
      "5926 0.9997706\n",
      "5927 0.9996138\n",
      "5928 0.9998641\n",
      "5929 0.99976975\n",
      "5930 0.9998718\n",
      "5931 0.9995848\n",
      "5932 0.9998204\n",
      "5933 0.99983877\n",
      "5934 0.9997292\n",
      "5935 0.99952775\n",
      "5936 0.9997532\n",
      "5937 0.999608\n",
      "5938 0.9995803\n",
      "5939 0.99967587\n",
      "5940 0.99966055\n",
      "5941 0.9995985\n",
      "5942 0.9997787\n",
      "5943 0.9994927\n",
      "5944 0.9997001\n",
      "5945 0.99948204\n",
      "5946 0.9997873\n",
      "5947 0.99949163\n",
      "5948 0.99978024\n",
      "5949 0.99955696\n",
      "5950 0.9996215\n",
      "5951 0.9991513\n",
      "5952 0.9997293\n",
      "5953 0.9997947\n",
      "5954 0.999673\n",
      "5955 0.9998554\n",
      "5956 0.99969864\n",
      "5957 0.99943113\n",
      "5958 0.9997661\n",
      "5959 0.99976593\n",
      "5960 0.99973124\n",
      "5961 0.9998592\n",
      "5962 0.9997111\n",
      "5963 0.9998413\n",
      "5964 0.99991167\n",
      "5965 0.9995954\n",
      "5966 0.99980533\n",
      "5967 0.9998314\n",
      "5968 0.9998682\n",
      "5969 0.99991935\n",
      "5970 0.9994665\n",
      "5971 0.9999634\n",
      "5972 0.99982005\n",
      "5973 0.9996369\n",
      "5974 0.9997356\n",
      "5975 0.99987066\n",
      "5976 0.9997903\n",
      "5977 0.99988866\n",
      "5978 0.9999552\n",
      "5979 0.9999593\n",
      "5980 0.9998795\n",
      "5981 0.99990654\n",
      "5982 0.99989575\n",
      "5983 0.99975896\n",
      "5984 0.9999817\n",
      "5985 0.99967813\n",
      "5986 0.9998525\n",
      "5987 0.9998982\n",
      "5988 0.9998065\n",
      "5989 0.9996537\n",
      "5990 0.99966747\n",
      "5991 0.9997661\n",
      "5992 0.99974334\n",
      "5993 0.99978864\n",
      "5994 0.9998588\n",
      "5995 0.9997931\n",
      "5996 0.9996884\n",
      "5997 0.9998447\n",
      "5998 0.99991065\n",
      "5999 0.9997867\n",
      "6000 0.9992057\n",
      "6001 0.99990696\n",
      "6002 0.9999306\n",
      "6003 0.9995675\n",
      "6004 0.999294\n",
      "6005 0.9997845\n",
      "6006 0.9995659\n",
      "6007 0.9994473\n",
      "6008 0.9998216\n",
      "6009 0.9994458\n",
      "6010 0.99993455\n",
      "6011 0.9992919\n",
      "6012 0.99970335\n",
      "6013 0.9998501\n",
      "6014 0.99913466\n",
      "6015 0.9995615\n",
      "6016 0.9994969\n",
      "6017 0.99955696\n",
      "6018 0.9996932\n",
      "6019 0.9997392\n",
      "6020 0.9996817\n",
      "6021 0.999658\n",
      "6022 0.99978995\n",
      "6023 0.99957263\n",
      "6024 0.9996517\n",
      "6025 0.9999742\n",
      "6026 0.9998596\n",
      "6027 0.9997289\n",
      "6028 0.9997039\n",
      "6029 0.999687\n",
      "6030 0.9997981\n",
      "6031 0.9998537\n",
      "6032 0.9998803\n",
      "6033 0.99982643\n",
      "6034 0.99963176\n",
      "6035 0.99909323\n",
      "6036 0.99924994\n",
      "6037 0.9994133\n",
      "6038 0.9994309\n",
      "6039 0.99953705\n",
      "6040 0.99964726\n",
      "6041 0.9997795\n",
      "6042 0.9997175\n",
      "6043 0.9997294\n",
      "6044 0.9995807\n",
      "6045 0.99974805\n",
      "6046 0.9995686\n",
      "6047 0.9994429\n",
      "6048 0.9996949\n",
      "6049 0.99989885\n",
      "6050 0.99959844\n",
      "6051 0.99983007\n",
      "6052 0.99969536\n",
      "6053 0.9997917\n",
      "6054 0.99923265\n",
      "6055 0.99979323\n",
      "6056 0.9998199\n",
      "6057 0.9996186\n",
      "6058 0.9999017\n",
      "6059 0.9999112\n",
      "6060 0.99938357\n",
      "6061 0.99931604\n",
      "6062 0.99983126\n",
      "6063 0.9997018\n",
      "6064 0.99971855\n",
      "6065 0.9998987\n",
      "6066 0.9998323\n",
      "6067 0.99935216\n",
      "6068 0.99988246\n",
      "6069 0.99957234\n",
      "6070 0.9996767\n",
      "6071 0.9999271\n",
      "6072 0.9997118\n",
      "6073 0.9994878\n",
      "6074 0.99931616\n",
      "6075 0.9997371\n",
      "6076 0.99975026\n",
      "6077 0.9995205\n",
      "6078 0.99968356\n",
      "6079 0.99963665\n",
      "6080 0.999829\n",
      "6081 0.99959636\n",
      "6082 0.9997737\n",
      "6083 0.9998196\n",
      "6084 0.99948084\n",
      "6085 0.99945587\n",
      "6086 0.9999761\n",
      "6087 0.99954885\n",
      "6088 0.9997082\n",
      "6089 0.9996203\n",
      "6090 0.99987996\n",
      "6091 0.9996826\n",
      "6092 0.99993473\n",
      "6093 0.9997389\n",
      "6094 0.9996172\n",
      "6095 0.9996544\n",
      "6096 0.99998593\n",
      "6097 0.9997958\n",
      "6098 0.99974245\n",
      "6099 0.99973726\n",
      "6100 0.99989325\n",
      "6101 0.99994856\n",
      "6102 0.99996775\n",
      "6103 0.99996376\n",
      "6104 0.99922013\n",
      "6105 0.99991816\n",
      "6106 0.99988645\n",
      "6107 0.9994278\n",
      "6108 0.999586\n",
      "6109 0.9999069\n",
      "6110 0.9997692\n",
      "6111 0.9997219\n",
      "6112 0.99985033\n",
      "6113 0.999681\n",
      "6114 0.99991626\n",
      "6115 0.9992638\n",
      "6116 0.9993252\n",
      "6117 0.99976695\n",
      "6118 0.99936897\n",
      "6119 0.9999627\n",
      "6120 0.99989265\n",
      "6121 0.9996507\n",
      "6122 0.99905616\n",
      "6123 0.999867\n",
      "6124 0.99947214\n",
      "6125 0.9996218\n",
      "6126 0.9996563\n",
      "6127 0.99957603\n",
      "6128 0.9999787\n",
      "6129 0.9993876\n",
      "6130 0.9992555\n",
      "6131 0.99955255\n",
      "6132 0.99955016\n",
      "6133 0.99975914\n",
      "6134 0.9993035\n",
      "6135 0.9995924\n",
      "6136 0.9997243\n",
      "6137 0.9994725\n",
      "6138 0.9996937\n",
      "6139 0.9997899\n",
      "6140 0.99987996\n",
      "6141 0.9998344\n",
      "6142 0.99959886\n",
      "6143 0.9997499\n",
      "6144 0.99966294\n",
      "6145 0.999763\n",
      "6146 0.9993783\n",
      "6147 0.99938935\n",
      "6148 0.9995427\n",
      "6149 0.999824\n",
      "6150 0.9998567\n",
      "6151 0.99978346\n",
      "6152 0.99936664\n",
      "6153 0.99983984\n",
      "6154 0.9998851\n",
      "6155 0.9999134\n",
      "6156 0.99980986\n",
      "6157 0.99933624\n",
      "6158 0.99972504\n",
      "6159 0.999861\n",
      "6160 0.99962395\n",
      "6161 0.99979216\n",
      "6162 0.99985987\n",
      "6163 0.99990004\n",
      "6164 0.99973047\n",
      "6165 0.9994609\n",
      "6166 0.99976265\n",
      "6167 0.9998472\n",
      "6168 0.9995474\n",
      "6169 0.9997957\n",
      "6170 0.9994789\n",
      "6171 0.9997372\n",
      "6172 0.999806\n",
      "6173 0.9997114\n",
      "6174 0.999819\n",
      "6175 0.9996724\n",
      "6176 0.9996992\n",
      "6177 0.9999328\n",
      "6178 0.99993056\n",
      "6179 0.9998098\n",
      "6180 0.9997879\n",
      "6181 0.9997547\n",
      "6182 0.99972254\n",
      "6183 0.9996666\n",
      "6184 0.99985063\n",
      "6185 0.9998452\n",
      "6186 0.9996603\n",
      "6187 0.99991775\n",
      "6188 0.9998194\n",
      "6189 0.9999732\n",
      "6190 0.9998328\n",
      "6191 0.99965805\n",
      "6192 0.99974567\n",
      "6193 0.99971545\n",
      "6194 0.99991184\n",
      "6195 0.9998622\n",
      "6196 0.99996424\n",
      "6197 0.99936515\n",
      "6198 0.9995751\n",
      "6199 0.9996102\n",
      "6200 0.99963456\n",
      "6201 0.9992366\n",
      "6202 0.9994865\n",
      "6203 0.99929565\n",
      "6204 0.999143\n",
      "6205 0.99987525\n",
      "6206 0.9997494\n",
      "6207 0.9996977\n",
      "6208 0.99907714\n",
      "6209 0.9995222\n",
      "6210 0.9997825\n",
      "6211 0.9991958\n",
      "6212 0.99995065\n",
      "6213 0.9996132\n",
      "6214 0.9996574\n",
      "6215 0.99983793\n",
      "6216 0.9996832\n",
      "6217 0.9996867\n",
      "6218 0.9993148\n",
      "6219 0.9997915\n",
      "6220 0.99988765\n",
      "6221 0.99954456\n",
      "6222 0.9999085\n",
      "6223 0.9997661\n",
      "6224 0.99960357\n",
      "6225 0.999971\n",
      "6226 0.9999277\n",
      "6227 0.99976367\n",
      "6228 0.99951005\n",
      "6229 0.9998092\n",
      "6230 0.9997335\n",
      "6231 0.9997976\n",
      "6232 0.9998399\n",
      "6233 0.99979824\n",
      "6234 0.9998663\n",
      "6235 0.9999516\n",
      "6236 0.9997016\n",
      "6237 0.99980336\n",
      "6238 0.99939054\n",
      "6239 0.9993976\n",
      "6240 0.99977595\n",
      "6241 0.99978596\n",
      "6242 0.9998715\n",
      "6243 0.99989784\n",
      "6244 0.99975145\n",
      "6245 0.9999183\n",
      "6246 0.99987656\n",
      "6247 0.99965405\n",
      "6248 0.9997807\n",
      "6249 0.9998445\n",
      "6250 0.9996375\n",
      "6251 0.99983037\n",
      "6252 0.99962515\n",
      "6253 0.9998125\n",
      "6254 0.99987644\n",
      "6255 0.9996988\n",
      "6256 0.9995451\n",
      "6257 0.99892086\n",
      "6258 0.99967545\n",
      "6259 0.9993597\n",
      "6260 0.99991053\n",
      "6261 0.99979144\n",
      "6262 0.99963\n",
      "6263 0.9995662\n",
      "6264 0.9992666\n",
      "6265 0.9994014\n",
      "6266 0.9998794\n",
      "6267 0.9997108\n",
      "6268 0.9996849\n",
      "6269 0.9990805\n",
      "6270 0.99958813\n",
      "6271 0.9993524\n",
      "6272 0.9998621\n",
      "6273 0.99951726\n",
      "6274 0.9999232\n",
      "6275 0.99986124\n",
      "6276 0.9997157\n",
      "6277 0.99983424\n",
      "6278 0.9995994\n",
      "6279 0.99989134\n",
      "6280 0.9995003\n",
      "6281 0.9998631\n",
      "6282 0.999624\n",
      "6283 0.99952745\n",
      "6284 0.99982136\n",
      "6285 0.9998479\n",
      "6286 0.99988914\n",
      "6287 0.9996736\n",
      "6288 0.99979424\n",
      "6289 0.99962604\n",
      "6290 0.9996894\n",
      "6291 0.99979645\n",
      "6292 0.99986196\n",
      "6293 0.9998228\n",
      "6294 0.99972993\n",
      "6295 0.9994765\n",
      "6296 0.99984443\n",
      "6297 0.99975914\n",
      "6298 0.99992037\n",
      "6299 0.99988264\n",
      "6300 0.9995187\n",
      "6301 0.99964374\n",
      "6302 0.9998717\n",
      "6303 0.9997838\n",
      "6304 0.9998143\n",
      "6305 0.9997055\n",
      "6306 0.99956644\n",
      "6307 0.9993497\n",
      "6308 0.9998244\n",
      "6309 0.99990207\n",
      "6310 0.9998391\n",
      "6311 0.999444\n",
      "6312 0.9995447\n",
      "6313 0.9996882\n",
      "6314 0.99974525\n",
      "6315 0.9993699\n",
      "6316 0.9995102\n",
      "6317 0.9996273\n",
      "6318 0.9996909\n",
      "6319 0.9998522\n",
      "6320 0.9997236\n",
      "6321 0.9998189\n",
      "6322 0.99972135\n",
      "6323 0.9998016\n",
      "6324 0.9995616\n",
      "6325 0.99977666\n",
      "6326 0.99988526\n",
      "6327 0.9999625\n",
      "6328 0.99937165\n",
      "6329 0.99945146\n",
      "6330 0.9998711\n",
      "6331 0.9996209\n",
      "6332 0.9993083\n",
      "6333 0.999706\n",
      "6334 0.99959373\n",
      "6335 0.99962914\n",
      "6336 0.9995842\n",
      "6337 0.99989873\n",
      "6338 0.9999516\n",
      "6339 0.9997999\n",
      "6340 0.9998359\n",
      "6341 0.9997146\n",
      "6342 0.9998048\n",
      "6343 0.9998764\n",
      "6344 0.99972683\n",
      "6345 0.9995548\n",
      "6346 0.9997326\n",
      "6347 0.99959\n",
      "6348 0.999508\n",
      "6349 0.99983495\n",
      "6350 0.99986905\n",
      "6351 0.99969614\n",
      "6352 0.9998755\n",
      "6353 0.99987143\n",
      "6354 0.9997184\n",
      "6355 0.9997467\n",
      "6356 0.9995539\n",
      "6357 0.99975485\n",
      "6358 0.99978983\n",
      "6359 0.9997667\n",
      "6360 0.99956167\n",
      "6361 0.99966925\n",
      "6362 0.9995494\n",
      "6363 0.99989814\n",
      "6364 0.99953467\n",
      "6365 0.9999301\n",
      "6366 0.99944097\n",
      "6367 0.9994754\n",
      "6368 0.9998886\n",
      "6369 0.99993986\n",
      "6370 0.99968195\n",
      "6371 0.99986607\n",
      "6372 0.99978465\n",
      "6373 0.9998416\n",
      "6374 0.9994379\n",
      "6375 0.999738\n",
      "6376 0.9998281\n",
      "6377 0.9996862\n",
      "6378 0.9997176\n",
      "6379 0.9997421\n",
      "6380 0.9995777\n",
      "6381 0.9996718\n",
      "6382 0.99976003\n",
      "6383 0.99945045\n",
      "6384 0.99976796\n",
      "6385 0.9996925\n",
      "6386 0.9995125\n",
      "6387 0.9998183\n",
      "6388 0.9998076\n",
      "6389 0.9997359\n",
      "6390 0.9999139\n",
      "6391 0.99972403\n",
      "6392 0.99964076\n",
      "6393 0.9996766\n",
      "6394 0.9997548\n",
      "6395 0.9994239\n",
      "6396 0.9996592\n",
      "6397 0.9998963\n",
      "6398 0.99969465\n",
      "6399 0.9998019\n",
      "6400 0.9996171\n",
      "6401 0.9998006\n",
      "6402 0.9998111\n",
      "6403 0.99993885\n",
      "6404 0.99857855\n",
      "6405 0.99936986\n",
      "6406 0.9995393\n",
      "6407 0.99973977\n",
      "6408 0.9999896\n",
      "6409 0.9998158\n",
      "6410 0.9997855\n",
      "6411 0.9992478\n",
      "6412 0.9996492\n",
      "6413 0.9998534\n",
      "6414 0.9994555\n",
      "6415 0.9998085\n",
      "6416 0.9996943\n",
      "6417 0.99980116\n",
      "6418 0.9995108\n",
      "6419 0.9996274\n",
      "6420 0.9997656\n",
      "6421 0.9993508\n",
      "6422 0.9992958\n",
      "6423 0.9998515\n",
      "6424 0.9995744\n",
      "6425 0.9998825\n",
      "6426 0.9994802\n",
      "6427 0.99991596\n",
      "6428 0.999832\n",
      "6429 0.99961704\n",
      "6430 0.9999249\n",
      "6431 0.9994437\n",
      "6432 0.9996949\n",
      "6433 0.9997139\n",
      "6434 0.9994631\n",
      "6435 0.999669\n",
      "6436 0.999757\n",
      "6437 0.99970603\n",
      "6438 0.99980223\n",
      "6439 0.99992067\n",
      "6440 0.99967444\n",
      "6441 0.9997242\n",
      "6442 0.99989974\n",
      "6443 0.99986124\n",
      "6444 0.99993956\n",
      "6445 0.9994213\n",
      "6446 0.99950725\n",
      "6447 0.9993882\n",
      "6448 0.9993999\n",
      "6449 0.9995347\n",
      "6450 0.9992031\n",
      "6451 0.9997514\n",
      "6452 0.99965835\n",
      "6453 0.9999783\n",
      "6454 0.9998103\n",
      "6455 0.99964607\n",
      "6456 0.99940646\n",
      "6457 0.9999652\n",
      "6458 0.999762\n",
      "6459 0.99959147\n",
      "6460 0.99982536\n",
      "6461 0.999944\n",
      "6462 0.9997749\n",
      "6463 0.99968857\n",
      "6464 0.99993086\n",
      "6465 0.99960196\n",
      "6466 0.9998576\n",
      "6467 0.99996054\n",
      "6468 0.9998593\n",
      "6469 0.99971974\n",
      "6470 0.999868\n",
      "6471 0.99943966\n",
      "6472 0.9997473\n",
      "6473 0.9999122\n",
      "6474 0.99952424\n",
      "6475 0.99934804\n",
      "6476 0.99982095\n",
      "6477 0.99981165\n",
      "6478 0.9998818\n",
      "6479 0.9999153\n",
      "6480 0.99986285\n",
      "6481 0.99988\n",
      "6482 0.99993104\n",
      "6483 0.9999664\n",
      "6484 0.99959713\n",
      "6485 0.99970704\n",
      "6486 0.9998084\n",
      "6487 0.9994657\n",
      "6488 0.9997207\n",
      "6489 0.9995861\n",
      "6490 0.99976814\n",
      "6491 0.99991494\n",
      "6492 0.99990153\n",
      "6493 0.9996862\n",
      "6494 0.999818\n",
      "6495 0.99953765\n",
      "6496 0.99978125\n",
      "6497 0.99980557\n",
      "6498 0.9997971\n",
      "6499 0.99978983\n",
      "6500 0.9998064\n",
      "6501 0.99995196\n",
      "6502 0.99994326\n",
      "6503 0.9994774\n",
      "6504 0.9997511\n",
      "6505 0.99949825\n",
      "6506 0.99954975\n",
      "6507 0.9999639\n",
      "6508 0.9998306\n",
      "6509 0.9997616\n",
      "6510 0.9996918\n",
      "6511 0.99982554\n",
      "6512 0.99945265\n",
      "6513 0.9995905\n",
      "6514 0.99984205\n",
      "6515 0.9999553\n",
      "6516 0.9997584\n",
      "6517 0.9994519\n",
      "6518 0.99965584\n",
      "6519 0.9997612\n",
      "6520 0.99984586\n",
      "6521 0.99991506\n",
      "6522 0.9998833\n",
      "6523 0.9998631\n",
      "6524 0.9997895\n",
      "6525 0.99996144\n",
      "6526 0.9999259\n",
      "6527 0.99970007\n",
      "6528 0.9995567\n",
      "6529 0.9998002\n",
      "6530 0.9996011\n",
      "6531 0.9997738\n",
      "6532 0.99972093\n",
      "6533 0.9996129\n",
      "6534 0.9993847\n",
      "6535 0.999825\n",
      "6536 0.99962705\n",
      "6537 0.99984336\n",
      "6538 0.99946\n",
      "6539 0.9996319\n",
      "6540 0.9999677\n",
      "6541 0.9995898\n",
      "6542 0.9998888\n",
      "6543 0.9999785\n",
      "6544 0.99952567\n",
      "6545 0.9997271\n",
      "6546 0.9995283\n",
      "6547 0.9999019\n",
      "6548 0.999949\n",
      "6549 0.9993991\n",
      "6550 0.9999269\n",
      "6551 0.99970216\n",
      "6552 0.9998829\n",
      "6553 0.9997161\n",
      "6554 0.9998671\n",
      "6555 0.99920356\n",
      "6556 0.9996171\n",
      "6557 0.9999254\n",
      "6558 0.9997746\n",
      "6559 0.9997838\n",
      "6560 0.99934083\n",
      "6561 0.99989015\n",
      "6562 0.9994974\n",
      "6563 0.99985147\n",
      "6564 0.9998435\n",
      "6565 0.9999513\n",
      "6566 0.9997657\n",
      "6567 0.9996697\n",
      "6568 0.99953115\n",
      "6569 0.9997248\n",
      "6570 0.9997159\n",
      "6571 0.99939185\n",
      "6572 0.9996927\n",
      "6573 0.9995759\n",
      "6574 0.99977744\n",
      "6575 0.9996022\n",
      "6576 0.999562\n",
      "6577 0.9995655\n",
      "6578 0.99969864\n",
      "6579 0.99952716\n",
      "6580 0.99935573\n",
      "6581 0.9997263\n",
      "6582 0.99990535\n",
      "6583 0.99988174\n",
      "6584 0.9996314\n",
      "6585 0.9998017\n",
      "6586 0.9995507\n",
      "6587 0.9998001\n",
      "6588 0.9999452\n",
      "6589 0.9999097\n",
      "6590 0.999486\n",
      "6591 0.9999471\n",
      "6592 0.99989265\n",
      "6593 0.99972016\n",
      "6594 0.9995945\n",
      "6595 0.99988246\n",
      "6596 0.9998333\n",
      "6597 0.9997782\n",
      "6598 0.99934417\n",
      "6599 0.99988985\n",
      "6600 0.9998727\n",
      "6601 0.9996196\n",
      "6602 0.9995492\n",
      "6603 0.9999437\n",
      "6604 0.99963117\n",
      "6605 0.99995273\n",
      "6606 0.9997728\n",
      "6607 0.9998669\n",
      "6608 0.9995746\n",
      "6609 0.99963033\n",
      "6610 0.9999056\n",
      "6611 0.9997873\n",
      "6612 0.99990064\n",
      "6613 0.99968636\n",
      "6614 0.9997843\n",
      "6615 0.99980724\n",
      "6616 0.9997712\n",
      "6617 0.99978495\n",
      "6618 0.999548\n",
      "6619 0.9997809\n",
      "6620 0.99981785\n",
      "6621 0.9990649\n",
      "6622 0.999963\n",
      "6623 0.9997757\n",
      "6624 0.9999134\n",
      "6625 0.9996463\n",
      "6626 0.99979454\n",
      "6627 0.99962986\n",
      "6628 0.99978477\n",
      "6629 0.99974656\n",
      "6630 0.9998222\n",
      "6631 0.999844\n",
      "6632 0.9994693\n",
      "6633 0.99995154\n",
      "6634 0.9998333\n",
      "6635 0.9997042\n",
      "6636 0.99993217\n",
      "6637 0.9998084\n",
      "6638 0.9996836\n",
      "6639 0.99941564\n",
      "6640 0.9995916\n",
      "6641 0.99981666\n",
      "6642 0.9996265\n",
      "6643 0.99983156\n",
      "6644 0.9997156\n",
      "6645 0.99981606\n",
      "6646 0.9999479\n",
      "6647 0.9996634\n",
      "6648 0.9997048\n",
      "6649 0.9999777\n",
      "6650 0.99968934\n",
      "6651 0.99950695\n",
      "6652 0.99992716\n",
      "6653 0.9995098\n",
      "6654 0.9999055\n",
      "6655 0.9997299\n",
      "6656 0.99992603\n",
      "6657 0.9999053\n",
      "6658 0.99970335\n",
      "6659 0.99974704\n",
      "6660 0.9998428\n",
      "6661 0.9998795\n",
      "6662 0.9999392\n",
      "6663 0.9994863\n",
      "6664 0.99968946\n",
      "6665 0.99980706\n",
      "6666 0.99967176\n",
      "6667 0.9997079\n",
      "6668 0.99968743\n",
      "6669 0.9993515\n",
      "6670 0.9998153\n",
      "6671 0.9995257\n",
      "6672 0.9998017\n",
      "6673 0.99964076\n",
      "6674 0.99995565\n",
      "6675 0.9992978\n",
      "6676 0.9997671\n",
      "6677 0.9999027\n",
      "6678 0.9998268\n",
      "6679 0.99971086\n",
      "6680 0.99956805\n",
      "6681 0.9998913\n",
      "6682 0.99988556\n",
      "6683 0.9998719\n",
      "6684 0.9992562\n",
      "6685 0.9998589\n",
      "6686 0.99969685\n",
      "6687 0.99976134\n",
      "6688 0.9998305\n",
      "6689 0.99975526\n",
      "6690 0.9995574\n",
      "6691 0.9996432\n",
      "6692 0.9999782\n",
      "6693 0.99980485\n",
      "6694 0.9994481\n",
      "6695 0.99951935\n",
      "6696 0.9994218\n",
      "6697 0.9998361\n",
      "6698 0.99993604\n",
      "6699 0.9997446\n",
      "6700 0.9995068\n",
      "6701 0.9995625\n",
      "6702 0.99987775\n",
      "6703 0.9996194\n",
      "6704 0.99991775\n",
      "6705 0.9995897\n",
      "6706 0.99947196\n",
      "6707 0.99982077\n",
      "6708 0.9998437\n",
      "6709 0.9998914\n",
      "6710 0.9996831\n",
      "6711 0.9997298\n",
      "6712 0.9995133\n",
      "6713 0.9996396\n",
      "6714 0.99947846\n",
      "6715 0.99966174\n",
      "6716 0.9994821\n",
      "6717 0.9995904\n",
      "6718 0.9997483\n",
      "6719 0.99974597\n",
      "6720 0.9994943\n",
      "6721 0.9994116\n",
      "6722 0.99957734\n",
      "6723 0.99940866\n",
      "6724 0.99967504\n",
      "6725 0.9994227\n",
      "6726 0.9993801\n",
      "6727 0.99958813\n",
      "6728 0.99892175\n",
      "6729 0.9997027\n",
      "6730 0.9995096\n",
      "6731 0.9998424\n",
      "6732 0.99970037\n",
      "6733 0.9995084\n",
      "6734 0.9998743\n",
      "6735 0.99986905\n",
      "6736 0.99954635\n",
      "6737 0.99987876\n",
      "6738 0.9997372\n",
      "6739 0.99995327\n",
      "6740 0.999807\n",
      "6741 0.9996457\n",
      "6742 0.9995787\n",
      "6743 0.9997827\n",
      "6744 0.99969524\n",
      "6745 0.9995712\n",
      "6746 0.99977475\n",
      "6747 0.99964756\n",
      "6748 0.999931\n",
      "6749 0.99994755\n",
      "6750 0.99961275\n",
      "6751 0.99987143\n",
      "6752 0.9998662\n",
      "6753 0.99987346\n",
      "6754 0.9996711\n",
      "6755 0.9999777\n",
      "6756 0.99983877\n",
      "6757 0.9999837\n",
      "6758 0.9995874\n",
      "6759 0.9999621\n",
      "6760 0.9996934\n",
      "6761 0.9999123\n",
      "6762 0.9998151\n",
      "6763 0.99978244\n",
      "6764 0.9999047\n",
      "6765 0.9999617\n",
      "6766 0.99992234\n",
      "6767 0.999731\n",
      "6768 0.99992865\n",
      "6769 0.99991655\n",
      "6770 0.99982333\n",
      "6771 0.9997694\n",
      "6772 0.99970585\n",
      "6773 0.9997247\n",
      "6774 0.9996694\n",
      "6775 0.9998333\n",
      "6776 0.9996311\n",
      "6777 0.9999518\n",
      "6778 0.999759\n",
      "6779 0.99982506\n",
      "6780 0.99977106\n",
      "6781 0.9997781\n",
      "6782 0.9999029\n",
      "6783 0.9995008\n",
      "6784 0.9995963\n",
      "6785 0.9997543\n",
      "6786 0.99982053\n",
      "6787 0.9997221\n",
      "6788 0.9998686\n",
      "6789 0.999972\n",
      "6790 0.99997044\n",
      "6791 0.99980736\n",
      "6792 0.99977237\n",
      "6793 0.9997668\n",
      "6794 0.9999864\n",
      "6795 0.99990964\n",
      "6796 0.999763\n",
      "6797 0.9997552\n",
      "6798 0.9998084\n",
      "6799 0.9998679\n",
      "6800 0.99969095\n",
      "6801 0.9999487\n",
      "6802 0.99934393\n",
      "6803 0.99990463\n",
      "6804 0.999231\n",
      "6805 0.9997212\n",
      "6806 0.9998556\n",
      "6807 0.9996617\n",
      "6808 0.9993254\n",
      "6809 0.99937594\n",
      "6810 0.9996974\n",
      "6811 0.9995132\n",
      "6812 0.9996959\n",
      "6813 0.99977607\n",
      "6814 0.9996117\n",
      "6815 0.9998726\n",
      "6816 0.9997273\n",
      "6817 0.9995688\n",
      "6818 0.9997746\n",
      "6819 0.9998628\n",
      "6820 0.9998288\n",
      "6821 0.99962336\n",
      "6822 0.9998963\n",
      "6823 0.9999856\n",
      "6824 0.9999473\n",
      "6825 0.99963224\n",
      "6826 0.99973714\n",
      "6827 0.9993366\n",
      "6828 0.99944377\n",
      "6829 0.9998318\n",
      "6830 0.99966884\n",
      "6831 0.99982995\n",
      "6832 0.99979526\n",
      "6833 0.9997824\n",
      "6834 0.999855\n",
      "6835 0.9997163\n",
      "6836 0.9998155\n",
      "6837 0.99917173\n",
      "6838 0.99979645\n",
      "6839 0.99996525\n",
      "6840 0.9995029\n",
      "6841 0.9998875\n",
      "6842 0.9996658\n",
      "6843 0.9998654\n",
      "6844 0.9997667\n",
      "6845 0.9995671\n",
      "6846 0.9995952\n",
      "6847 0.99988776\n",
      "6848 0.9998861\n",
      "6849 0.99971557\n",
      "6850 0.99983126\n",
      "6851 0.9999074\n",
      "6852 0.9997765\n",
      "6853 0.99978304\n",
      "6854 0.9998272\n",
      "6855 0.9998394\n",
      "6856 0.9998125\n",
      "6857 0.9996926\n",
      "6858 0.99962664\n",
      "6859 0.9997604\n",
      "6860 0.99974984\n",
      "6861 0.9996154\n",
      "6862 0.999641\n",
      "6863 0.9996472\n",
      "6864 0.99984354\n",
      "6865 0.99942017\n",
      "6866 0.99968785\n",
      "6867 0.99940145\n",
      "6868 0.99973613\n",
      "6869 0.99996674\n",
      "6870 0.9993878\n",
      "6871 0.99982387\n",
      "6872 0.99986094\n",
      "6873 0.999787\n",
      "6874 0.9995397\n",
      "6875 0.99961567\n",
      "6876 0.9997425\n",
      "6877 0.9998199\n",
      "6878 0.9997817\n",
      "6879 0.999587\n",
      "6880 0.99983895\n",
      "6881 0.99967974\n",
      "6882 0.99968433\n",
      "6883 0.9996767\n",
      "6884 0.999346\n",
      "6885 0.99974656\n",
      "6886 0.99942136\n",
      "6887 0.9995882\n",
      "6888 0.9995977\n",
      "6889 0.9996004\n",
      "6890 0.9998859\n",
      "6891 0.99969846\n",
      "6892 0.99949044\n",
      "6893 0.99957854\n",
      "6894 0.99981666\n",
      "6895 0.9997327\n",
      "6896 0.99933374\n",
      "6897 0.9997828\n",
      "6898 0.9996484\n",
      "6899 0.99971926\n",
      "6900 0.9995477\n",
      "6901 0.99970466\n",
      "6902 0.99972355\n",
      "6903 0.99985677\n",
      "6904 0.9994896\n",
      "6905 0.9995653\n",
      "6906 0.9996271\n",
      "6907 0.99984676\n",
      "6908 0.9997767\n",
      "6909 0.99960136\n",
      "6910 0.9995564\n",
      "6911 0.99982727\n",
      "6912 0.99952835\n",
      "6913 0.99996006\n",
      "6914 0.9998038\n",
      "6915 0.99998987\n",
      "6916 0.99962217\n",
      "6917 0.999851\n",
      "6918 0.99948895\n",
      "6919 0.9996873\n",
      "6920 0.99952495\n",
      "6921 0.9998096\n",
      "6922 0.9997296\n",
      "6923 0.9996045\n",
      "6924 0.9996367\n",
      "6925 0.99951506\n",
      "6926 0.9997765\n",
      "6927 0.9996111\n",
      "6928 0.9995953\n",
      "6929 0.99920106\n",
      "6930 0.99964285\n",
      "6931 0.99991816\n",
      "6932 0.9998875\n",
      "6933 0.9997465\n",
      "6934 0.9999314\n",
      "6935 0.99977684\n",
      "6936 0.9994926\n",
      "6937 0.9997857\n",
      "6938 0.99961966\n",
      "6939 0.99977857\n",
      "6940 0.9994873\n",
      "6941 0.99952227\n",
      "6942 0.99948126\n",
      "6943 0.99984884\n",
      "6944 0.99951357\n",
      "6945 0.9994728\n",
      "6946 0.9994635\n",
      "6947 0.9997263\n",
      "6948 0.9998259\n",
      "6949 0.99956906\n",
      "6950 0.9992434\n",
      "6951 0.99978906\n",
      "6952 0.9997145\n",
      "6953 0.9996508\n",
      "6954 0.99952817\n",
      "6955 0.99944717\n",
      "6956 0.99990517\n",
      "6957 0.9997251\n",
      "6958 0.99989086\n",
      "6959 0.99948186\n",
      "6960 0.99952906\n",
      "6961 0.99989843\n",
      "6962 0.999755\n",
      "6963 0.99975085\n",
      "6964 0.99924237\n",
      "6965 0.99948764\n",
      "6966 0.9994178\n",
      "6967 0.9999354\n",
      "6968 0.9999024\n",
      "6969 0.9995747\n",
      "6970 0.9997934\n",
      "6971 0.99930674\n",
      "6972 0.9996386\n",
      "6973 0.99933696\n",
      "6974 0.99976087\n",
      "6975 0.9996284\n",
      "6976 0.9999368\n",
      "6977 0.99932534\n",
      "6978 0.999659\n",
      "6979 0.99985343\n",
      "6980 0.99982065\n",
      "6981 0.99986035\n",
      "6982 0.99984676\n",
      "6983 0.9991764\n",
      "6984 0.9997983\n",
      "6985 0.9995323\n",
      "6986 0.99983793\n",
      "6987 0.9999366\n",
      "6988 0.9996262\n",
      "6989 0.99881804\n",
      "6990 0.9990651\n",
      "6991 0.99964535\n",
      "6992 0.9997699\n",
      "6993 0.99965686\n",
      "6994 0.99987084\n",
      "6995 0.9998499\n",
      "6996 0.9997624\n",
      "6997 0.99992394\n",
      "6998 0.9999176\n",
      "6999 0.9994593\n",
      "7000 0.99959993\n",
      "7001 0.99983126\n",
      "7002 0.99982667\n",
      "7003 0.9996814\n",
      "7004 0.99941564\n",
      "7005 0.9992539\n",
      "7006 0.999571\n",
      "7007 0.999851\n",
      "7008 0.9999151\n",
      "7009 0.99960285\n",
      "7010 0.9994265\n",
      "7011 0.9998164\n",
      "7012 0.9990427\n",
      "7013 0.9996932\n",
      "7014 0.99973816\n",
      "7015 0.9998032\n",
      "7016 0.9999401\n",
      "7017 0.99991226\n",
      "7018 0.99961257\n",
      "7019 0.9996384\n",
      "7020 0.9998155\n",
      "7021 0.9994231\n",
      "7022 0.999564\n",
      "7023 0.9997115\n",
      "7024 0.99977356\n",
      "7025 0.9998224\n",
      "7026 0.9999063\n",
      "7027 0.9998277\n",
      "7028 0.9993554\n",
      "7029 0.9996256\n",
      "7030 0.9998376\n",
      "7031 0.9998061\n",
      "7032 0.99958843\n",
      "7033 0.9997952\n",
      "7034 0.9991115\n",
      "7035 0.9994941\n",
      "7036 0.99951345\n",
      "7037 0.9996422\n",
      "7038 0.99921566\n",
      "7039 0.99968153\n",
      "7040 0.99947757\n",
      "7041 0.9997806\n",
      "7042 0.9991316\n",
      "7043 0.99962157\n",
      "7044 0.9998061\n",
      "7045 0.9998597\n",
      "7046 0.99984276\n",
      "7047 0.99984336\n",
      "7048 0.9998545\n",
      "7049 0.9999185\n",
      "7050 0.9999141\n",
      "7051 0.99987113\n",
      "7052 0.9993367\n",
      "7053 0.9998603\n",
      "7054 0.99980015\n",
      "7055 0.999859\n",
      "7056 0.9995911\n",
      "7057 0.9996106\n",
      "7058 0.99947625\n",
      "7059 0.9997772\n",
      "7060 0.9996282\n",
      "7061 0.9999548\n",
      "7062 0.9999261\n",
      "7063 0.9997377\n",
      "7064 0.99974704\n",
      "7065 0.9994883\n",
      "7066 0.99913764\n",
      "7067 0.9993356\n",
      "7068 0.99975836\n",
      "7069 0.99967253\n",
      "7070 0.9996735\n",
      "7071 0.9997939\n",
      "7072 0.9997103\n",
      "7073 0.9998666\n",
      "7074 0.99984604\n",
      "7075 0.9994233\n",
      "7076 0.99984163\n",
      "7077 0.9996798\n",
      "7078 0.9997457\n",
      "7079 0.9998732\n",
      "7080 0.9997051\n",
      "7081 0.99974835\n",
      "7082 0.99957234\n",
      "7083 0.99977696\n",
      "7084 0.9998267\n",
      "7085 0.999662\n",
      "7086 0.9999454\n",
      "7087 0.99960405\n",
      "7088 0.9995789\n",
      "7089 0.9997613\n",
      "7090 0.99968946\n",
      "7091 0.99978185\n",
      "7092 0.999955\n",
      "7093 0.99982786\n",
      "7094 0.9997892\n",
      "7095 0.99971086\n",
      "7096 0.9996912\n",
      "7097 0.9994467\n",
      "7098 0.99981475\n",
      "7099 0.99979174\n",
      "7100 0.9994663\n",
      "7101 0.9994641\n",
      "7102 0.99953777\n",
      "7103 0.99982613\n",
      "7104 0.99987054\n",
      "7105 0.99980277\n",
      "7106 0.9998579\n",
      "7107 0.9995504\n",
      "7108 0.9992048\n",
      "7109 0.9998021\n",
      "7110 0.9997764\n",
      "7111 0.99955994\n",
      "7112 0.999666\n",
      "7113 0.99981475\n",
      "7114 0.99951714\n",
      "7115 0.99965805\n",
      "7116 0.9993871\n",
      "7117 0.99977756\n",
      "7118 0.99949193\n",
      "7119 0.99971473\n",
      "7120 0.9992864\n",
      "7121 0.9995739\n",
      "7122 0.9996307\n",
      "7123 0.99953496\n",
      "7124 0.99960285\n",
      "7125 0.99971974\n",
      "7126 0.9996055\n",
      "7127 0.9995275\n",
      "7128 0.99973893\n",
      "7129 0.9997794\n",
      "7130 0.99945605\n",
      "7131 0.9995535\n",
      "7132 0.99978125\n",
      "7133 0.99981344\n",
      "7134 0.9998996\n",
      "7135 0.9997458\n",
      "7136 0.9996703\n",
      "7137 0.9998141\n",
      "7138 0.999496\n",
      "7139 0.99975145\n",
      "7140 0.9996741\n",
      "7141 0.99964154\n",
      "7142 0.99951947\n",
      "7143 0.99924624\n",
      "7144 0.9992085\n",
      "7145 0.9998579\n",
      "7146 0.999737\n",
      "7147 0.99950767\n",
      "7148 0.99982953\n",
      "7149 0.99977887\n",
      "7150 0.9998573\n",
      "7151 0.99957764\n",
      "7152 0.99969995\n",
      "7153 0.9997858\n",
      "7154 0.9997184\n",
      "7155 0.9997012\n",
      "7156 0.9998384\n",
      "7157 0.99973\n",
      "7158 0.9998226\n",
      "7159 0.99984217\n",
      "7160 0.9998813\n",
      "7161 0.99987304\n",
      "7162 0.99955523\n",
      "7163 0.9996261\n",
      "7164 0.99987733\n",
      "7165 0.9999226\n",
      "7166 0.99923486\n",
      "7167 0.99984187\n",
      "7168 0.99984515\n",
      "7169 0.9998547\n",
      "7170 0.9994913\n",
      "7171 0.99954015\n",
      "7172 0.9998056\n",
      "7173 0.99996936\n",
      "7174 0.99944323\n",
      "7175 0.99986094\n",
      "7176 0.9997003\n",
      "7177 0.99986815\n",
      "7178 0.99973124\n",
      "7179 0.9999464\n",
      "7180 0.9997163\n",
      "7181 0.9996585\n",
      "7182 0.9997812\n",
      "7183 0.99972713\n",
      "7184 0.99976957\n",
      "7185 0.99985725\n",
      "7186 0.9997793\n",
      "7187 0.9997816\n",
      "7188 0.99964595\n",
      "7189 0.99985456\n",
      "7190 0.9996853\n",
      "7191 0.99943846\n",
      "7192 0.9998727\n",
      "7193 0.9998504\n",
      "7194 0.999877\n",
      "7195 0.9996403\n",
      "7196 0.9995384\n",
      "7197 0.9997905\n",
      "7198 0.99973786\n",
      "7199 0.9993023\n",
      "7200 0.99978894\n",
      "7201 0.99979174\n",
      "7202 0.99973035\n",
      "7203 0.99971706\n",
      "7204 0.9994471\n",
      "7205 0.999469\n",
      "7206 0.9995481\n",
      "7207 0.99932367\n",
      "7208 0.9992838\n",
      "7209 0.99977\n",
      "7210 0.99979484\n",
      "7211 0.9996135\n",
      "7212 0.99961483\n",
      "7213 0.9998394\n",
      "7214 0.99981433\n",
      "7215 0.999563\n",
      "7216 0.9997682\n",
      "7217 0.99985135\n",
      "7218 0.9996432\n",
      "7219 0.99979514\n",
      "7220 0.9998323\n",
      "7221 0.9996723\n",
      "7222 0.99987966\n",
      "7223 0.9999066\n",
      "7224 0.9998652\n",
      "7225 0.99974287\n",
      "7226 0.9996649\n",
      "7227 0.9997423\n",
      "7228 0.99994177\n",
      "7229 0.9990006\n",
      "7230 0.9996415\n",
      "7231 0.99932635\n",
      "7232 0.99961054\n",
      "7233 0.9998579\n",
      "7234 0.9997426\n",
      "7235 0.99969816\n",
      "7236 0.99987984\n",
      "7237 0.9994959\n",
      "7238 0.9994802\n",
      "7239 0.9995426\n",
      "7240 0.99947816\n",
      "7241 0.9998646\n",
      "7242 0.9999433\n",
      "7243 0.9998686\n",
      "7244 0.99973375\n",
      "7245 0.9996982\n",
      "7246 0.9997969\n",
      "7247 0.9996583\n",
      "7248 0.99971026\n",
      "7249 0.99961895\n",
      "7250 0.9996477\n",
      "7251 0.99995613\n",
      "7252 0.9997271\n",
      "7253 0.9996606\n",
      "7254 0.99948424\n",
      "7255 0.9992933\n",
      "7256 0.9994494\n",
      "7257 0.9991956\n",
      "7258 0.99973965\n",
      "7259 0.9997401\n",
      "7260 0.99976313\n",
      "7261 0.9997107\n",
      "7262 0.9996148\n",
      "7263 0.9996539\n",
      "7264 0.99925613\n",
      "7265 0.9991898\n",
      "7266 0.9999659\n",
      "7267 0.99982023\n",
      "7268 0.99970895\n",
      "7269 0.9997867\n",
      "7270 0.9998264\n",
      "7271 0.9998099\n",
      "7272 0.9999012\n",
      "7273 0.99980605\n",
      "7274 0.9993802\n",
      "7275 0.99958944\n",
      "7276 0.9995718\n",
      "7277 0.99980605\n",
      "7278 0.9996996\n",
      "7279 0.99963164\n",
      "7280 0.99970436\n",
      "7281 0.99983805\n",
      "7282 0.99981874\n",
      "7283 0.99977666\n",
      "7284 0.9997075\n",
      "7285 0.9996005\n",
      "7286 0.99973154\n",
      "7287 0.9997371\n",
      "7288 0.9994591\n",
      "7289 0.9996841\n",
      "7290 0.99979264\n",
      "7291 0.9993219\n",
      "7292 0.9997605\n",
      "7293 0.9999701\n",
      "7294 0.99980444\n",
      "7295 0.9996944\n",
      "7296 0.9997027\n",
      "7297 0.99961805\n",
      "7298 0.9996604\n",
      "7299 0.999535\n",
      "7300 0.99932605\n",
      "7301 0.99976796\n",
      "7302 0.9994898\n",
      "7303 0.9996801\n",
      "7304 0.9996724\n",
      "7305 0.9996904\n",
      "7306 0.99970955\n",
      "7307 0.99979043\n",
      "7308 0.9995777\n",
      "7309 0.9997794\n",
      "7310 0.99959445\n",
      "7311 0.9995479\n",
      "7312 0.99954045\n",
      "7313 0.99987054\n",
      "7314 0.99976254\n",
      "7315 0.99964523\n",
      "7316 0.9997788\n",
      "7317 0.9995169\n",
      "7318 0.99971384\n",
      "7319 0.99982625\n",
      "7320 0.9998053\n",
      "7321 0.9996102\n",
      "7322 0.9998331\n",
      "7323 0.999834\n",
      "7324 0.999876\n",
      "7325 0.99954236\n",
      "7326 0.9995288\n",
      "7327 0.99927866\n",
      "7328 0.9997734\n",
      "7329 0.9997675\n",
      "7330 0.99903274\n",
      "7331 0.999704\n",
      "7332 0.9995286\n",
      "7333 0.9998515\n",
      "7334 0.99990845\n",
      "7335 0.9998012\n",
      "7336 0.9994819\n",
      "7337 0.99971765\n",
      "7338 0.9995496\n",
      "7339 0.99987817\n",
      "7340 0.9995609\n",
      "7341 0.99947655\n",
      "7342 0.99967974\n",
      "7343 0.9997955\n",
      "7344 0.9995454\n",
      "7345 0.99958116\n",
      "7346 0.9999587\n",
      "7347 0.99956924\n",
      "7348 0.9997149\n",
      "7349 0.9999381\n",
      "7350 0.99950016\n",
      "7351 0.9995565\n",
      "7352 0.9999208\n",
      "7353 0.99987394\n",
      "7354 0.9996838\n",
      "7355 0.9997389\n",
      "7356 0.9996263\n",
      "7357 0.99974036\n",
      "7358 0.9995815\n",
      "7359 0.9997852\n",
      "7360 0.9996655\n",
      "7361 0.9996009\n",
      "7362 0.9999345\n",
      "7363 0.99975973\n",
      "7364 0.9996942\n",
      "7365 0.99984354\n",
      "7366 0.9997457\n",
      "7367 0.9999693\n",
      "7368 0.9997956\n",
      "7369 0.99973345\n",
      "7370 0.9997858\n",
      "7371 0.99989885\n",
      "7372 0.9998625\n",
      "7373 0.9997658\n",
      "7374 0.999819\n",
      "7375 0.9998221\n",
      "7376 0.99975663\n",
      "7377 0.9996966\n",
      "7378 0.9997739\n",
      "7379 0.9998719\n",
      "7380 0.9997519\n",
      "7381 0.99977833\n",
      "7382 0.999796\n",
      "7383 0.9997618\n",
      "7384 0.9996606\n",
      "7385 0.99974096\n",
      "7386 0.999818\n",
      "7387 0.9997928\n",
      "7388 0.99960417\n",
      "7389 0.9994045\n",
      "7390 0.99976325\n",
      "7391 0.9995152\n",
      "7392 0.9997127\n",
      "7393 0.99981445\n",
      "7394 0.99968016\n",
      "7395 0.9997584\n",
      "7396 0.99984235\n",
      "7397 0.99984306\n",
      "7398 0.99969596\n",
      "7399 0.99938893\n",
      "7400 0.9996191\n",
      "7401 0.9996008\n",
      "7402 0.99979615\n",
      "7403 0.99980325\n",
      "7404 0.9999091\n",
      "7405 0.99884194\n",
      "7406 0.9995629\n",
      "7407 0.99946415\n",
      "7408 0.99986434\n",
      "7409 0.9998773\n",
      "7410 0.99977255\n",
      "7411 0.9998735\n",
      "7412 0.9998838\n",
      "7413 0.99990654\n",
      "7414 0.99968547\n",
      "7415 0.99994546\n",
      "7416 0.9998653\n",
      "7417 0.99968535\n",
      "7418 0.99887216\n",
      "7419 0.99936706\n",
      "7420 0.9998412\n",
      "7421 0.99970526\n",
      "7422 0.9998256\n",
      "7423 0.99988073\n",
      "7424 0.99993515\n",
      "7425 0.9997063\n",
      "7426 0.9999591\n",
      "7427 0.9996758\n",
      "7428 0.9997939\n",
      "7429 0.99946743\n",
      "7430 0.999751\n",
      "7431 0.99965626\n",
      "7432 0.9999252\n",
      "7433 0.99969774\n",
      "7434 0.99968266\n",
      "7435 0.9996959\n",
      "7436 0.9998018\n",
      "7437 0.9998068\n",
      "7438 0.9996943\n",
      "7439 0.9998806\n",
      "7440 0.9995067\n",
      "7441 0.99975145\n",
      "7442 0.99978185\n",
      "7443 0.99960834\n",
      "7444 0.9994849\n",
      "7445 0.99955195\n",
      "7446 0.99979967\n",
      "7447 0.99982506\n",
      "7448 0.9999307\n",
      "7449 0.9997647\n",
      "7450 0.99980265\n",
      "7451 0.99974614\n",
      "7452 0.99986345\n",
      "7453 0.9997056\n",
      "7454 0.9997705\n",
      "7455 0.999829\n",
      "7456 0.99951756\n",
      "7457 0.9996664\n",
      "7458 0.99992186\n",
      "7459 0.9999032\n",
      "7460 0.99978817\n",
      "7461 0.9993419\n",
      "7462 0.99928075\n",
      "7463 0.9996837\n",
      "7464 0.9996213\n",
      "7465 0.99988276\n",
      "7466 0.99913245\n",
      "7467 0.99939185\n",
      "7468 0.9997348\n",
      "7469 0.99975663\n",
      "7470 0.9992751\n",
      "7471 0.99981797\n",
      "7472 0.99947625\n",
      "7473 0.99930114\n",
      "7474 0.9995502\n",
      "7475 0.99993354\n",
      "7476 0.99966383\n",
      "7477 0.9998027\n",
      "7478 0.9996115\n",
      "7479 0.99963516\n",
      "7480 0.99988276\n",
      "7481 0.9995632\n",
      "7482 0.99967915\n",
      "7483 0.999657\n",
      "7484 0.99961656\n",
      "7485 0.9993779\n",
      "7486 0.9998596\n",
      "7487 0.9997783\n",
      "7488 0.99982375\n",
      "7489 0.99918586\n",
      "7490 0.99971145\n",
      "7491 0.999913\n",
      "7492 0.99945694\n",
      "7493 0.9999233\n",
      "7494 0.99971175\n",
      "7495 0.9993953\n",
      "7496 0.9997201\n",
      "7497 0.9996885\n",
      "7498 0.9998369\n",
      "7499 0.9998596\n",
      "7500 0.9996583\n",
      "7501 0.999964\n",
      "7502 0.9996854\n",
      "7503 0.9996666\n",
      "7504 0.999341\n",
      "7505 0.9998246\n",
      "7506 0.9997425\n",
      "7507 0.99983805\n",
      "7508 0.99965334\n",
      "7509 0.9996596\n",
      "7510 0.99988914\n",
      "7511 0.9999939\n",
      "7512 0.99944985\n",
      "7513 0.99977803\n",
      "7514 0.9997587\n",
      "7515 0.9997924\n",
      "7516 0.9997736\n",
      "7517 0.9997756\n",
      "7518 0.99979925\n",
      "7519 0.9997603\n",
      "7520 0.99988514\n",
      "7521 0.9991876\n",
      "7522 0.9996023\n",
      "7523 0.9998482\n",
      "7524 0.99944127\n",
      "7525 0.99943584\n",
      "7526 0.9996317\n",
      "7527 0.9998692\n",
      "7528 0.99998224\n",
      "7529 0.9996002\n",
      "7530 0.99959844\n",
      "7531 0.99985546\n",
      "7532 0.9998597\n",
      "7533 0.999389\n",
      "7534 0.99980533\n",
      "7535 0.9996311\n",
      "7536 0.99972403\n",
      "7537 0.99974644\n",
      "7538 0.99995023\n",
      "7539 0.9996897\n",
      "7540 0.99936277\n",
      "7541 0.9994044\n",
      "7542 0.9995628\n",
      "7543 0.9998857\n",
      "7544 0.9998274\n",
      "7545 0.9998805\n",
      "7546 0.9997528\n",
      "7547 0.99978095\n",
      "7548 0.9995483\n",
      "7549 0.9995937\n",
      "7550 0.99983776\n",
      "7551 0.99961734\n",
      "7552 0.99978817\n",
      "7553 0.99975723\n",
      "7554 0.999574\n",
      "7555 0.9998805\n",
      "7556 0.99975425\n",
      "7557 0.9998341\n",
      "7558 0.9998736\n",
      "7559 0.99970734\n",
      "7560 0.99989796\n",
      "7561 0.9999593\n",
      "7562 0.9998185\n",
      "7563 0.99966073\n",
      "7564 0.9999081\n",
      "7565 0.9998143\n",
      "7566 0.999864\n",
      "7567 0.999548\n",
      "7568 0.9998786\n",
      "7569 0.99978334\n",
      "7570 0.9997235\n",
      "7571 0.9998267\n",
      "7572 0.99988836\n",
      "7573 0.9998371\n",
      "7574 0.999496\n",
      "7575 0.99960166\n",
      "7576 0.9996101\n",
      "7577 0.9998823\n",
      "7578 0.9998142\n",
      "7579 0.999891\n",
      "7580 0.9994877\n",
      "7581 0.99981827\n",
      "7582 0.99990183\n",
      "7583 0.9995607\n",
      "7584 0.99957246\n",
      "7585 0.9997611\n",
      "7586 0.9998795\n",
      "7587 0.9997621\n",
      "7588 0.99977064\n",
      "7589 0.9996237\n",
      "7590 0.9996014\n",
      "7591 0.9995874\n",
      "7592 0.9997693\n",
      "7593 0.99985075\n",
      "7594 0.9998076\n",
      "7595 0.9995878\n",
      "7596 0.99968654\n",
      "7597 0.9997219\n",
      "7598 0.99992627\n",
      "7599 0.9996843\n",
      "7600 0.9998044\n",
      "7601 0.999541\n",
      "7602 0.99967706\n",
      "7603 0.9999006\n",
      "7604 0.9997126\n",
      "7605 0.9994552\n",
      "7606 0.99982065\n",
      "7607 0.9998352\n",
      "7608 0.99983406\n",
      "7609 0.9997238\n",
      "7610 0.9998143\n",
      "7611 0.9998544\n",
      "7612 0.9996221\n",
      "7613 0.9997292\n",
      "7614 0.9997923\n",
      "7615 0.99955916\n",
      "7616 0.99988395\n",
      "7617 0.9998307\n",
      "7618 0.9996501\n",
      "7619 0.99943024\n",
      "7620 0.99964046\n",
      "7621 0.99966866\n",
      "7622 0.9990765\n",
      "7623 0.99950415\n",
      "7624 0.99997425\n",
      "7625 0.9998574\n",
      "7626 0.9997568\n",
      "7627 0.99979144\n",
      "7628 0.9996625\n",
      "7629 0.9997633\n",
      "7630 0.99994487\n",
      "7631 0.9997591\n",
      "7632 0.9997367\n",
      "7633 0.9993705\n",
      "7634 0.9997748\n",
      "7635 0.99963063\n",
      "7636 0.9998765\n",
      "7637 0.99967504\n",
      "7638 0.9997452\n",
      "7639 0.99977577\n",
      "7640 0.99960303\n",
      "7641 0.9998022\n",
      "7642 0.99987906\n",
      "7643 0.99988586\n",
      "7644 0.99969554\n",
      "7645 0.999578\n",
      "7646 0.999469\n",
      "7647 0.999779\n",
      "7648 0.9998837\n",
      "7649 0.9995987\n",
      "7650 0.9998032\n",
      "7651 0.99993443\n",
      "7652 0.9999713\n",
      "7653 0.9996908\n",
      "7654 0.99977106\n",
      "7655 0.9999388\n",
      "7656 0.9998797\n",
      "7657 0.9996921\n",
      "7658 0.9997492\n",
      "7659 0.99946165\n",
      "7660 0.9997784\n",
      "7661 0.99972284\n",
      "7662 0.9996347\n",
      "7663 0.9993452\n",
      "7664 0.99975544\n",
      "7665 0.99962366\n",
      "7666 0.9998024\n",
      "7667 0.99970186\n",
      "7668 0.99965954\n",
      "7669 0.99961907\n",
      "7670 0.99994385\n",
      "7671 0.99991804\n",
      "7672 0.99900126\n",
      "7673 0.99983054\n",
      "7674 0.99954814\n",
      "7675 0.999431\n",
      "7676 0.9997181\n",
      "7677 0.9997707\n",
      "7678 0.99963546\n",
      "7679 0.99909896\n",
      "7680 0.9999139\n",
      "7681 0.9996323\n",
      "7682 0.9996401\n",
      "7683 0.99962723\n",
      "7684 0.99962914\n",
      "7685 0.99943256\n",
      "7686 0.9997013\n",
      "7687 0.9999701\n",
      "7688 0.99978983\n",
      "7689 0.9994613\n",
      "7690 0.9998027\n",
      "7691 0.99861443\n",
      "7692 0.99981666\n",
      "7693 0.9999405\n",
      "7694 0.99994403\n",
      "7695 0.99974674\n",
      "7696 0.99974436\n",
      "7697 0.9997377\n",
      "7698 0.99974865\n",
      "7699 0.99949664\n",
      "7700 0.9993626\n",
      "7701 0.99974734\n",
      "7702 0.9995127\n",
      "7703 0.99976355\n",
      "7704 0.99982977\n",
      "7705 0.9999396\n",
      "7706 0.9998556\n",
      "7707 0.9995384\n",
      "7708 0.99964726\n",
      "7709 0.9997012\n",
      "7710 0.99987686\n",
      "7711 0.9996802\n",
      "7712 0.9997586\n",
      "7713 0.999286\n",
      "7714 0.9998212\n",
      "7715 0.99934393\n",
      "7716 0.9998972\n",
      "7717 0.99955934\n",
      "7718 0.99994546\n",
      "7719 0.9997771\n",
      "7720 0.9997822\n",
      "7721 0.99967265\n",
      "7722 0.9998899\n",
      "7723 0.99937344\n",
      "7724 0.99972755\n",
      "7725 0.999501\n",
      "7726 0.9992822\n",
      "7727 0.9996735\n",
      "7728 0.99891466\n",
      "7729 0.99946326\n",
      "7730 0.9998141\n",
      "7731 0.9994995\n",
      "7732 0.9997972\n",
      "7733 0.9996382\n",
      "7734 0.9995265\n",
      "7735 0.99987954\n",
      "7736 0.999705\n",
      "7737 0.99959505\n",
      "7738 0.9997955\n",
      "7739 0.9997984\n",
      "7740 0.9998384\n",
      "7741 0.9998075\n",
      "7742 0.9999013\n",
      "7743 0.99987924\n",
      "7744 0.99968296\n",
      "7745 0.999886\n",
      "7746 0.999874\n",
      "7747 0.9995596\n",
      "7748 0.9996852\n",
      "7749 0.99979407\n",
      "7750 0.99979204\n",
      "7751 0.99969894\n",
      "7752 0.9999315\n",
      "7753 0.9996361\n",
      "7754 0.9998047\n",
      "7755 0.9995858\n",
      "7756 0.9996552\n",
      "7757 0.99952453\n",
      "7758 0.99980676\n",
      "7759 0.9998051\n",
      "7760 0.9997896\n",
      "7761 0.9997322\n",
      "7762 0.9996543\n",
      "7763 0.9995711\n",
      "7764 0.9999411\n",
      "7765 0.99963784\n",
      "7766 0.999686\n",
      "7767 0.9995623\n",
      "7768 0.99981546\n",
      "7769 0.99978\n",
      "7770 0.9995118\n",
      "7771 0.9996791\n",
      "7772 0.9997605\n",
      "7773 0.99934983\n",
      "7774 0.9995659\n",
      "7775 0.9995911\n",
      "7776 0.99991286\n",
      "7777 0.99966455\n",
      "7778 0.9996474\n",
      "7779 0.999604\n",
      "7780 0.9997012\n",
      "7781 0.99960834\n",
      "7782 0.99955803\n",
      "7783 0.9997178\n",
      "7784 0.9995881\n",
      "7785 0.99958086\n",
      "7786 0.99979866\n",
      "7787 0.99991393\n",
      "7788 0.9991604\n",
      "7789 0.99941653\n",
      "7790 0.9996994\n",
      "7791 0.99957603\n",
      "7792 0.999808\n",
      "7793 0.9996165\n",
      "7794 0.9991753\n",
      "7795 0.99942255\n",
      "7796 0.99989295\n",
      "7797 0.9996577\n",
      "7798 0.99908847\n",
      "7799 0.99901766\n",
      "7800 0.99978477\n",
      "7801 0.9998238\n",
      "7802 0.999698\n",
      "7803 0.9994788\n",
      "7804 0.9997229\n",
      "7805 0.9996249\n",
      "7806 0.99951583\n",
      "7807 0.99945205\n",
      "7808 0.9998891\n",
      "7809 0.999766\n",
      "7810 0.9994051\n",
      "7811 0.99955326\n",
      "7812 0.9995641\n",
      "7813 0.9996994\n",
      "7814 0.99962\n",
      "7815 0.99953705\n",
      "7816 0.9998598\n",
      "7817 0.9997106\n",
      "7818 0.9994571\n",
      "7819 0.9992197\n",
      "7820 0.9994985\n",
      "7821 0.99976116\n",
      "7822 0.99985546\n",
      "7823 0.99952716\n",
      "7824 0.999644\n",
      "7825 0.9997007\n",
      "7826 0.99962413\n",
      "7827 0.9999169\n",
      "7828 0.9997379\n",
      "7829 0.99940974\n",
      "7830 0.9996117\n",
      "7831 0.9988988\n",
      "7832 0.9993117\n",
      "7833 0.99975395\n",
      "7834 0.9995238\n",
      "7835 0.9997182\n",
      "7836 0.99949217\n",
      "7837 0.9994236\n",
      "7838 0.9996735\n",
      "7839 0.9998856\n",
      "7840 0.9993907\n",
      "7841 0.99981695\n",
      "7842 0.9996321\n",
      "7843 0.9995391\n",
      "7844 0.99990076\n",
      "7845 0.99976987\n",
      "7846 0.99961954\n",
      "7847 0.9996835\n",
      "7848 0.99941266\n",
      "7849 0.9996489\n",
      "7850 0.9996196\n",
      "7851 0.9995519\n",
      "7852 0.9990918\n",
      "7853 0.9991602\n",
      "7854 0.9990462\n",
      "7855 0.9994711\n",
      "7856 0.9997862\n",
      "7857 0.99980265\n",
      "7858 0.9996733\n",
      "7859 0.9996807\n",
      "7860 0.99988145\n",
      "7861 0.9999232\n",
      "7862 0.9998496\n",
      "7863 0.999843\n",
      "7864 0.999413\n",
      "7865 0.9988388\n",
      "7866 0.9997922\n",
      "7867 0.9995335\n",
      "7868 0.9997746\n",
      "7869 0.99872077\n",
      "7870 0.99929553\n",
      "7871 0.99965614\n",
      "7872 0.99950653\n",
      "7873 0.9996945\n",
      "7874 0.999848\n",
      "7875 0.9994095\n",
      "7876 0.9993881\n",
      "7877 0.9988372\n",
      "7878 0.9998398\n",
      "7879 0.9996692\n",
      "7880 0.99949336\n",
      "7881 0.999859\n",
      "7882 0.999451\n",
      "7883 0.99880993\n",
      "7884 0.99942744\n",
      "7885 0.9994331\n",
      "7886 0.99974495\n",
      "7887 0.99939626\n",
      "7888 0.99943817\n",
      "7889 0.99969524\n",
      "7890 0.99976826\n",
      "7891 0.9998483\n",
      "7892 0.99996555\n",
      "7893 0.99988604\n",
      "7894 0.99992967\n",
      "7895 0.99971545\n",
      "7896 0.99974954\n",
      "7897 0.9998471\n",
      "7898 0.9998523\n",
      "7899 0.99941677\n",
      "7900 0.9997316\n",
      "7901 0.9997536\n",
      "7902 0.9996322\n",
      "7903 0.999426\n",
      "7904 0.99989885\n",
      "7905 0.99982816\n",
      "7906 0.9996754\n",
      "7907 0.99981815\n",
      "7908 0.99979484\n",
      "7909 0.9998414\n",
      "7910 0.9996376\n",
      "7911 0.99983495\n",
      "7912 0.9998039\n",
      "7913 0.99957645\n",
      "7914 0.9995652\n",
      "7915 0.9995875\n",
      "7916 0.99983585\n",
      "7917 0.99967647\n",
      "7918 0.9995748\n",
      "7919 0.99954647\n",
      "7920 0.99957454\n",
      "7921 0.9998235\n",
      "7922 0.9997493\n",
      "7923 0.9996763\n",
      "7924 0.999396\n",
      "7925 0.9996011\n",
      "7926 0.9995411\n",
      "7927 0.9998373\n",
      "7928 0.99970233\n",
      "7929 0.999631\n",
      "7930 0.9999521\n",
      "7931 0.99988145\n",
      "7932 0.9998251\n",
      "7933 0.9995529\n",
      "7934 0.99968404\n",
      "7935 0.99983025\n",
      "7936 0.99981076\n",
      "7937 0.9996069\n",
      "7938 0.99969155\n",
      "7939 0.9999088\n",
      "7940 0.9992593\n",
      "7941 0.99943805\n",
      "7942 0.99975616\n",
      "7943 0.9995525\n",
      "7944 0.99947894\n",
      "7945 0.99970454\n",
      "7946 0.9995761\n",
      "7947 0.9995445\n",
      "7948 0.9996594\n",
      "7949 0.99970603\n",
      "7950 0.9998342\n",
      "7951 0.9997332\n",
      "7952 0.99976104\n",
      "7953 0.9995744\n",
      "7954 0.9997548\n",
      "7955 0.9996652\n",
      "7956 0.99944156\n",
      "7957 0.9997855\n",
      "7958 0.9998506\n",
      "7959 0.99970096\n",
      "7960 0.99963886\n",
      "7961 0.9999314\n",
      "7962 0.99993646\n",
      "7963 0.9998749\n",
      "7964 0.99988353\n",
      "7965 0.9997778\n",
      "7966 0.9998513\n",
      "7967 0.9992594\n",
      "7968 0.9997033\n",
      "7969 0.9996683\n",
      "7970 0.99984664\n",
      "7971 0.99960816\n",
      "7972 0.9999153\n",
      "7973 0.99994755\n",
      "7974 0.99973285\n",
      "7975 0.9997963\n",
      "7976 0.99988025\n",
      "7977 0.99971133\n",
      "7978 0.99987173\n",
      "7979 0.99977237\n",
      "7980 0.9998175\n",
      "7981 0.9996906\n",
      "7982 0.9997836\n",
      "7983 0.9999839\n",
      "7984 0.99976116\n",
      "7985 0.9998962\n",
      "7986 0.9999573\n",
      "7987 0.9999621\n",
      "7988 0.99953455\n",
      "7989 0.9997664\n",
      "7990 0.9995795\n",
      "7991 0.9997979\n",
      "7992 0.9998871\n",
      "7993 0.99961734\n",
      "7994 0.99954545\n",
      "7995 0.99969393\n",
      "7996 0.9996952\n",
      "7997 0.99944323\n",
      "7998 0.99970895\n",
      "7999 0.999786\n",
      "8000 0.9998356\n",
      "8001 0.9997095\n",
      "8002 0.9989985\n",
      "8003 0.99767095\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PRpyGGlhAdXl"
   },
   "source": [
    "f_param_list[0][0].detach().numpy()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UE0WiG5bCd2W"
   },
   "source": [],
   "execution_count": null,
   "outputs": []
  }
 ]
}
